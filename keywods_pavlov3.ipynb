{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1d46f2a54c479ab59d26ebb3ce50c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356e6944b3174a959619137d019407b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2061 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Предсказание отзывов:   0%|                                                                                                                                                                        | 0/65 [00:00<?, ?it/s]/tmp/ipykernel_39/1355171717.py:197: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Используем смешанную точность\n",
      "Предсказание отзывов: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 65/65 [00:12<00:00,  5.09it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a444cba8b84bc2a9279963a141ae7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2061 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories and products: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:18<00:00,  1.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>word_count</th>\n",
       "      <th>key_thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВПМ / Антибукс - антипробуксовочные траки утол...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Переднее колесо закрылось в снегу, подложили п...</td>\n",
       "      <td>40</td>\n",
       "      <td>Переднее колесо закрылось в снегу, подложили п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВПМ / Антибукс - антипробуксовочные траки утол...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>На вид крепкие. | Вроде прочные. | На вид проч...</td>\n",
       "      <td>12</td>\n",
       "      <td>На вид крепкие.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>neutral</td>\n",
       "      <td>В деле не пробовал | В деле пока не пробовала....</td>\n",
       "      <td>37</td>\n",
       "      <td>В деле не пробовал</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>Пахнет и Точка / Ароматизатор в машину автопар...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Рекомендую, буду брать еще | Закажу | мыМыочно...</td>\n",
       "      <td>20</td>\n",
       "      <td>Буду заказывать ещё.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>Пахнет и Точка / Ароматизатор в машину автопар...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Еле пахнет. | Он даже не пахнет. | Пахнет каки...</td>\n",
       "      <td>13</td>\n",
       "      <td>Еле пахнет.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                category  \\\n",
       "0                    /Автотовары/OFFroad   \n",
       "1                    /Автотовары/OFFroad   \n",
       "3                    /Автотовары/OFFroad   \n",
       "4  /Автотовары/Автокосметика и автохимия   \n",
       "5  /Автотовары/Автокосметика и автохимия   \n",
       "\n",
       "                                             product  avg_rating  \\\n",
       "0  ВПМ / Антибукс - антипробуксовочные траки утол...    0.819588   \n",
       "1  ВПМ / Антибукс - антипробуксовочные траки утол...    0.819588   \n",
       "3  ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...    0.842975   \n",
       "4  Пахнет и Точка / Ароматизатор в машину автопар...    0.704545   \n",
       "5  Пахнет и Точка / Ароматизатор в машину автопар...    0.704545   \n",
       "\n",
       "  rating_category                                  cluster_sentences  \\\n",
       "0         neutral  Переднее колесо закрылось в снегу, подложили п...   \n",
       "1         neutral  На вид крепкие. | Вроде прочные. | На вид проч...   \n",
       "3         neutral  В деле не пробовал | В деле пока не пробовала....   \n",
       "4         neutral  Рекомендую, буду брать еще | Закажу | мыМыочно...   \n",
       "5         neutral  Еле пахнет. | Он даже не пахнет. | Пахнет каки...   \n",
       "\n",
       "   word_count                                        key_thought  \n",
       "0          40  Переднее колесо закрылось в снегу, подложили п...  \n",
       "1          12                                    На вид крепкие.  \n",
       "3          37                                 В деле не пробовал  \n",
       "4          20                               Буду заказывать ещё.  \n",
       "5          13                                        Еле пахнет.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pyarrow.parquet as pq\n",
    "import dask.dataframe as dd\n",
    "import spacy\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, BertTokenizerFast, BertForSequenceClassification, BertConfig\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, Dataset as TorchDataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import hdbscan\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import logging\n",
    "import re\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "class ReviewsKeywords:\n",
    "    def __init__(self, csv_path, model_path, spacy_model=\"ru_core_news_lg\"):\n",
    "        self.csv_path = csv_path\n",
    "        self.model_path = model_path\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if self.device == \"cuda\":\n",
    "            import cudf.pandas  # Импортирование cuDF и активация его использования\n",
    "            cudf.pandas.install()\n",
    "        os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"  # Включаем параллелизм токенизатора для ускорения\n",
    "        self.tokenizer_my = BertTokenizerFast.from_pretrained(self.model_path)\n",
    "         # Загрузка модели для классификации\n",
    "        self.classification_model = BertForSequenceClassification.from_pretrained(self.model_path).to(self.device)\n",
    "        # Загрузка базовой модели для получения эмбеддингов\n",
    "        self.embedding_model = AutoModel.from_pretrained(self.model_path).to(self.device)\n",
    "        \n",
    "        # Загрузка модели и токенайзера от Сбербанка\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('sberbank-ai/sbert_large_nlu_ru')\n",
    "        self.embedding_model = AutoModel.from_pretrained('sberbank-ai/sbert_large_nlu_ru').to(self.device)\n",
    "        \n",
    "        spacy.prefer_gpu()\n",
    "        self.nlp = spacy.load(spacy_model, disable=[\"ner\", \"tagger\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "        \n",
    "        self.df = pd.read_csv(self.csv_path, nrows=1000)\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text):\n",
    "        text = re.sub(r'[\\n\\r\\t]+|\\s{2,}', ' ', text)\n",
    "        text = re.sub(r'(?<!\\.)\\s*\\.\\s*|\\s*\\.\\s*(?!\\.)', '. ', text)\n",
    "        return text.strip().rstrip('.')\n",
    "\n",
    "    def split_reviews_into_sentences(self, batch):\n",
    "        cleaned_texts = [self.clean_text(text) for text in batch['corrected_text']]\n",
    "        docs = list(self.nlp.pipe(cleaned_texts, batch_size=64))\n",
    "        batch['sentences'] = [[sent.text for sent in doc.sents] for doc in docs]\n",
    "        return batch\n",
    "\n",
    "    def process_reviews(self):\n",
    "        dataset = Dataset.from_pandas(self.df)\n",
    "        dataset = dataset.map(self.split_reviews_into_sentences, batched=True, batch_size=32)\n",
    "        self.df = dataset.to_pandas()\n",
    "        df_exploded = self.df.explode('sentences').reset_index(drop=True)\n",
    "        df_exploded = df_exploded.drop(columns=[col for col in df_exploded.columns if col.startswith('__index_level_')])\n",
    "        return Dataset.from_pandas(df_exploded)\n",
    "\n",
    "    def compute_sentence_embeddings(self, sentences):\n",
    "        sentences = [str(sentence) for sentence in sentences if isinstance(sentence, str)]\n",
    "        if not sentences:\n",
    "            raise ValueError(\"Input contains no valid strings.\")\n",
    "        inputs = self.tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.embedding_model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "    def compute_embeddings_after_explode(self, batch):\n",
    "        sentences = batch['sentences']\n",
    "        valid_sentences = [str(sentence) for sentence in sentences if isinstance(sentence, str)]\n",
    "        if not valid_sentences:\n",
    "            batch['sentence_embeddings'] = [[]] * len(sentences)\n",
    "            return batch\n",
    "        embeddings = self.compute_sentence_embeddings(valid_sentences)\n",
    "        embeddings = embeddings.astype(np.float32)\n",
    "        final_embeddings = []\n",
    "        embed_idx = 0\n",
    "        for sentence in sentences:\n",
    "            if isinstance(sentence, str):\n",
    "                final_embeddings.append(embeddings[embed_idx])\n",
    "                embed_idx += 1\n",
    "            else:\n",
    "                final_embeddings.append(np.zeros(embeddings.shape[1], dtype=np.float32))\n",
    "        batch['sentence_embeddings'] = final_embeddings\n",
    "        return batch\n",
    "\n",
    "    def apply_embeddings(self, dataset_exploded):\n",
    "        return dataset_exploded.map(self.compute_embeddings_after_explode, batched=True, batch_size=128)\n",
    "\n",
    "    def extract_key_thought(self, cluster_sentences):\n",
    "        sentences = cluster_sentences.split(\" | \")\n",
    "        embeddings = self.compute_sentence_embeddings(sentences)\n",
    "        centroid = np.mean(embeddings, axis=0)\n",
    "        similarities = cosine_similarity(embeddings, [centroid])\n",
    "        key_sentence_index = np.argmax(similarities)\n",
    "        return sentences[key_sentence_index]\n",
    "\n",
    "    def count_words(self, cluster_sentences):\n",
    "        words = cluster_sentences.split()\n",
    "        return len(words)\n",
    "\n",
    "    def recluster_large_cluster(self, cluster_sentences, eps=0.1, min_samples=2):\n",
    "        sentences = cluster_sentences.split(\" | \")\n",
    "        embeddings = self.compute_sentence_embeddings(sentences)\n",
    "        re_clustering = DBSCAN(eps=eps, min_samples=min_samples, metric=\"cosine\").fit(embeddings)\n",
    "        re_cluster_dict = {}\n",
    "        for idx, label in enumerate(re_clustering.labels_):\n",
    "            if label == -1:\n",
    "                continue\n",
    "            label_str = str(label)\n",
    "            if label_str not in re_cluster_dict:\n",
    "                re_cluster_dict[label_str] = []\n",
    "            re_cluster_dict[label_str].append(sentences[idx])\n",
    "        return [\" | \".join(cluster) for cluster in re_cluster_dict.values()]\n",
    "\n",
    "    def recursive_clustering(self, cluster_sentences, threshold, eps=0.22, min_samples=3, min_eps=0.02):\n",
    "        current_eps = eps\n",
    "        current_min_samples = min_samples\n",
    "        new_clusters = [cluster_sentences]\n",
    "        while True:\n",
    "            next_clusters = []\n",
    "            reclustered_any = False\n",
    "            for cluster in new_clusters:\n",
    "                if self.count_words(cluster) > threshold:\n",
    "                    while current_eps >= min_eps:\n",
    "                        reclustered = self.recluster_large_cluster(cluster, eps=current_eps, min_samples=current_min_samples)\n",
    "                        if len(reclustered) > 1:\n",
    "                            next_clusters.extend(reclustered)\n",
    "                            reclustered_any = True\n",
    "                            break\n",
    "                        else:\n",
    "                            if current_eps > min_eps:\n",
    "                                current_eps -= 0.05\n",
    "                    if len(reclustered) == 1:\n",
    "                        next_clusters.append(cluster)\n",
    "                else:\n",
    "                    next_clusters.append(cluster)\n",
    "            new_clusters = next_clusters\n",
    "            if not reclustered_any:\n",
    "                break\n",
    "        return new_clusters\n",
    "\n",
    "    def generate_predictions(self, dataset_exploded):\n",
    "        tokenizer = self.tokenizer_my\n",
    "        model = self.classification_model\n",
    "        if self.device == torch.device(\"cuda\"):\n",
    "            model = model.half()\n",
    "\n",
    "        reviews = dataset_exploded[\"sentences\"]\n",
    "        reviews = [str(review) for review in reviews if isinstance(review, str) and review.strip()]\n",
    "\n",
    "        class ReviewDataset(TorchDataset):\n",
    "            def __init__(self, reviews, tokenizer, max_len=128):\n",
    "                self.reviews = reviews\n",
    "                self.tokenizer = tokenizer\n",
    "                self.max_len = max_len\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.reviews)\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                review = self.reviews[idx]\n",
    "                encoding = self.tokenizer.encode_plus(\n",
    "                    review,\n",
    "                    add_special_tokens=True,\n",
    "                    max_length=self.max_len,\n",
    "                    return_token_type_ids=False,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_attention_mask=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                return {key: val.flatten() for key, val in encoding.items()}\n",
    "\n",
    "        dataset = ReviewDataset(reviews, tokenizer)\n",
    "        batch_size = 32\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        from torch.cuda.amp import autocast\n",
    "\n",
    "        for batch in tqdm(dataloader, desc=\"Предсказание отзывов\"):\n",
    "            batch = {key: val.to(self.device) for key, val in batch.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                with autocast():  # Используем смешанную точность\n",
    "                    outputs = model(**batch)\n",
    "                    logits = outputs[0] if isinstance(outputs, tuple) else outputs.logits\n",
    "                    probabilities = torch.softmax(logits, dim=-1)\n",
    "                    batch_predictions = (probabilities[:, 1] > 0.7).cpu().numpy()  # Используем порог 0.7\n",
    "                    predictions.extend(batch_predictions)\n",
    "\n",
    "        if len(predictions) != len(dataset_exploded):\n",
    "            print(f\"Warning: Length of predictions ({len(predictions)}) does not match length of index ({len(dataset_exploded)})\")\n",
    "            if len(predictions) < len(dataset_exploded):\n",
    "                missing_count = len(dataset_exploded) - len(predictions)\n",
    "                predictions.extend([0] * missing_count)\n",
    "            elif len(predictions) > len(dataset_exploded):\n",
    "                predictions = predictions[:len(dataset_exploded)]\n",
    "        dataset_exploded = dataset_exploded.add_column(\"predictions\", predictions)\n",
    "        return dataset_exploded\n",
    "\n",
    "    def process_group(self, category_name, product_name, group):\n",
    "        all_sentences = group['sentences'].tolist()\n",
    "        if not all_sentences:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        try:\n",
    "            all_embeddings = self.compute_sentence_embeddings(all_sentences)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in computing embeddings for product {product_name}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        distance_matrix = squareform(pdist(all_embeddings, metric='cosine'))\n",
    "        clustering = hdbscan.HDBSCAN(min_samples=3, metric='precomputed').fit(distance_matrix)\n",
    "\n",
    "        cluster_dict = {}\n",
    "        for idx, label in enumerate(clustering.labels_):\n",
    "            if label == -1:\n",
    "                continue\n",
    "            label_str = str(label)\n",
    "            if label_str not in cluster_dict:\n",
    "                cluster_dict[label_str] = set()\n",
    "            cluster_dict[label_str].add(all_sentences[idx])\n",
    "\n",
    "        clusters = [\" | \".join(sentences) for sentences in cluster_dict.values()]\n",
    "\n",
    "        if not clusters:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        group['binary_rating'] = group['review_rating'].apply(lambda x: 1 if x in [4, 5] else 0)\n",
    "        avg_rating = group['binary_rating'].mean()\n",
    "        rating_category = 'positive' if avg_rating > 0.7 else 'neutral'\n",
    "        rating_category = 'neutral' if avg_rating > 0.5 else 'negative'\n",
    "\n",
    "        threshold = self.determine_threshold(clusters)\n",
    "\n",
    "        final_clusters = []\n",
    "        for cluster in clusters:\n",
    "            if self.count_words(cluster) > threshold:\n",
    "                final_clusters.extend(self.recursive_clustering(cluster, threshold))\n",
    "            else:\n",
    "                final_clusters.append(cluster)\n",
    "\n",
    "        # Обеспечение минимального количества кластеров\n",
    "        final_clusters = self.ensure_minimum_clusters(final_clusters, threshold)\n",
    "\n",
    "        df_exploded_sorted = pd.DataFrame({\n",
    "            'category': category_name,\n",
    "            'product': product_name,\n",
    "            'avg_rating': avg_rating,\n",
    "            'rating_category': rating_category,\n",
    "            'cluster_sentences': final_clusters\n",
    "        })\n",
    "        df_exploded_sorted['word_count'] = df_exploded_sorted['cluster_sentences'].apply(self.count_words)\n",
    "        df_exploded_sorted['key_thought'] = df_exploded_sorted['cluster_sentences'].apply(self.extract_key_thought)\n",
    "        df_exploded_sorted = df_exploded_sorted.sort_values(by='word_count', ascending=False)\n",
    "\n",
    "        return df_exploded_sorted\n",
    "\n",
    "    def determine_threshold(self, clusters):\n",
    "        if len(clusters) == 1:\n",
    "            cluster_word_count = self.count_words(clusters[0])\n",
    "            if cluster_word_count > 20:\n",
    "                return cluster_word_count / 2\n",
    "            return cluster_word_count\n",
    "        return np.min([np.mean([self.count_words(cluster) for cluster in clusters]) * 1.5, 250])\n",
    "\n",
    "    def ensure_minimum_clusters(self, final_clusters, threshold):\n",
    "        while len(final_clusters) < 3 and any(self.count_words(cluster) > threshold for cluster in final_clusters):\n",
    "            largest_cluster = max(final_clusters, key=self.count_words)\n",
    "            final_clusters.remove(largest_cluster)\n",
    "            new_clusters = self.recursive_clustering(largest_cluster, threshold)\n",
    "            if len(new_clusters) <= 1:\n",
    "                final_clusters.append(largest_cluster)\n",
    "                break\n",
    "            final_clusters.extend(new_clusters)\n",
    "        return final_clusters\n",
    "    \n",
    "    def cluster_reviews(self, dataset_exploded):\n",
    "        # Фильтрация на основе предсказаний\n",
    "        dataset_filtered = dataset_exploded.filter(lambda x: x['predictions'] == 1)\n",
    "        \n",
    "        # Преобразование в pandas DataFrame для группировки\n",
    "        df_filtered = dataset_filtered.to_pandas()\n",
    "        grouped = df_filtered.groupby(['category', 'product'])\n",
    "\n",
    "        results = []\n",
    "        \n",
    "        # Последовательная обработка без параллелизма\n",
    "        for (category_name, product_name), group in tqdm(grouped, desc=\"Processing categories and products\"):\n",
    "            result_df = self.process_group(category_name, product_name, group)\n",
    "            if not result_df.empty:\n",
    "                results.append(result_df)\n",
    "\n",
    "        if results:  # Проверяем, что список results не пуст\n",
    "            final_result = pd.concat(results, ignore_index=True)\n",
    "            final_result = final_result[((final_result['word_count'] > 10) & (final_result['key_thought'].str.len() > 5))]\n",
    "            final_result.to_csv(\"./reviews_keywords/feedbackfueltest.csv\")\n",
    "        else:\n",
    "            print(\"No valid results to concatenate. Returning an empty DataFrame.\")\n",
    "            final_result = pd.DataFrame()  # Возвращаем пустой DataFrame, если нет данных для объединения\n",
    "        \n",
    "        return final_result\n",
    "\n",
    "    def run(self):\n",
    "        dataset_exploded = self.process_reviews()\n",
    "        dataset_exploded = self.apply_embeddings(dataset_exploded)\n",
    "        dataset_exploded = self.generate_predictions(dataset_exploded)\n",
    "        result = self.cluster_reviews(dataset_exploded)\n",
    "        return result\n",
    "\n",
    "\n",
    "reviews_keywords = ReviewsKeywords(csv_path=\"./reviews_keywords/wildberries_reviews.csv\",\n",
    "                                    model_path='./reviews_keywords/fine_tuned_model')\n",
    "final_result = reviews_keywords.run()\n",
    "final_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>word_count</th>\n",
       "      <th>key_thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВПМ / Антибукс - антипробуксовочные траки утол...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Переднее колесо закрылось в снегу, подложили п...</td>\n",
       "      <td>40</td>\n",
       "      <td>Переднее колесо закрылось в снегу, подложили п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВПМ / Антибукс - антипробуксовочные траки утол...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>На вид крепкие. | Вроде прочные. | На вид проч...</td>\n",
       "      <td>12</td>\n",
       "      <td>На вид крепкие.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>neutral</td>\n",
       "      <td>В деле не пробовал | В деле пока не пробовала....</td>\n",
       "      <td>37</td>\n",
       "      <td>В деле не пробовал</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>Пахнет и Точка / Ароматизатор в машину автопар...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Рекомендую, буду брать еще | Закажу | мыМыочно...</td>\n",
       "      <td>20</td>\n",
       "      <td>Буду заказывать ещё.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>Пахнет и Точка / Ароматизатор в машину автопар...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Еле пахнет. | Он даже не пахнет. | Пахнет каки...</td>\n",
       "      <td>13</td>\n",
       "      <td>Еле пахнет.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>Пахнет и Точка / Ароматизатор в машину автопар...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>🔥🔥🔥🔥🔥🔥 запах. | Запах огонь) | Запах огонь!!!!...</td>\n",
       "      <td>11</td>\n",
       "      <td>Запах 🔥!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Убирает ржавчину хорошо через 10-20 минут | Со...</td>\n",
       "      <td>76</td>\n",
       "      <td>Ржавчину убирает отлично.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Ржавчина уже хорошо въелась, пришлось нескольк...</td>\n",
       "      <td>38</td>\n",
       "      <td>Ржавчина уже хорошо въелась, пришлось нескольк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Фото «до» к сожалению не сделала, только «посл...</td>\n",
       "      <td>24</td>\n",
       "      <td>Фото «до» к сожалению не сделала, только «после»</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>В деле пока не пробовала. | В деле не пробовал...</td>\n",
       "      <td>14</td>\n",
       "      <td>В деле не пробовал</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 category  \\\n",
       "0                     /Автотовары/OFFroad   \n",
       "1                     /Автотовары/OFFroad   \n",
       "3                     /Автотовары/OFFroad   \n",
       "4   /Автотовары/Автокосметика и автохимия   \n",
       "5   /Автотовары/Автокосметика и автохимия   \n",
       "6   /Автотовары/Автокосметика и автохимия   \n",
       "7   /Автотовары/Автокосметика и автохимия   \n",
       "8   /Автотовары/Автокосметика и автохимия   \n",
       "9   /Автотовары/Автокосметика и автохимия   \n",
       "10  /Автотовары/Автокосметика и автохимия   \n",
       "\n",
       "                                              product  avg_rating  \\\n",
       "0   ВПМ / Антибукс - антипробуксовочные траки утол...    0.819588   \n",
       "1   ВПМ / Антибукс - антипробуксовочные траки утол...    0.819588   \n",
       "3   ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...    0.842975   \n",
       "4   Пахнет и Точка / Ароматизатор в машину автопар...    0.704545   \n",
       "5   Пахнет и Точка / Ароматизатор в машину автопар...    0.704545   \n",
       "6   Пахнет и Точка / Ароматизатор в машину автопар...    0.704545   \n",
       "7   ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "8   ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "9   ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "10  ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "\n",
       "   rating_category                                  cluster_sentences  \\\n",
       "0          neutral  Переднее колесо закрылось в снегу, подложили п...   \n",
       "1          neutral  На вид крепкие. | Вроде прочные. | На вид проч...   \n",
       "3          neutral  В деле не пробовал | В деле пока не пробовала....   \n",
       "4          neutral  Рекомендую, буду брать еще | Закажу | мыМыочно...   \n",
       "5          neutral  Еле пахнет. | Он даже не пахнет. | Пахнет каки...   \n",
       "6          neutral  🔥🔥🔥🔥🔥🔥 запах. | Запах огонь) | Запах огонь!!!!...   \n",
       "7          neutral  Убирает ржавчину хорошо через 10-20 минут | Со...   \n",
       "8          neutral  Ржавчина уже хорошо въелась, пришлось нескольк...   \n",
       "9          neutral  Фото «до» к сожалению не сделала, только «посл...   \n",
       "10         neutral  В деле пока не пробовала. | В деле не пробовал...   \n",
       "\n",
       "    word_count                                        key_thought  \n",
       "0           40  Переднее колесо закрылось в снегу, подложили п...  \n",
       "1           12                                    На вид крепкие.  \n",
       "3           37                                 В деле не пробовал  \n",
       "4           20                               Буду заказывать ещё.  \n",
       "5           13                                        Еле пахнет.  \n",
       "6           11                                         Запах 🔥!!!  \n",
       "7           76                          Ржавчину убирает отлично.  \n",
       "8           38  Ржавчина уже хорошо въелась, пришлось нескольк...  \n",
       "9           24   Фото «до» к сожалению не сделала, только «после»  \n",
       "10          14                                 В деле не пробовал  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>word_count</th>\n",
       "      <th>key_thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Спорт/Страйкбол и пейнтбол/Аксессуары</td>\n",
       "      <td>karbi / Рюкзак тактический туристический - кар...</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Много доп карманов, чехол от дождя, прорезинен...</td>\n",
       "      <td>203</td>\n",
       "      <td>Рюкзак вместительный, прочный, есть защитный ч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Спорт/Страйкбол и пейнтбол/Аксессуары</td>\n",
       "      <td>karbi / Рюкзак тактический туристический - кар...</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>neutral</td>\n",
       "      <td>В подарок шёл компас,, налобныйфонарь,, ножане...</td>\n",
       "      <td>69</td>\n",
       "      <td>В подарок положили фонарик налобный, компас и ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 category  \\\n",
       "0  /Спорт/Страйкбол и пейнтбол/Аксессуары   \n",
       "1  /Спорт/Страйкбол и пейнтбол/Аксессуары   \n",
       "\n",
       "                                             product  avg_rating  \\\n",
       "0  karbi / Рюкзак тактический туристический - кар...    0.797101   \n",
       "1  karbi / Рюкзак тактический туристический - кар...    0.797101   \n",
       "\n",
       "  rating_category                                  cluster_sentences  \\\n",
       "0         neutral  Много доп карманов, чехол от дождя, прорезинен...   \n",
       "1         neutral  В подарок шёл компас,, налобныйфонарь,, ножане...   \n",
       "\n",
       "   word_count                                        key_thought  \n",
       "0         203  Рюкзак вместительный, прочный, есть защитный ч...  \n",
       "1          69  В подарок положили фонарик налобный, компас и ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf.pandas  # Импортирование cuDF и активация его использования\n",
    "cudf.pandas.install()  # Установка cuDF как основного интерфейса для pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pyarrow.parquet as pq\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# # Чтение Parquet-файла с использованием pyarrow\n",
    "# table = pq.read_table('./reviews_keywords/wildberries_reviews_corrected.parquet')\n",
    "\n",
    "# # Преобразование в pandas DataFrame\n",
    "# df_pandas = table.to_pandas()\n",
    "\n",
    "# # Преобразование pandas DataFrame в Dask DataFrame\n",
    "# df_dask = dd.from_pandas(df_pandas, npartitions=100)  # Укажите количество нужных вам частей\n",
    "# df_pandas = None\n",
    "# table = None\n",
    "# import gc\n",
    "# gc.collect()\n",
    "# df_dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype\n",
      "---  ------            --------------  -----\n",
      " 0   Unnamed: 0        1000 non-null   int64\n",
      " 1   review_full_text  1000 non-null   object\n",
      " 2   review_rating     1000 non-null   int64\n",
      " 3   product           1000 non-null   object\n",
      " 4   category          1000 non-null   object\n",
      " 5   url               1000 non-null   object\n",
      " 6   corrected_text    1000 non-null   object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 540.9+ KB\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv(\"./reviews_keywords/wildberries_reviews.csv\", nrows=1000)\n",
    "result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оставляем только по 5 записей для каждого уникального значения в столбце 'product'\n",
    "# result_limited = result.groupby('product').apply(lambda x: x.iloc[5:8]).reset_index(drop=True)\n",
    "result_limited = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, BertTokenizerFast\n",
    "import torch\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Проверка доступности GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import DBSCAN\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, BertConfig\n",
    "import hdbscan\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Загрузка дообученной модели и токенизатора\n",
    "# Загружаем конфигурацию модели\n",
    "\n",
    "\n",
    "# Загрузка модели и токенайзера от Сбербанка\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"./reviews_keywords/fine_tuned_model\")\n",
    "model = AutoModel.from_pretrained(\"./reviews_keywords/fine_tuned_model\").to(device)\n",
    "# Инициализируем модель с конфигурацией\n",
    "config = BertConfig.from_pretrained('./reviews_keywords/fine_tuned_model', output_hidden_states=True)\n",
    "model_classification = BertForSequenceClassification.from_pretrained('./reviews_keywords/fine_tuned_model', config=config).to(device)\n",
    "\n",
    "        # self.tokenizer_my = BertTokenizerFast.from_pretrained(self.model_path)\n",
    "        #  # Загрузка модели для классификации\n",
    "        # self.classification_model = BertForSequenceClassification.from_pretrained(self.model_path).to(self.device)\n",
    "        # # Загрузка базовой модели для получения эмбеддингов\n",
    "        # self.embedding_model = AutoModel.from_pretrained(self.model_path).to(self.device)\n",
    "\n",
    "spacy.prefer_gpu()\n",
    "# Загрузка и настройка модели SpaCy\n",
    "nlp = spacy.load(\"ru_core_news_lg\", disable=[\"ner\", \"tagger\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "\n",
    "df = result_limited\n",
    "\n",
    "# Преобразование pandas DataFrame в Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837a44705b1d44828df1a47b43273697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629350b5326d44b08abba9becf88c64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2061 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[\\n\\r\\t]+|\\s{2,}', ' ', text)  # Объединяем шаги для замены пробелов\n",
    "    text = re.sub(r'(?<!\\.)\\s*\\.\\s*|\\s*\\.\\s*(?!\\.)', '. ', text)  # Оптимизация замены точки\n",
    "    return text.strip().rstrip('.')\n",
    "\n",
    "def split_reviews_into_sentences(batch):\n",
    "    # Очистка текстов\n",
    "    cleaned_texts = [clean_text(text) for text in batch['corrected_text']]\n",
    "    \n",
    "    # Обработка текстов с помощью nlp.pipe с указанием batch_size\n",
    "    docs = list(nlp.pipe(cleaned_texts, batch_size=64))  # Здесь 64 - пример значения\n",
    "\n",
    "    # Извлечение предложений\n",
    "    batch['sentences'] = [[sent.text for sent in doc.sents] for doc in docs]\n",
    "    \n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(split_reviews_into_sentences, batched=True, batch_size=32)\n",
    "\n",
    "# Преобразуем Dataset обратно в pandas DataFrame\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "# Выполним explode по столбцу с предложениями\n",
    "df_exploded = df.explode('sentences').reset_index(drop=True)\n",
    "\n",
    "# Удаляем лишние столбцы, которые появились после explode\n",
    "df_exploded = df_exploded.drop(columns=[col for col in df_exploded.columns if col.startswith('__index_level_')])\n",
    "\n",
    "# Преобразуем DataFrame обратно в Hugging Face Dataset\n",
    "dataset_exploded = Dataset.from_pandas(df_exploded)\n",
    "\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "def compute_sentence_embeddings(sentences):\n",
    "    # Фильтруем список, оставляя только строки\n",
    "    sentences = [str(sentence) for sentence in sentences if isinstance(sentence, str)]\n",
    "    \n",
    "    if not sentences:\n",
    "        raise ValueError(\"Input contains no valid strings.\")\n",
    "\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with autocast():  # Используем mixed precision для ускорения\n",
    "            outputs = model_classification(**inputs)\n",
    "    \n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "def compute_embeddings_after_explode(batch):\n",
    "    sentences = batch['sentences']\n",
    "\n",
    "    # Проверяем, что все элементы в batch являются строками\n",
    "    valid_sentences = [str(sentence) for sentence in sentences if isinstance(sentence, str)]\n",
    "    \n",
    "    if not valid_sentences:\n",
    "        batch['sentence_embeddings'] = [[]] * len(sentences)  # Если нет валидных предложений, возвращаем пустые эмбеддинги\n",
    "        return batch\n",
    "\n",
    "    embeddings = compute_sentence_embeddings(valid_sentences)\n",
    "\n",
    "    # Приведение эмбеддингов к типу float32 для консистентности\n",
    "    embeddings = embeddings.astype(np.float32)\n",
    "\n",
    "    # Проверяем, что количество эмбеддингов совпадает с количеством предложений\n",
    "    if len(embeddings) != len(valid_sentences):\n",
    "        raise ValueError(\"Количество эмбеддингов не совпадает с количеством предложений.\")\n",
    "    \n",
    "    # Если количество предложений после фильтрации не совпадает с исходным, корректируем выходные данные\n",
    "    final_embeddings = []\n",
    "    embed_idx = 0\n",
    "    for sentence in sentences:\n",
    "        if isinstance(sentence, str):\n",
    "            final_embeddings.append(embeddings[embed_idx])\n",
    "            embed_idx += 1\n",
    "        else:\n",
    "            final_embeddings.append(np.zeros(embeddings.shape[1], dtype=np.float32))  # Добавляем нулевые эмбеддинги для невалидных предложений\n",
    "\n",
    "    batch['sentence_embeddings'] = final_embeddings\n",
    "    return batch\n",
    "\n",
    "# Применение функции\n",
    "dataset = dataset_exploded.map(compute_embeddings_after_explode, batched=True, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, BertConfig\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import hdbscan  # HDBSCAN для более стабильной кластеризации с поддержкой кастомных метрик\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Предсказание отзывов:   0%|                                                                                                                                                                        | 0/65 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Предсказание отзывов: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 65/65 [00:11<00:00,  5.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_full_text</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "      <th>corrected_text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Работает хорошо.</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 3000lb 13...</td>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>Работает хорошо.</td>\n",
       "      <td>Работает хорошо</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Пришло быстро, все целое на вид. Завтра буду и...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 3000lb 13...</td>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>Пришло быстро, все целое на вид. Завтра буду и...</td>\n",
       "      <td>Пришло быстро, все целое на вид.</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Пришло быстро, все целое на вид. Завтра буду и...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 3000lb 13...</td>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>Пришло быстро, все целое на вид. Завтра буду и...</td>\n",
       "      <td>Завтра буду испытывать</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Купил на квадр для поднятия отвала, установка ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 3000lb 13...</td>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>Купил на квадр для поднятия отвала, установка ...</td>\n",
       "      <td>Купил на квадр для поднятия отвала, установка ...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Лебёдка хорошая. Но в инструкции ни слова про ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 3000lb 13...</td>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>Лебёдка хорошая. Но в инструкции ни слова про ...</td>\n",
       "      <td>Лебёдка хорошая.</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                   review_full_text  \\\n",
       "0           0                                   Работает хорошо.   \n",
       "1           1  Пришло быстро, все целое на вид. Завтра буду и...   \n",
       "2           1  Пришло быстро, все целое на вид. Завтра буду и...   \n",
       "3           2  Купил на квадр для поднятия отвала, установка ...   \n",
       "4           3  Лебёдка хорошая. Но в инструкции ни слова про ...   \n",
       "\n",
       "   review_rating                                            product  \\\n",
       "0              5  Shtapler / Лебедка электрическая 12v 3000lb 13...   \n",
       "1              5  Shtapler / Лебедка электрическая 12v 3000lb 13...   \n",
       "2              5  Shtapler / Лебедка электрическая 12v 3000lb 13...   \n",
       "3              5  Shtapler / Лебедка электрическая 12v 3000lb 13...   \n",
       "4              5  Shtapler / Лебедка электрическая 12v 3000lb 13...   \n",
       "\n",
       "              category                                                url  \\\n",
       "0  /Автотовары/OFFroad  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "1  /Автотовары/OFFroad  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "2  /Автотовары/OFFroad  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "3  /Автотовары/OFFroad  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "4  /Автотовары/OFFroad  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "\n",
       "                                      corrected_text  \\\n",
       "0                                   Работает хорошо.   \n",
       "1  Пришло быстро, все целое на вид. Завтра буду и...   \n",
       "2  Пришло быстро, все целое на вид. Завтра буду и...   \n",
       "3  Купил на квадр для поднятия отвала, установка ...   \n",
       "4  Лебёдка хорошая. Но в инструкции ни слова про ...   \n",
       "\n",
       "                                           sentences  __index_level_0__  \\\n",
       "0                                    Работает хорошо                  0   \n",
       "1                   Пришло быстро, все целое на вид.                  1   \n",
       "2                             Завтра буду испытывать                  2   \n",
       "3  Купил на квадр для поднятия отвала, установка ...                  3   \n",
       "4                                   Лебёдка хорошая.                  4   \n",
       "\n",
       "   predictions  \n",
       "0        False  \n",
       "1        False  \n",
       "2         True  \n",
       "3         True  \n",
       "4         True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Определение устройства (GPU или CPU)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Перевод модели в режим FP16, если это возможно\n",
    "if use_cuda:\n",
    "    model_classification = model_classification.half()\n",
    "\n",
    "# Пример данных (замените на реальные данные)\n",
    "reviews = dataset_exploded[\"sentences\"]\n",
    "\n",
    "# Очистка данных от некорректных значений\n",
    "reviews = [str(review) for review in reviews if isinstance(review, str) and review.strip()]\n",
    "\n",
    "# Создание кастомного Dataset для обработки отзывов\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, tokenizer, max_len=128):\n",
    "        self.reviews = reviews\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = self.reviews[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {key: val.flatten() for key, val in encoding.items()}\n",
    "\n",
    "# Создаем датасет и DataLoader\n",
    "dataset = ReviewDataset(reviews, tokenizer)\n",
    "batch_size = 32  # Размер батча можно изменить в зависимости от объема доступной памяти GPU\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Получение предсказаний с отображением прогресса\n",
    "predictions = []\n",
    "\n",
    "from torch.cuda.amp import autocast  # Импортируем autocast для смешанной точности\n",
    "\n",
    "for batch in tqdm(dataloader, desc=\"Предсказание отзывов\"):\n",
    "    batch = {key: val.to(device) for key, val in batch.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with autocast():  # Используем смешанную точность\n",
    "            outputs = model_classification(**batch)\n",
    "            logits = outputs[0] if isinstance(outputs, tuple) else outputs.logits\n",
    "            probabilities = torch.softmax(logits, dim=-1)\n",
    "            batch_predictions = (probabilities[:, 1] > 0.7).cpu().numpy()  # Используем порог 0.7\n",
    "            predictions.extend(batch_predictions)\n",
    "\n",
    "# Преобразование в DataFrame, если это еще не сделано\n",
    "if not isinstance(dataset_exploded, pd.DataFrame):\n",
    "    dataset_exploded = pd.DataFrame(dataset_exploded)\n",
    "\n",
    "# Проверка и обработка несоответствия длины\n",
    "if len(predictions) != len(dataset_exploded):\n",
    "    print(f\"Warning: Length of predictions ({len(predictions)}) does not match length of index ({len(dataset_exploded)})\")\n",
    "    \n",
    "    # Пример: Заполнение недостающих значений\n",
    "    if len(predictions) < len(dataset_exploded):\n",
    "        missing_count = len(dataset_exploded) - len(predictions)\n",
    "        predictions.extend([0] * missing_count)  # Добавляем нули в случае недостатка предсказаний\n",
    "\n",
    "    elif len(predictions) > len(dataset_exploded):\n",
    "        predictions = predictions[:len(dataset_exploded)]  # Обрезаем список предсказаний\n",
    "\n",
    "# Присоединение предсказаний к датасету\n",
    "dataset_exploded['predictions'] = predictions\n",
    "dataset_exploded.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Настройка логирования\n",
    "logging.basicConfig(filename='./reviews_keywords/clustering.log', \n",
    "                    level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Загрузка модели spaCy для русского языка\n",
    "nlp = spacy.load(\"ru_core_news_lg\")\n",
    "\n",
    "# Установка стоп-слов\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories and products: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:07<00:00,  2.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>key_thought</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВПМ / Антибукс - антипробуксовочные траки утол...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Не вставать сзади, когда машина начинает движе...</td>\n",
       "      <td>Хороши когда нужно \"выскочить\" из снежного мес...</td>\n",
       "      <td>1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВПМ / Антибукс - антипробуксовочные траки утол...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Хорошие траки, на ощупь достаточно прочные | О...</td>\n",
       "      <td>Хорошие траки, на ощупь достаточно прочные</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВПМ / Антибукс - антипробуксовочные траки утол...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Вроде прочные. | На вид крепкие. | На вид проч...</td>\n",
       "      <td>На вид крепкие.</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВПМ / Антибукс - антипробуксовочные траки утол...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>.. | . | (так сказал). | (</td>\n",
       "      <td>..</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Иногда их выбрасывало из-под колес. | Хватало ...</td>\n",
       "      <td>Не выручать даже летом, чуток сел в небольшую ...</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>neutral</td>\n",
       "      <td>В деле не пробовал | Траки мощные, в деле ещё ...</td>\n",
       "      <td>В деле пока не пробовала.</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>Пахнет и Точка / Ароматизатор в машину автопар...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Посмотрим на сколько хватит! | Посмотри и на к...</td>\n",
       "      <td>Посмотрим на сколько хватит</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>Пахнет и Точка / Ароматизатор в машину автопар...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>мыМыочно будем заказывать ещё! | Закажу еще не...</td>\n",
       "      <td>Буду заказывать ещё.</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>Пахнет и Точка / Ароматизатор в машину автопар...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>.. | д…. | .</td>\n",
       "      <td>..</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Фото «до» к сожалению не сделала, только «посл...</td>\n",
       "      <td>Фото «до» к сожалению не сделала, только «после»</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Обработал глушитель на авто, даже заводская кр...</td>\n",
       "      <td>Удалял \"жучки\" на дверях авто.</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>В деле пока не пробовала. | В деле не пробовал...</td>\n",
       "      <td>В деле пока не пробовала.</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>.. | ...</td>\n",
       "      <td>..</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 category  \\\n",
       "0                     /Автотовары/OFFroad   \n",
       "1                     /Автотовары/OFFroad   \n",
       "2                     /Автотовары/OFFroad   \n",
       "3                     /Автотовары/OFFroad   \n",
       "4                     /Автотовары/OFFroad   \n",
       "5                     /Автотовары/OFFroad   \n",
       "6   /Автотовары/Автокосметика и автохимия   \n",
       "7   /Автотовары/Автокосметика и автохимия   \n",
       "8   /Автотовары/Автокосметика и автохимия   \n",
       "9   /Автотовары/Автокосметика и автохимия   \n",
       "10  /Автотовары/Автокосметика и автохимия   \n",
       "11  /Автотовары/Автокосметика и автохимия   \n",
       "12  /Автотовары/Автокосметика и автохимия   \n",
       "\n",
       "                                              product  avg_rating  \\\n",
       "0   ВПМ / Антибукс - антипробуксовочные траки утол...    0.819588   \n",
       "1   ВПМ / Антибукс - антипробуксовочные траки утол...    0.819588   \n",
       "2   ВПМ / Антибукс - антипробуксовочные траки утол...    0.819588   \n",
       "3   ВПМ / Антибукс - антипробуксовочные траки утол...    0.819588   \n",
       "4   ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...    0.842975   \n",
       "5   ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...    0.842975   \n",
       "6   Пахнет и Точка / Ароматизатор в машину автопар...    0.704545   \n",
       "7   Пахнет и Точка / Ароматизатор в машину автопар...    0.704545   \n",
       "8   Пахнет и Точка / Ароматизатор в машину автопар...    0.704545   \n",
       "9   ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "10  ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "11  ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "12  ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "\n",
       "   rating_category                                  cluster_sentences  \\\n",
       "0          neutral  Не вставать сзади, когда машина начинает движе...   \n",
       "1          neutral  Хорошие траки, на ощупь достаточно прочные | О...   \n",
       "2          neutral  Вроде прочные. | На вид крепкие. | На вид проч...   \n",
       "3          neutral                         .. | . | (так сказал). | (   \n",
       "4          neutral  Иногда их выбрасывало из-под колес. | Хватало ...   \n",
       "5          neutral  В деле не пробовал | Траки мощные, в деле ещё ...   \n",
       "6          neutral  Посмотрим на сколько хватит! | Посмотри и на к...   \n",
       "7          neutral  мыМыочно будем заказывать ещё! | Закажу еще не...   \n",
       "8          neutral                                       .. | д…. | .   \n",
       "9          neutral  Фото «до» к сожалению не сделала, только «посл...   \n",
       "10         neutral  Обработал глушитель на авто, даже заводская кр...   \n",
       "11         neutral  В деле пока не пробовала. | В деле не пробовал...   \n",
       "12         neutral                                           .. | ...   \n",
       "\n",
       "                                          key_thought  word_count  \n",
       "0   Хороши когда нужно \"выскочить\" из снежного мес...        1081  \n",
       "1          Хорошие траки, на ощупь достаточно прочные          15  \n",
       "2                                     На вид крепкие.          12  \n",
       "3                                                  ..           8  \n",
       "4   Не выручать даже летом, чуток сел в небольшую ...         432  \n",
       "5                           В деле пока не пробовала.          37  \n",
       "6                         Посмотрим на сколько хватит          16  \n",
       "7                                Буду заказывать ещё.          13  \n",
       "8                                                  ..           5  \n",
       "9    Фото «до» к сожалению не сделала, только «после»          24  \n",
       "10                     Удалял \"жучки\" на дверях авто.          24  \n",
       "11                          В деле пока не пробовала.          14  \n",
       "12                                                 ..           3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Перевод модели в режим FP16, если это возможно\n",
    "if torch.cuda.is_available():\n",
    "    model_classification = model_classification.half()\n",
    "\n",
    "# Функция для вычисления центра кластера (центроида)\n",
    "def find_centroid(embeddings):\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "# Функция для вычисления эмбеддингов\n",
    "def compute_sentence_embeddings(sentences):\n",
    "    # Проверка на корректность данных\n",
    "    if not all(isinstance(sentence, str) and sentence.strip() for sentence in sentences):\n",
    "        raise ValueError(\"All items in the input must be non-empty strings.\")\n",
    "    \n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model_classification(**inputs)\n",
    "        # Проверка на наличие скрытых состояний\n",
    "        if outputs.hidden_states is None:\n",
    "            raise ValueError(\"Модель не возвращает скрытые состояния. Проверьте конфигурацию модели.\")\n",
    "        # Получаем последние скрытые состояния\n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "    embeddings = hidden_states.mean(dim=1).cpu().numpy()\n",
    "    return embeddings\n",
    "\n",
    "# Функция для нахождения ключевой мысли в кластере\n",
    "def extract_key_thought(cluster_sentences):\n",
    "    sentences = cluster_sentences.split(\" | \")\n",
    "    \n",
    "    embeddings = compute_sentence_embeddings(sentences)\n",
    "    \n",
    "    centroid = find_centroid(embeddings)\n",
    "    similarities = cosine_similarity(embeddings, [centroid])\n",
    "    key_sentence_index = np.argmax(similarities)\n",
    "    \n",
    "    return sentences[key_sentence_index]\n",
    "\n",
    "# Функция для подсчета количества слов в каждом кластере\n",
    "def count_words(cluster_sentences):\n",
    "    words = cluster_sentences.split()\n",
    "    return len(words)\n",
    "\n",
    "# Функция для повторной кластеризации крупных кластеров\n",
    "def recluster_large_cluster(cluster_sentences, eps=0.1, min_samples=2):\n",
    "    sentences = cluster_sentences.split(\" | \")\n",
    "    \n",
    "    embeddings = compute_sentence_embeddings(sentences)\n",
    "    \n",
    "    re_clustering = DBSCAN(eps=eps, min_samples=min_samples, metric=\"cosine\").fit(embeddings)\n",
    "    \n",
    "    re_cluster_dict = {}\n",
    "    for idx, label in enumerate(re_clustering.labels_):\n",
    "        if label == -1:\n",
    "            continue\n",
    "        label_str = str(label)\n",
    "        if label_str not in re_cluster_dict:\n",
    "            re_cluster_dict[label_str] = []\n",
    "        re_cluster_dict[label_str].append(sentences[idx])\n",
    "    \n",
    "    return [\" | \".join(cluster) for cluster in re_cluster_dict.values()]\n",
    "\n",
    "# Рекурсивная функция для кластеризации крупных кластеров\n",
    "def recursive_clustering(cluster_sentences, threshold, eps=0.22, min_samples=3, min_eps=0.02):\n",
    "    current_eps = eps\n",
    "    current_min_samples = min_samples\n",
    "    new_clusters = [cluster_sentences]\n",
    "\n",
    "    while True:\n",
    "        next_clusters = []\n",
    "        reclustered_any = False\n",
    "        \n",
    "        for cluster in new_clusters:\n",
    "            if count_words(cluster) > threshold:\n",
    "                while current_eps >= min_eps:\n",
    "                    reclustered = recluster_large_cluster(cluster, eps=current_eps, min_samples=current_min_samples)\n",
    "                    \n",
    "                    if len(reclustered) > 1:\n",
    "                        next_clusters.extend(reclustered)\n",
    "                        reclustered_any = True\n",
    "                        break  # Кластер успешно разделен, выходим из внутреннего цикла\n",
    "                    else:\n",
    "                        if current_eps > min_eps:\n",
    "                            current_eps -= 0.05  # Уменьшаем eps и пробуем снова\n",
    "                \n",
    "                if len(reclustered) == 1:\n",
    "                    # Если кластер так и не был разделен, добавляем его обратно\n",
    "                    next_clusters.append(cluster)\n",
    "            else:\n",
    "                next_clusters.append(cluster)\n",
    "        \n",
    "        new_clusters = next_clusters\n",
    "        \n",
    "        if not reclustered_any:\n",
    "            break\n",
    "    \n",
    "    return new_clusters\n",
    "\n",
    "# Основной процесс кластеризации по категориям и продуктам\n",
    "final_result = pd.DataFrame()\n",
    "\n",
    "# Группируем по category и product\n",
    "for (category_name, product_name), group in tqdm(dataset_exploded[dataset_exploded[\"predictions\"] == 1].groupby(['category', 'product']), desc=\"Processing categories and products\"):\n",
    "    all_sentences = group['sentences'].tolist()\n",
    "\n",
    "    if not all_sentences:\n",
    "        continue  # пропустить, если нет предложений\n",
    "\n",
    "    try:\n",
    "        # Обработка предложений без разделения на батчи\n",
    "        all_embeddings = compute_sentence_embeddings(all_sentences)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in computing embeddings for product {product_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Прогресс-бар для начальной кластеризации с использованием HDBSCAN и косинусной метрики\n",
    "    distance_matrix = squareform(pdist(all_embeddings, metric='cosine'))\n",
    "    clustering = hdbscan.HDBSCAN(min_samples=3, metric='precomputed').fit(distance_matrix)\n",
    "\n",
    "    cluster_dict = {}\n",
    "    for idx, label in enumerate(clustering.labels_):\n",
    "        if label == -1:\n",
    "            continue\n",
    "        label_str = str(label)\n",
    "        if label_str not in cluster_dict:\n",
    "            cluster_dict[label_str] = set()\n",
    "        cluster_dict[label_str].add(all_sentences[idx])\n",
    "\n",
    "    clusters = [\" | \".join(sentences) for sentences in cluster_dict.values()]\n",
    "\n",
    "    if not clusters:\n",
    "        continue  # пропустить, если нет кластеров\n",
    "\n",
    "    # Преобразуем review_rating в 1 и 0\n",
    "    group['binary_rating'] = group['review_rating'].apply(lambda x: 1 if x in [4, 5] else 0)\n",
    "\n",
    "    # Рассчитываем средний рейтинг для этой группы\n",
    "    avg_rating = group['binary_rating'].mean()\n",
    "    \n",
    "    # Определяем, positive или negative\n",
    "    rating_category = 'positive' if avg_rating > 0.7 else 'neutral'\n",
    "    rating_category = 'neutral' if avg_rating > 0.5 else 'negative'\n",
    "\n",
    "    # Условие для определения порогового значения threshold\n",
    "    if len(clusters) == 1:\n",
    "        cluster_word_count = count_words(clusters[0])\n",
    "        if cluster_word_count > 20:\n",
    "            threshold = cluster_word_count / 2\n",
    "        else:\n",
    "            threshold = cluster_word_count  # Оставляем threshold как есть\n",
    "    else:\n",
    "        # В противном случае используем исходную логику для расчета порога\n",
    "        threshold = np.min([np.mean([count_words(cluster) for cluster in clusters]) * 1.5, 250])\n",
    "\n",
    "    final_clusters = []\n",
    "    for cluster in clusters:\n",
    "        if count_words(cluster) > threshold:\n",
    "            final_clusters.extend(recursive_clustering(cluster, threshold))\n",
    "        else:\n",
    "            final_clusters.append(cluster)\n",
    "\n",
    "    # Убедиться, что минимальное количество кластеров — 3\n",
    "    while len(final_clusters) < 3 and any(count_words(cluster) > threshold for cluster in final_clusters):\n",
    "        largest_cluster = max(final_clusters, key=count_words)\n",
    "        final_clusters.remove(largest_cluster)\n",
    "        new_clusters = recursive_clustering(largest_cluster, threshold)\n",
    "        \n",
    "        if len(new_clusters) <= 1:\n",
    "            final_clusters.append(largest_cluster)\n",
    "            break\n",
    "\n",
    "        final_clusters.extend(new_clusters)\n",
    "\n",
    "    df_exploded_sorted = pd.DataFrame({\n",
    "        'category': category_name,\n",
    "        'product': product_name,\n",
    "        'avg_rating': avg_rating,\n",
    "        'rating_category': rating_category,\n",
    "        'cluster_sentences': final_clusters\n",
    "    })\n",
    "    df_exploded_sorted['word_count'] = df_exploded_sorted['cluster_sentences'].apply(count_words)\n",
    "    df_exploded_sorted['key_thought'] = df_exploded_sorted['cluster_sentences'].apply(extract_key_thought)\n",
    "\n",
    "    df_exploded_sorted = df_exploded_sorted.sort_values(by='word_count', ascending=False)\n",
    "\n",
    "    final_result = pd.concat([final_result, df_exploded_sorted], ignore_index=True)\n",
    "\n",
    "# Показать результат\n",
    "display(final_result[['category', 'product', 'avg_rating', 'rating_category', 'cluster_sentences', 'key_thought', 'word_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>word_count</th>\n",
       "      <th>key_thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВПМ / Антибукс - антипробуксовочные траки утол...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Не во всех случаях, конечно, эти Анти буксы мо...</td>\n",
       "      <td>1081</td>\n",
       "      <td>Хороши когда нужно \"выскочить\" из снежного мес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВПМ / Антибукс - антипробуксовочные траки утол...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Отличные траки, испытали на газели | Хорошие т...</td>\n",
       "      <td>15</td>\n",
       "      <td>Хорошие траки, на ощупь достаточно прочные</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВПМ / Антибукс - антипробуксовочные траки утол...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>На вид прочные и колючие. | На вид крепкие. | ...</td>\n",
       "      <td>12</td>\n",
       "      <td>На вид крепкие.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Выру чайка на самом деле тахта, застрял в сугр...</td>\n",
       "      <td>432</td>\n",
       "      <td>Не выручать даже летом, чуток сел в небольшую ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>neutral</td>\n",
       "      <td>, но в деле ещё не пробовали | В деле не пробо...</td>\n",
       "      <td>37</td>\n",
       "      <td>В деле пока не пробовала.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>Пахнет и Точка / Ароматизатор в машину автопар...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Посмотрим на сколько хватит! | Посмотри и на к...</td>\n",
       "      <td>16</td>\n",
       "      <td>Посмотрим на сколько хватит</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>Пахнет и Точка / Ароматизатор в машину автопар...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Закажу еще не раз! | Буду заказывать ещё. | мы...</td>\n",
       "      <td>13</td>\n",
       "      <td>Буду заказывать ещё.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>К сожалению забыл сделать фото \"до\" | Фото не ...</td>\n",
       "      <td>24</td>\n",
       "      <td>Фото «до» к сожалению не сделала, только «после»</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Оттирал автомобильный номер от следов ржавых б...</td>\n",
       "      <td>24</td>\n",
       "      <td>Удалял \"жучки\" на дверях авто.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>В деле не пробовал | В деле пока не пробовала....</td>\n",
       "      <td>14</td>\n",
       "      <td>В деле пока не пробовала.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 category  \\\n",
       "0                     /Автотовары/OFFroad   \n",
       "1                     /Автотовары/OFFroad   \n",
       "2                     /Автотовары/OFFroad   \n",
       "4                     /Автотовары/OFFroad   \n",
       "5                     /Автотовары/OFFroad   \n",
       "6   /Автотовары/Автокосметика и автохимия   \n",
       "7   /Автотовары/Автокосметика и автохимия   \n",
       "9   /Автотовары/Автокосметика и автохимия   \n",
       "10  /Автотовары/Автокосметика и автохимия   \n",
       "11  /Автотовары/Автокосметика и автохимия   \n",
       "\n",
       "                                              product  avg_rating  \\\n",
       "0   ВПМ / Антибукс - антипробуксовочные траки утол...    0.819588   \n",
       "1   ВПМ / Антибукс - антипробуксовочные траки утол...    0.819588   \n",
       "2   ВПМ / Антибукс - антипробуксовочные траки утол...    0.819588   \n",
       "4   ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...    0.842975   \n",
       "5   ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...    0.842975   \n",
       "6   Пахнет и Точка / Ароматизатор в машину автопар...    0.704545   \n",
       "7   Пахнет и Точка / Ароматизатор в машину автопар...    0.704545   \n",
       "9   ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "10  ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "11  ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "\n",
       "   rating_category                                  cluster_sentences  \\\n",
       "0          neutral  Не во всех случаях, конечно, эти Анти буксы мо...   \n",
       "1          neutral  Отличные траки, испытали на газели | Хорошие т...   \n",
       "2          neutral  На вид прочные и колючие. | На вид крепкие. | ...   \n",
       "4          neutral  Выру чайка на самом деле тахта, застрял в сугр...   \n",
       "5          neutral  , но в деле ещё не пробовали | В деле не пробо...   \n",
       "6          neutral  Посмотрим на сколько хватит! | Посмотри и на к...   \n",
       "7          neutral  Закажу еще не раз! | Буду заказывать ещё. | мы...   \n",
       "9          neutral  К сожалению забыл сделать фото \"до\" | Фото не ...   \n",
       "10         neutral  Оттирал автомобильный номер от следов ржавых б...   \n",
       "11         neutral  В деле не пробовал | В деле пока не пробовала....   \n",
       "\n",
       "    word_count                                        key_thought  \n",
       "0         1081  Хороши когда нужно \"выскочить\" из снежного мес...  \n",
       "1           15         Хорошие траки, на ощупь достаточно прочные  \n",
       "2           12                                    На вид крепкие.  \n",
       "4          432  Не выручать даже летом, чуток сел в небольшую ...  \n",
       "5           37                          В деле пока не пробовала.  \n",
       "6           16                        Посмотрим на сколько хватит  \n",
       "7           13                               Буду заказывать ещё.  \n",
       "9           24   Фото «до» к сожалению не сделала, только «после»  \n",
       "10          24                     Удалял \"жучки\" на дверях авто.  \n",
       "11          14                          В деле пока не пробовала.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Удаление записей с word_count <= 10 и ключевой мыслью менее 3 символов\n",
    "final_result = final_result[((final_result['word_count'] > 10) & (final_result['key_thought'].str.len() > 5))]\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.to_csv(\"./reviews_keywords/feedbackfueltest.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
