{
 "cells": [
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1d46f2a54c479ab59d26ebb3ce50c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356e6944b3174a959619137d019407b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2061 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤:   0%|                                                                                                                                                                        | 0/65 [00:00<?, ?it/s]/tmp/ipykernel_39/1355171717.py:197: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–º–µ—à–∞–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65/65 [00:12<00:00,  5.09it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a444cba8b84bc2a9279963a141ae7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2061 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories and products: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:18<00:00,  1.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>word_count</th>\n",
       "      <th>key_thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–ü–µ—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–µ—Å–æ –∑–∞–∫—Ä—ã–ª–æ—Å—å –≤ —Å–Ω–µ–≥—É, –ø–æ–¥–ª–æ–∂–∏–ª–∏ –ø...</td>\n",
       "      <td>40</td>\n",
       "      <td>–ü–µ—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–µ—Å–æ –∑–∞–∫—Ä—ã–ª–æ—Å—å –≤ —Å–Ω–µ–≥—É, –ø–æ–¥–ª–æ–∂–∏–ª–∏ –ø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–ù–∞ –≤–∏–¥ –∫—Ä–µ–ø–∫–∏–µ. | –í—Ä–æ–¥–µ –ø—Ä–æ—á–Ω—ã–µ. | –ù–∞ –≤–∏–¥ –ø—Ä–æ—á...</td>\n",
       "      <td>12</td>\n",
       "      <td>–ù–∞ –≤–∏–¥ –∫—Ä–µ–ø–∫–∏–µ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–´–†–£–ß–ê–ô–ö–ê / –ê–Ω—Ç–∏–±—É–∫—Å –ü—Ä–æ—Ç–∏–≤–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–í –¥–µ–ª–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª | –í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞....</td>\n",
       "      <td>37</td>\n",
       "      <td>–í –¥–µ–ª–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–†–µ–∫–æ–º–µ–Ω–¥—É—é, –±—É–¥—É –±—Ä–∞—Ç—å –µ—â–µ | –ó–∞–∫–∞–∂—É | –º—ã–ú—ã–æ—á–Ω–æ...</td>\n",
       "      <td>20</td>\n",
       "      <td>–ë—É–¥—É –∑–∞–∫–∞–∑—ã–≤–∞—Ç—å –µ—â—ë.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–ï–ª–µ –ø–∞—Ö–Ω–µ—Ç. | –û–Ω –¥–∞–∂–µ –Ω–µ –ø–∞—Ö–Ω–µ—Ç. | –ü–∞—Ö–Ω–µ—Ç –∫–∞–∫–∏...</td>\n",
       "      <td>13</td>\n",
       "      <td>–ï–ª–µ –ø–∞—Ö–Ω–µ—Ç.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                category  \\\n",
       "0                    /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "1                    /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "3                    /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "4  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "5  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "\n",
       "                                             product  avg_rating  \\\n",
       "0  –í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...    0.819588   \n",
       "1  –í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...    0.819588   \n",
       "3  –í–´–†–£–ß–ê–ô–ö–ê / –ê–Ω—Ç–∏–±—É–∫—Å –ü—Ä–æ—Ç–∏–≤–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ ...    0.842975   \n",
       "4  –ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...    0.704545   \n",
       "5  –ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...    0.704545   \n",
       "\n",
       "  rating_category                                  cluster_sentences  \\\n",
       "0         neutral  –ü–µ—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–µ—Å–æ –∑–∞–∫—Ä—ã–ª–æ—Å—å –≤ —Å–Ω–µ–≥—É, –ø–æ–¥–ª–æ–∂–∏–ª–∏ –ø...   \n",
       "1         neutral  –ù–∞ –≤–∏–¥ –∫—Ä–µ–ø–∫–∏–µ. | –í—Ä–æ–¥–µ –ø—Ä–æ—á–Ω—ã–µ. | –ù–∞ –≤–∏–¥ –ø—Ä–æ—á...   \n",
       "3         neutral  –í –¥–µ–ª–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª | –í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞....   \n",
       "4         neutral  –†–µ–∫–æ–º–µ–Ω–¥—É—é, –±—É–¥—É –±—Ä–∞—Ç—å –µ—â–µ | –ó–∞–∫–∞–∂—É | –º—ã–ú—ã–æ—á–Ω–æ...   \n",
       "5         neutral  –ï–ª–µ –ø–∞—Ö–Ω–µ—Ç. | –û–Ω –¥–∞–∂–µ –Ω–µ –ø–∞—Ö–Ω–µ—Ç. | –ü–∞—Ö–Ω–µ—Ç –∫–∞–∫–∏...   \n",
       "\n",
       "   word_count                                        key_thought  \n",
       "0          40  –ü–µ—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–µ—Å–æ –∑–∞–∫—Ä—ã–ª–æ—Å—å –≤ —Å–Ω–µ–≥—É, –ø–æ–¥–ª–æ–∂–∏–ª–∏ –ø...  \n",
       "1          12                                    –ù–∞ –≤–∏–¥ –∫—Ä–µ–ø–∫–∏–µ.  \n",
       "3          37                                 –í –¥–µ–ª–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª  \n",
       "4          20                               –ë—É–¥—É –∑–∞–∫–∞–∑—ã–≤–∞—Ç—å –µ—â—ë.  \n",
       "5          13                                        –ï–ª–µ –ø–∞—Ö–Ω–µ—Ç.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pyarrow.parquet as pq\n",
    "import dask.dataframe as dd\n",
    "import spacy\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, BertTokenizerFast, BertForSequenceClassification, BertConfig\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, Dataset as TorchDataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import hdbscan\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import logging\n",
    "import re\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "class ReviewsKeywords:\n",
    "    def __init__(self, csv_path, model_path, spacy_model=\"ru_core_news_lg\"):\n",
    "        self.csv_path = csv_path\n",
    "        self.model_path = model_path\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if self.device == \"cuda\":\n",
    "            import cudf.pandas  # –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ cuDF –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏—è –µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "            cudf.pandas.install()\n",
    "        os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"  # –í–∫–ª—é—á–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è\n",
    "        self.tokenizer_my = BertTokenizerFast.from_pretrained(self.model_path)\n",
    "         # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "        self.classification_model = BertForSequenceClassification.from_pretrained(self.model_path).to(self.device)\n",
    "        # –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "        self.embedding_model = AutoModel.from_pretrained(self.model_path).to(self.device)\n",
    "        \n",
    "        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ –æ—Ç –°–±–µ—Ä–±–∞–Ω–∫–∞\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('sberbank-ai/sbert_large_nlu_ru')\n",
    "        self.embedding_model = AutoModel.from_pretrained('sberbank-ai/sbert_large_nlu_ru').to(self.device)\n",
    "        \n",
    "        spacy.prefer_gpu()\n",
    "        self.nlp = spacy.load(spacy_model, disable=[\"ner\", \"tagger\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "        \n",
    "        self.df = pd.read_csv(self.csv_path, nrows=1000)\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text):\n",
    "        text = re.sub(r'[\\n\\r\\t]+|\\s{2,}', ' ', text)\n",
    "        text = re.sub(r'(?<!\\.)\\s*\\.\\s*|\\s*\\.\\s*(?!\\.)', '. ', text)\n",
    "        return text.strip().rstrip('.')\n",
    "\n",
    "    def split_reviews_into_sentences(self, batch):\n",
    "        cleaned_texts = [self.clean_text(text) for text in batch['corrected_text']]\n",
    "        docs = list(self.nlp.pipe(cleaned_texts, batch_size=64))\n",
    "        batch['sentences'] = [[sent.text for sent in doc.sents] for doc in docs]\n",
    "        return batch\n",
    "\n",
    "    def process_reviews(self):\n",
    "        dataset = Dataset.from_pandas(self.df)\n",
    "        dataset = dataset.map(self.split_reviews_into_sentences, batched=True, batch_size=32)\n",
    "        self.df = dataset.to_pandas()\n",
    "        df_exploded = self.df.explode('sentences').reset_index(drop=True)\n",
    "        df_exploded = df_exploded.drop(columns=[col for col in df_exploded.columns if col.startswith('__index_level_')])\n",
    "        return Dataset.from_pandas(df_exploded)\n",
    "\n",
    "    def compute_sentence_embeddings(self, sentences):\n",
    "        sentences = [str(sentence) for sentence in sentences if isinstance(sentence, str)]\n",
    "        if not sentences:\n",
    "            raise ValueError(\"Input contains no valid strings.\")\n",
    "        inputs = self.tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.embedding_model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "    def compute_embeddings_after_explode(self, batch):\n",
    "        sentences = batch['sentences']\n",
    "        valid_sentences = [str(sentence) for sentence in sentences if isinstance(sentence, str)]\n",
    "        if not valid_sentences:\n",
    "            batch['sentence_embeddings'] = [[]] * len(sentences)\n",
    "            return batch\n",
    "        embeddings = self.compute_sentence_embeddings(valid_sentences)\n",
    "        embeddings = embeddings.astype(np.float32)\n",
    "        final_embeddings = []\n",
    "        embed_idx = 0\n",
    "        for sentence in sentences:\n",
    "            if isinstance(sentence, str):\n",
    "                final_embeddings.append(embeddings[embed_idx])\n",
    "                embed_idx += 1\n",
    "            else:\n",
    "                final_embeddings.append(np.zeros(embeddings.shape[1], dtype=np.float32))\n",
    "        batch['sentence_embeddings'] = final_embeddings\n",
    "        return batch\n",
    "\n",
    "    def apply_embeddings(self, dataset_exploded):\n",
    "        return dataset_exploded.map(self.compute_embeddings_after_explode, batched=True, batch_size=128)\n",
    "\n",
    "    def extract_key_thought(self, cluster_sentences):\n",
    "        sentences = cluster_sentences.split(\" | \")\n",
    "        embeddings = self.compute_sentence_embeddings(sentences)\n",
    "        centroid = np.mean(embeddings, axis=0)\n",
    "        similarities = cosine_similarity(embeddings, [centroid])\n",
    "        key_sentence_index = np.argmax(similarities)\n",
    "        return sentences[key_sentence_index]\n",
    "\n",
    "    def count_words(self, cluster_sentences):\n",
    "        words = cluster_sentences.split()\n",
    "        return len(words)\n",
    "\n",
    "    def recluster_large_cluster(self, cluster_sentences, eps=0.1, min_samples=2):\n",
    "        sentences = cluster_sentences.split(\" | \")\n",
    "        embeddings = self.compute_sentence_embeddings(sentences)\n",
    "        re_clustering = DBSCAN(eps=eps, min_samples=min_samples, metric=\"cosine\").fit(embeddings)\n",
    "        re_cluster_dict = {}\n",
    "        for idx, label in enumerate(re_clustering.labels_):\n",
    "            if label == -1:\n",
    "                continue\n",
    "            label_str = str(label)\n",
    "            if label_str not in re_cluster_dict:\n",
    "                re_cluster_dict[label_str] = []\n",
    "            re_cluster_dict[label_str].append(sentences[idx])\n",
    "        return [\" | \".join(cluster) for cluster in re_cluster_dict.values()]\n",
    "\n",
    "    def recursive_clustering(self, cluster_sentences, threshold, eps=0.22, min_samples=3, min_eps=0.02):\n",
    "        current_eps = eps\n",
    "        current_min_samples = min_samples\n",
    "        new_clusters = [cluster_sentences]\n",
    "        while True:\n",
    "            next_clusters = []\n",
    "            reclustered_any = False\n",
    "            for cluster in new_clusters:\n",
    "                if self.count_words(cluster) > threshold:\n",
    "                    while current_eps >= min_eps:\n",
    "                        reclustered = self.recluster_large_cluster(cluster, eps=current_eps, min_samples=current_min_samples)\n",
    "                        if len(reclustered) > 1:\n",
    "                            next_clusters.extend(reclustered)\n",
    "                            reclustered_any = True\n",
    "                            break\n",
    "                        else:\n",
    "                            if current_eps > min_eps:\n",
    "                                current_eps -= 0.05\n",
    "                    if len(reclustered) == 1:\n",
    "                        next_clusters.append(cluster)\n",
    "                else:\n",
    "                    next_clusters.append(cluster)\n",
    "            new_clusters = next_clusters\n",
    "            if not reclustered_any:\n",
    "                break\n",
    "        return new_clusters\n",
    "\n",
    "    def generate_predictions(self, dataset_exploded):\n",
    "        tokenizer = self.tokenizer_my\n",
    "        model = self.classification_model\n",
    "        if self.device == torch.device(\"cuda\"):\n",
    "            model = model.half()\n",
    "\n",
    "        reviews = dataset_exploded[\"sentences\"]\n",
    "        reviews = [str(review) for review in reviews if isinstance(review, str) and review.strip()]\n",
    "\n",
    "        class ReviewDataset(TorchDataset):\n",
    "            def __init__(self, reviews, tokenizer, max_len=128):\n",
    "                self.reviews = reviews\n",
    "                self.tokenizer = tokenizer\n",
    "                self.max_len = max_len\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.reviews)\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                review = self.reviews[idx]\n",
    "                encoding = self.tokenizer.encode_plus(\n",
    "                    review,\n",
    "                    add_special_tokens=True,\n",
    "                    max_length=self.max_len,\n",
    "                    return_token_type_ids=False,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_attention_mask=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                return {key: val.flatten() for key, val in encoding.items()}\n",
    "\n",
    "        dataset = ReviewDataset(reviews, tokenizer)\n",
    "        batch_size = 32\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        from torch.cuda.amp import autocast\n",
    "\n",
    "        for batch in tqdm(dataloader, desc=\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤\"):\n",
    "            batch = {key: val.to(self.device) for key, val in batch.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                with autocast():  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–º–µ—à–∞–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å\n",
    "                    outputs = model(**batch)\n",
    "                    logits = outputs[0] if isinstance(outputs, tuple) else outputs.logits\n",
    "                    probabilities = torch.softmax(logits, dim=-1)\n",
    "                    batch_predictions = (probabilities[:, 1] > 0.7).cpu().numpy()  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ä–æ–≥ 0.7\n",
    "                    predictions.extend(batch_predictions)\n",
    "\n",
    "        if len(predictions) != len(dataset_exploded):\n",
    "            print(f\"Warning: Length of predictions ({len(predictions)}) does not match length of index ({len(dataset_exploded)})\")\n",
    "            if len(predictions) < len(dataset_exploded):\n",
    "                missing_count = len(dataset_exploded) - len(predictions)\n",
    "                predictions.extend([0] * missing_count)\n",
    "            elif len(predictions) > len(dataset_exploded):\n",
    "                predictions = predictions[:len(dataset_exploded)]\n",
    "        dataset_exploded = dataset_exploded.add_column(\"predictions\", predictions)\n",
    "        return dataset_exploded\n",
    "\n",
    "    def process_group(self, category_name, product_name, group):\n",
    "        all_sentences = group['sentences'].tolist()\n",
    "        if not all_sentences:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        try:\n",
    "            all_embeddings = self.compute_sentence_embeddings(all_sentences)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in computing embeddings for product {product_name}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        distance_matrix = squareform(pdist(all_embeddings, metric='cosine'))\n",
    "        clustering = hdbscan.HDBSCAN(min_samples=3, metric='precomputed').fit(distance_matrix)\n",
    "\n",
    "        cluster_dict = {}\n",
    "        for idx, label in enumerate(clustering.labels_):\n",
    "            if label == -1:\n",
    "                continue\n",
    "            label_str = str(label)\n",
    "            if label_str not in cluster_dict:\n",
    "                cluster_dict[label_str] = set()\n",
    "            cluster_dict[label_str].add(all_sentences[idx])\n",
    "\n",
    "        clusters = [\" | \".join(sentences) for sentences in cluster_dict.values()]\n",
    "\n",
    "        if not clusters:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        group['binary_rating'] = group['review_rating'].apply(lambda x: 1 if x in [4, 5] else 0)\n",
    "        avg_rating = group['binary_rating'].mean()\n",
    "        rating_category = 'positive' if avg_rating > 0.7 else 'neutral'\n",
    "        rating_category = 'neutral' if avg_rating > 0.5 else 'negative'\n",
    "\n",
    "        threshold = self.determine_threshold(clusters)\n",
    "\n",
    "        final_clusters = []\n",
    "        for cluster in clusters:\n",
    "            if self.count_words(cluster) > threshold:\n",
    "                final_clusters.extend(self.recursive_clustering(cluster, threshold))\n",
    "            else:\n",
    "                final_clusters.append(cluster)\n",
    "\n",
    "        # –û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "        final_clusters = self.ensure_minimum_clusters(final_clusters, threshold)\n",
    "\n",
    "        df_exploded_sorted = pd.DataFrame({\n",
    "            'category': category_name,\n",
    "            'product': product_name,\n",
    "            'avg_rating': avg_rating,\n",
    "            'rating_category': rating_category,\n",
    "            'cluster_sentences': final_clusters\n",
    "        })\n",
    "        df_exploded_sorted['word_count'] = df_exploded_sorted['cluster_sentences'].apply(self.count_words)\n",
    "        df_exploded_sorted['key_thought'] = df_exploded_sorted['cluster_sentences'].apply(self.extract_key_thought)\n",
    "        df_exploded_sorted = df_exploded_sorted.sort_values(by='word_count', ascending=False)\n",
    "\n",
    "        return df_exploded_sorted\n",
    "\n",
    "    def determine_threshold(self, clusters):\n",
    "        if len(clusters) == 1:\n",
    "            cluster_word_count = self.count_words(clusters[0])\n",
    "            if cluster_word_count > 20:\n",
    "                return cluster_word_count / 2\n",
    "            return cluster_word_count\n",
    "        return np.min([np.mean([self.count_words(cluster) for cluster in clusters]) * 1.5, 250])\n",
    "\n",
    "    def ensure_minimum_clusters(self, final_clusters, threshold):\n",
    "        while len(final_clusters) < 3 and any(self.count_words(cluster) > threshold for cluster in final_clusters):\n",
    "            largest_cluster = max(final_clusters, key=self.count_words)\n",
    "            final_clusters.remove(largest_cluster)\n",
    "            new_clusters = self.recursive_clustering(largest_cluster, threshold)\n",
    "            if len(new_clusters) <= 1:\n",
    "                final_clusters.append(largest_cluster)\n",
    "                break\n",
    "            final_clusters.extend(new_clusters)\n",
    "        return final_clusters\n",
    "    \n",
    "    def cluster_reviews(self, dataset_exploded):\n",
    "        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "        dataset_filtered = dataset_exploded.filter(lambda x: x['predictions'] == 1)\n",
    "        \n",
    "        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ pandas DataFrame –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏\n",
    "        df_filtered = dataset_filtered.to_pandas()\n",
    "        grouped = df_filtered.groupby(['category', 'product'])\n",
    "\n",
    "        results = []\n",
    "        \n",
    "        # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ–∑ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞\n",
    "        for (category_name, product_name), group in tqdm(grouped, desc=\"Processing categories and products\"):\n",
    "            result_df = self.process_group(category_name, product_name, group)\n",
    "            if not result_df.empty:\n",
    "                results.append(result_df)\n",
    "\n",
    "        if results:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–ø–∏—Å–æ–∫ results –Ω–µ –ø—É—Å—Ç\n",
    "            final_result = pd.concat(results, ignore_index=True)\n",
    "            final_result = final_result[((final_result['word_count'] > 10) & (final_result['key_thought'].str.len() > 5))]\n",
    "            final_result.to_csv(\"./reviews_keywords/feedbackfueltest.csv\")\n",
    "        else:\n",
    "            print(\"No valid results to concatenate. Returning an empty DataFrame.\")\n",
    "            final_result = pd.DataFrame()  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π DataFrame, –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è\n",
    "        \n",
    "        return final_result\n",
    "\n",
    "    def run(self):\n",
    "        dataset_exploded = self.process_reviews()\n",
    "        dataset_exploded = self.apply_embeddings(dataset_exploded)\n",
    "        dataset_exploded = self.generate_predictions(dataset_exploded)\n",
    "        result = self.cluster_reviews(dataset_exploded)\n",
    "        return result\n",
    "\n",
    "\n",
    "reviews_keywords = ReviewsKeywords(csv_path=\"./reviews_keywords/wildberries_reviews.csv\",\n",
    "                                    model_path='./reviews_keywords/fine_tuned_model')\n",
    "final_result = reviews_keywords.run()\n",
    "final_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>word_count</th>\n",
       "      <th>key_thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–ü–µ—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–µ—Å–æ –∑–∞–∫—Ä—ã–ª–æ—Å—å –≤ —Å–Ω–µ–≥—É, –ø–æ–¥–ª–æ–∂–∏–ª–∏ –ø...</td>\n",
       "      <td>40</td>\n",
       "      <td>–ü–µ—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–µ—Å–æ –∑–∞–∫—Ä—ã–ª–æ—Å—å –≤ —Å–Ω–µ–≥—É, –ø–æ–¥–ª–æ–∂–∏–ª–∏ –ø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–ù–∞ –≤–∏–¥ –∫—Ä–µ–ø–∫–∏–µ. | –í—Ä–æ–¥–µ –ø—Ä–æ—á–Ω—ã–µ. | –ù–∞ –≤–∏–¥ –ø—Ä–æ—á...</td>\n",
       "      <td>12</td>\n",
       "      <td>–ù–∞ –≤–∏–¥ –∫—Ä–µ–ø–∫–∏–µ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–´–†–£–ß–ê–ô–ö–ê / –ê–Ω—Ç–∏–±—É–∫—Å –ü—Ä–æ—Ç–∏–≤–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–í –¥–µ–ª–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª | –í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞....</td>\n",
       "      <td>37</td>\n",
       "      <td>–í –¥–µ–ª–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–†–µ–∫–æ–º–µ–Ω–¥—É—é, –±—É–¥—É –±—Ä–∞—Ç—å –µ—â–µ | –ó–∞–∫–∞–∂—É | –º—ã–ú—ã–æ—á–Ω–æ...</td>\n",
       "      <td>20</td>\n",
       "      <td>–ë—É–¥—É –∑–∞–∫–∞–∑—ã–≤–∞—Ç—å –µ—â—ë.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–ï–ª–µ –ø–∞—Ö–Ω–µ—Ç. | –û–Ω –¥–∞–∂–µ –Ω–µ –ø–∞—Ö–Ω–µ—Ç. | –ü–∞—Ö–Ω–µ—Ç –∫–∞–∫–∏...</td>\n",
       "      <td>13</td>\n",
       "      <td>–ï–ª–µ –ø–∞—Ö–Ω–µ—Ç.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>üî•üî•üî•üî•üî•üî• –∑–∞–ø–∞—Ö. | –ó–∞–ø–∞—Ö –æ–≥–æ–Ω—å) | –ó–∞–ø–∞—Ö –æ–≥–æ–Ω—å!!!!...</td>\n",
       "      <td>11</td>\n",
       "      <td>–ó–∞–ø–∞—Ö üî•!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–£–±–∏—Ä–∞–µ—Ç —Ä–∂–∞–≤—á–∏–Ω—É —Ö–æ—Ä–æ—à–æ —á–µ—Ä–µ–∑ 10-20 –º–∏–Ω—É—Ç | –°–æ...</td>\n",
       "      <td>76</td>\n",
       "      <td>–†–∂–∞–≤—á–∏–Ω—É —É–±–∏—Ä–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–†–∂–∞–≤—á–∏–Ω–∞ —É–∂–µ —Ö–æ—Ä–æ—à–æ –≤—ä–µ–ª–∞—Å—å, –ø—Ä–∏—à–ª–æ—Å—å –Ω–µ—Å–∫–æ–ª—å–∫...</td>\n",
       "      <td>38</td>\n",
       "      <td>–†–∂–∞–≤—á–∏–Ω–∞ —É–∂–µ —Ö–æ—Ä–æ—à–æ –≤—ä–µ–ª–∞—Å—å, –ø—Ä–∏—à–ª–æ—Å—å –Ω–µ—Å–∫–æ–ª—å–∫...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–§–æ—Ç–æ ¬´–¥–æ¬ª –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é –Ω–µ —Å–¥–µ–ª–∞–ª–∞, —Ç–æ–ª—å–∫–æ ¬´–ø–æ—Å–ª...</td>\n",
       "      <td>24</td>\n",
       "      <td>–§–æ—Ç–æ ¬´–¥–æ¬ª –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é –Ω–µ —Å–¥–µ–ª–∞–ª–∞, —Ç–æ–ª—å–∫–æ ¬´–ø–æ—Å–ª–µ¬ª</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞. | –í –¥–µ–ª–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª...</td>\n",
       "      <td>14</td>\n",
       "      <td>–í –¥–µ–ª–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 category  \\\n",
       "0                     /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "1                     /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "3                     /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "4   /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "5   /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "6   /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "7   /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "8   /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "9   /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "10  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "\n",
       "                                              product  avg_rating  \\\n",
       "0   –í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...    0.819588   \n",
       "1   –í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...    0.819588   \n",
       "3   –í–´–†–£–ß–ê–ô–ö–ê / –ê–Ω—Ç–∏–±—É–∫—Å –ü—Ä–æ—Ç–∏–≤–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ ...    0.842975   \n",
       "4   –ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...    0.704545   \n",
       "5   –ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...    0.704545   \n",
       "6   –ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...    0.704545   \n",
       "7   –ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...    0.853933   \n",
       "8   –ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...    0.853933   \n",
       "9   –ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...    0.853933   \n",
       "10  –ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...    0.853933   \n",
       "\n",
       "   rating_category                                  cluster_sentences  \\\n",
       "0          neutral  –ü–µ—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–µ—Å–æ –∑–∞–∫—Ä—ã–ª–æ—Å—å –≤ —Å–Ω–µ–≥—É, –ø–æ–¥–ª–æ–∂–∏–ª–∏ –ø...   \n",
       "1          neutral  –ù–∞ –≤–∏–¥ –∫—Ä–µ–ø–∫–∏–µ. | –í—Ä–æ–¥–µ –ø—Ä–æ—á–Ω—ã–µ. | –ù–∞ –≤–∏–¥ –ø—Ä–æ—á...   \n",
       "3          neutral  –í –¥–µ–ª–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª | –í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞....   \n",
       "4          neutral  –†–µ–∫–æ–º–µ–Ω–¥—É—é, –±—É–¥—É –±—Ä–∞—Ç—å –µ—â–µ | –ó–∞–∫–∞–∂—É | –º—ã–ú—ã–æ—á–Ω–æ...   \n",
       "5          neutral  –ï–ª–µ –ø–∞—Ö–Ω–µ—Ç. | –û–Ω –¥–∞–∂–µ –Ω–µ –ø–∞—Ö–Ω–µ—Ç. | –ü–∞—Ö–Ω–µ—Ç –∫–∞–∫–∏...   \n",
       "6          neutral  üî•üî•üî•üî•üî•üî• –∑–∞–ø–∞—Ö. | –ó–∞–ø–∞—Ö –æ–≥–æ–Ω—å) | –ó–∞–ø–∞—Ö –æ–≥–æ–Ω—å!!!!...   \n",
       "7          neutral  –£–±–∏—Ä–∞–µ—Ç —Ä–∂–∞–≤—á–∏–Ω—É —Ö–æ—Ä–æ—à–æ —á–µ—Ä–µ–∑ 10-20 –º–∏–Ω—É—Ç | –°–æ...   \n",
       "8          neutral  –†–∂–∞–≤—á–∏–Ω–∞ —É–∂–µ —Ö–æ—Ä–æ—à–æ –≤—ä–µ–ª–∞—Å—å, –ø—Ä–∏—à–ª–æ—Å—å –Ω–µ—Å–∫–æ–ª—å–∫...   \n",
       "9          neutral  –§–æ—Ç–æ ¬´–¥–æ¬ª –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é –Ω–µ —Å–¥–µ–ª–∞–ª–∞, —Ç–æ–ª—å–∫–æ ¬´–ø–æ—Å–ª...   \n",
       "10         neutral  –í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞. | –í –¥–µ–ª–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª...   \n",
       "\n",
       "    word_count                                        key_thought  \n",
       "0           40  –ü–µ—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–µ—Å–æ –∑–∞–∫—Ä—ã–ª–æ—Å—å –≤ —Å–Ω–µ–≥—É, –ø–æ–¥–ª–æ–∂–∏–ª–∏ –ø...  \n",
       "1           12                                    –ù–∞ –≤–∏–¥ –∫—Ä–µ–ø–∫–∏–µ.  \n",
       "3           37                                 –í –¥–µ–ª–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª  \n",
       "4           20                               –ë—É–¥—É –∑–∞–∫–∞–∑—ã–≤–∞—Ç—å –µ—â—ë.  \n",
       "5           13                                        –ï–ª–µ –ø–∞—Ö–Ω–µ—Ç.  \n",
       "6           11                                         –ó–∞–ø–∞—Ö üî•!!!  \n",
       "7           76                          –†–∂–∞–≤—á–∏–Ω—É —É–±–∏—Ä–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ.  \n",
       "8           38  –†–∂–∞–≤—á–∏–Ω–∞ —É–∂–µ —Ö–æ—Ä–æ—à–æ –≤—ä–µ–ª–∞—Å—å, –ø—Ä–∏—à–ª–æ—Å—å –Ω–µ—Å–∫–æ–ª—å–∫...  \n",
       "9           24   –§–æ—Ç–æ ¬´–¥–æ¬ª –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é –Ω–µ —Å–¥–µ–ª–∞–ª–∞, —Ç–æ–ª—å–∫–æ ¬´–ø–æ—Å–ª–µ¬ª  \n",
       "10          14                                 –í –¥–µ–ª–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>word_count</th>\n",
       "      <th>key_thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/–°–ø–æ—Ä—Ç/–°—Ç—Ä–∞–π–∫–±–æ–ª –∏ –ø–µ–π–Ω—Ç–±–æ–ª/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>karbi / –†—é–∫–∑–∞–∫ —Ç–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π - –∫–∞—Ä...</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–ú–Ω–æ–≥–æ –¥–æ–ø –∫–∞—Ä–º–∞–Ω–æ–≤, —á–µ—Ö–æ–ª –æ—Ç –¥–æ–∂–¥—è, –ø—Ä–æ—Ä–µ–∑–∏–Ω–µ–Ω...</td>\n",
       "      <td>203</td>\n",
       "      <td>–†—é–∫–∑–∞–∫ –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å–Ω—ã–π, –ø—Ä–æ—á–Ω—ã–π, –µ—Å—Ç—å –∑–∞—â–∏—Ç–Ω—ã–π —á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/–°–ø–æ—Ä—Ç/–°—Ç—Ä–∞–π–∫–±–æ–ª –∏ –ø–µ–π–Ω—Ç–±–æ–ª/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>karbi / –†—é–∫–∑–∞–∫ —Ç–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π - –∫–∞—Ä...</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–í –ø–æ–¥–∞—Ä–æ–∫ —à—ë–ª –∫–æ–º–ø–∞—Å,, –Ω–∞–ª–æ–±–Ω—ã–π—Ñ–æ–Ω–∞—Ä—å,, –Ω–æ–∂–∞–Ω–µ...</td>\n",
       "      <td>69</td>\n",
       "      <td>–í –ø–æ–¥–∞—Ä–æ–∫ –ø–æ–ª–æ–∂–∏–ª–∏ —Ñ–æ–Ω–∞—Ä–∏–∫ –Ω–∞–ª–æ–±–Ω—ã–π, –∫–æ–º–ø–∞—Å –∏ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 category  \\\n",
       "0  /–°–ø–æ—Ä—Ç/–°—Ç—Ä–∞–π–∫–±–æ–ª –∏ –ø–µ–π–Ω—Ç–±–æ–ª/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "1  /–°–ø–æ—Ä—Ç/–°—Ç—Ä–∞–π–∫–±–æ–ª –∏ –ø–µ–π–Ω—Ç–±–æ–ª/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "\n",
       "                                             product  avg_rating  \\\n",
       "0  karbi / –†—é–∫–∑–∞–∫ —Ç–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π - –∫–∞—Ä...    0.797101   \n",
       "1  karbi / –†—é–∫–∑–∞–∫ —Ç–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π - –∫–∞—Ä...    0.797101   \n",
       "\n",
       "  rating_category                                  cluster_sentences  \\\n",
       "0         neutral  –ú–Ω–æ–≥–æ –¥–æ–ø –∫–∞—Ä–º–∞–Ω–æ–≤, —á–µ—Ö–æ–ª –æ—Ç –¥–æ–∂–¥—è, –ø—Ä–æ—Ä–µ–∑–∏–Ω–µ–Ω...   \n",
       "1         neutral  –í –ø–æ–¥–∞—Ä–æ–∫ —à—ë–ª –∫–æ–º–ø–∞—Å,, –Ω–∞–ª–æ–±–Ω—ã–π—Ñ–æ–Ω–∞—Ä—å,, –Ω–æ–∂–∞–Ω–µ...   \n",
       "\n",
       "   word_count                                        key_thought  \n",
       "0         203  –†—é–∫–∑–∞–∫ –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å–Ω—ã–π, –ø—Ä–æ—á–Ω—ã–π, –µ—Å—Ç—å –∑–∞—â–∏—Ç–Ω—ã–π —á...  \n",
       "1          69  –í –ø–æ–¥–∞—Ä–æ–∫ –ø–æ–ª–æ–∂–∏–ª–∏ —Ñ–æ–Ω–∞—Ä–∏–∫ –Ω–∞–ª–æ–±–Ω—ã–π, –∫–æ–º–ø–∞—Å –∏ ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
=======
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –≠—Ç–∞–ø 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf.pandas  # –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ cuDF –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏—è –µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "cudf.pandas.install()  # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ cuDF –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –¥–ª—è pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
<<<<<<< HEAD
    "import torch\n",
    "import pyarrow.parquet as pq\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# # –ß—Ç–µ–Ω–∏–µ Parquet-—Ñ–∞–π–ª–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º pyarrow\n",
    "# table = pq.read_table('./reviews_keywords/wildberries_reviews_corrected.parquet')\n",
    "\n",
    "# # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ pandas DataFrame\n",
    "# df_pandas = table.to_pandas()\n",
    "\n",
    "# # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ pandas DataFrame –≤ Dask DataFrame\n",
    "# df_dask = dd.from_pandas(df_pandas, npartitions=100)  # –£–∫–∞–∂–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω—É–∂–Ω—ã—Ö –≤–∞–º —á–∞—Å—Ç–µ–π\n",
    "# df_pandas = None\n",
    "# table = None\n",
    "# import gc\n",
    "# gc.collect()\n",
    "# df_dask"
=======
    "import torch"
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "<class 'cudf.core.dataframe.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype\n",
      "---  ------            --------------  -----\n",
      " 0   Unnamed: 0        1000 non-null   int64\n",
      " 1   review_full_text  1000 non-null   object\n",
      " 2   review_rating     1000 non-null   int64\n",
      " 3   product           1000 non-null   object\n",
      " 4   category          1000 non-null   object\n",
      " 5   url               1000 non-null   object\n",
      " 6   corrected_text    1000 non-null   object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 540.9+ KB\n"
=======
      "–§–∞–π–ª '/workspace/wildberries_reviews.csv' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.\n"
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "result = pd.read_csv(\"./reviews_keywords/wildberries_reviews.csv\", nrows=1000)\n",
    "result.info()"
=======
    "import os\n",
    "import gdown\n",
    "\n",
    "def download_file_if_not_exists(file_url, output_path):\n",
    "    \"\"\"–°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª —Å Google Drive, –µ—Å–ª–∏ –æ–Ω –µ—â—ë –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.\"\"\"\n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–∞\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"–§–∞–π–ª '{output_path}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.\")\n",
    "    else:\n",
    "        print(f\"–§–∞–π–ª '{output_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É...\")\n",
    "        gdown.download(file_url, output_path, quiet=False)\n",
    "        print(f\"–§–∞–π–ª '{output_path}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.\")\n",
    "\n",
    "# –£–∫–∞–∑—ã–≤–∞–µ–º URL –∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É\n",
    "# file_url = 'https://drive.google.com/uc?id=15pofNbomaoUap41Rcn1uNGeiJIqFd2qe'\n",
    "file_url = 'https://drive.google.com/uc?id=1alondqI-2IHo__mYU7KQz4Ip8ytYGHXg'\n",
    "output_file_name = 'wildberries_reviews.csv'  # –£–∫–∞–∂–∏—Ç–µ —Ä–µ–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞, –∫–æ—Ç–æ—Ä–æ–µ —Ö–æ—Ç–∏—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å\n",
    "output_path = os.path.join(os.getcwd(), output_file_name)  # –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É\n",
    "\n",
    "download_file_if_not_exists(file_url, output_path)\n"
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
   "source": [
    "# –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ 5 –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç–æ–ª–±—Ü–µ 'product'\n",
    "# result_limited = result.groupby('product').apply(lambda x: x.iloc[5:8]).reset_index(drop=True)\n",
    "result_limited = result\n"
=======
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corrected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>362145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>244853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>–í—Å–µ –æ—Ç–ª–∏—á–Ω–æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       corrected_text\n",
       "count          362145\n",
       "unique         244853\n",
       "top       –í—Å–µ –æ—Ç–ª–∏—á–Ω–æ\n",
       "freq               87"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å CSV —Ñ–∞–π–ª–∞–º–∏\n",
    "folder_path = './reviews_keywords/corrected_reviews'\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# –ß–∏—Ç–∞–µ–º –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ CSV —Ñ–∞–π–ª—ã –≤ –æ–¥–∏–Ω –¥–∞—Ç–∞—Ñ—Ä–µ–π–º\n",
    "df_list = [pd.read_csv(os.path.join(folder_path, file), index_col=\"id\") for file in csv_files]\n",
    "combined_df = pd.concat(df_list, ignore_index=False)\n",
    "\n",
    "combined_df.index = combined_df.index - 1\n",
    "combined_df = pd.concat([pd.read_csv(\"wildberries_reviews.csv\")[[\"corrected_text\"]], combined_df], ignore_index=False)\n",
    "# –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "combined_df.describe()\n"
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
   "source": [
=======
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corrected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–í—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ, –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479799</th>\n",
       "      <td>–ü–∏—Å—Ç–æ–ª–µ—Ç —Å—É–ø–µ—Ä, –æ—á–µ–Ω—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π. –°–≤–µ—Ç–∏—Ç—Å—è, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479819</th>\n",
       "      <td>–ü–∏—Å—Ç–æ–ª–µ—Ç –ø—Ä–∏—à–µ–ª, —Ö–æ—Ä–æ—à–æ —É–ø–∞–∫–æ–≤–∞–Ω, –∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏—è...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479834</th>\n",
       "      <td>–ö–ª–∞—Å—Å–Ω—ã–π –ø–∏—Å—Ç–æ–ª–µ—Ç, –≤—ã–ø—É—Å–∫–∞–µ—Ç –æ–≥—Ä–æ–º–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479841</th>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π –ø–∏—Å—Ç–æ–ª–µ—Ç, –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–πüëå–†–µ–±—ë–Ω–æ–∫ –≤ –≤–æ—Å—Ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479866</th>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π –ø–∏—Å—Ç–æ–ª–µ—Ç. –í—Å–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∫–ª–∞—Å—Å–Ω–æ —á—Ç–æ –≤...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362145 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            corrected_text\n",
       "0                                         –†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.\n",
       "1        –ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...\n",
       "2        –ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...\n",
       "3        –õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...\n",
       "4        –í—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ, –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑...\n",
       "...                                                    ...\n",
       "1479799  –ü–∏—Å—Ç–æ–ª–µ—Ç —Å—É–ø–µ—Ä, –æ—á–µ–Ω—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π. –°–≤–µ—Ç–∏—Ç—Å—è, ...\n",
       "1479819  –ü–∏—Å—Ç–æ–ª–µ—Ç –ø—Ä–∏—à–µ–ª, —Ö–æ—Ä–æ—à–æ —É–ø–∞–∫–æ–≤–∞–Ω, –∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏—è...\n",
       "1479834  –ö–ª–∞—Å—Å–Ω—ã–π –ø–∏—Å—Ç–æ–ª–µ—Ç, –≤—ã–ø—É—Å–∫–∞–µ—Ç –æ–≥—Ä–æ–º–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç...\n",
       "1479841  –û—Ç–ª–∏—á–Ω—ã–π –ø–∏—Å—Ç–æ–ª–µ—Ç, –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–πüëå–†–µ–±—ë–Ω–æ–∫ –≤ –≤–æ—Å—Ç...\n",
       "1479866  –û—Ç–ª–∏—á–Ω—ã–π –ø–∏—Å—Ç–æ–ª–µ—Ç. –í—Å–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∫–ª–∞—Å—Å–Ω–æ —á—Ç–æ –≤...\n",
       "\n",
       "[362145 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_full_text</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–í—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ, –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    review_full_text  review_rating  \\\n",
       "0                                   –†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.              5   \n",
       "1  –ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...              5   \n",
       "2  –ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...              5   \n",
       "3  –õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...              5   \n",
       "4  –í—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ, –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑...              5   \n",
       "\n",
       "                                             product             category  \\\n",
       "0  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "1  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "2  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "3  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "4  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.wildberries.ru/catalog/162315454/f...  \n",
       "1  https://www.wildberries.ru/catalog/162315454/f...  \n",
       "2  https://www.wildberries.ru/catalog/162315454/f...  \n",
       "3  https://www.wildberries.ru/catalog/162315454/f...  \n",
       "4  https://www.wildberries.ru/catalog/162315454/f...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_big = pd.read_csv(\"wildberries_reviews.csv.gz\", compression=\"gzip\").drop(\"Unnamed: 0\", axis=1)[:1479867]\n",
    "df_raw_big.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.479877e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.607101e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.014978e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_rating\n",
       "count   1.479877e+06\n",
       "mean    4.607101e+00\n",
       "std     1.014978e+00\n",
       "min     1.000000e+00\n",
       "25%     5.000000e+00\n",
       "50%     5.000000e+00\n",
       "75%     5.000000e+00\n",
       "max     5.000000e+00"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = combined_df.merge(df_raw_big, left_index=True, right_index=True, how='right')\n",
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['corrected_text'] = result['corrected_text'].fillna(result['review_full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_full_text</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "      <th>corrected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>–†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>–ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>–ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>–õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–í—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ, –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>–í—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ, –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    review_full_text  review_rating  \\\n",
       "0                                   –†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.              5   \n",
       "1  –ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...              5   \n",
       "2  –ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...              5   \n",
       "3  –õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...              5   \n",
       "4  –í—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ, –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑...              5   \n",
       "\n",
       "                                             product             category  \\\n",
       "0  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "1  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "2  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "3  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "4  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "1  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "2  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "3  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "4  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "\n",
       "                                      corrected_text  \n",
       "0                                   –†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.  \n",
       "1  –ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...  \n",
       "2  –ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...  \n",
       "3  –õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...  \n",
       "4  –í—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ, –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ 5 –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç–æ–ª–±—Ü–µ 'product'\n",
    "# result_limited = result.groupby('product').apply(lambda x: x.iloc[5:8]).reset_index(drop=True)\n",
    "result_limited = result[result.category == result.iloc[-260000].category]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d44c0204b52453f8875b9bf0ff7d966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
    "import spacy\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
<<<<<<< HEAD
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ –æ—Ç –°–±–µ—Ä–±–∞–Ω–∫–∞\n",
    "tokenizer = AutoTokenizer.from_pretrained('sberbank-ai/sbert_large_nlu_ru')\n",
    "model = AutoModel.from_pretrained('sberbank-ai/sbert_large_nlu_ru').to(device)\n",
    "\n",
    "spacy.prefer_gpu()\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ SpaCy\n",
    "nlp = spacy.load(\"ru_core_news_lg\", disable=[\"ner\", \"tagger\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "\n",
    "df = result_limited\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ pandas DataFrame –≤ Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa4bfffd4f74d36b904bc9bb6a6cdd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b622cbce41e54fed8bf3eb1c340925e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2061 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/tmp/ipykernel_1209/3927185444.py:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # –ò—Å–ø–æ–ª—å–∑—É–µ–º mixed precision –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[\\n\\r\\t]+|\\s{2,}', ' ', text)  # –û–±—ä–µ–¥–∏–Ω—è–µ–º —à–∞–≥–∏ –¥–ª—è –∑–∞–º–µ–Ω—ã –ø—Ä–æ–±–µ–ª–æ–≤\n",
    "    text = re.sub(r'(?<!\\.)\\s*\\.\\s*|\\s*\\.\\s*(?!\\.)', '. ', text)  # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–º–µ–Ω—ã —Ç–æ—á–∫–∏\n",
    "    return text.strip().rstrip('.')\n",
    "\n",
    "def split_reviews_into_sentences(batch):\n",
    "    # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤\n",
    "    cleaned_texts = [clean_text(text) for text in batch['corrected_text']]\n",
    "    \n",
    "    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é nlp.pipe —Å —É–∫–∞–∑–∞–Ω–∏–µ–º batch_size\n",
    "    docs = list(nlp.pipe(cleaned_texts, batch_size=64))  # –ó–¥–µ—Å—å 64 - –ø—Ä–∏–º–µ—Ä –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "\n",
    "    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
    "    batch['sentences'] = [[sent.text for sent in doc.sents] for doc in docs]\n",
    "    \n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(split_reviews_into_sentences, batched=True, batch_size=32)\n",
=======
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ SpaCy\n",
    "nlp = spacy.load(\"ru_core_news_lg\")\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ pandas DataFrame\n",
    "df_raw = pd.read_csv(\"wildberries_reviews.csv\", nrows=30000)\n",
    "# df = df_raw[-500:-1]  # –û—Ç–±–æ—Ä 500 –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "df = result_limited\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ pandas DataFrame –≤ Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # –°–Ω–∞—á–∞–ª–∞ –∑–∞–º–µ–Ω—è–µ–º –≤—Å–µ \\n, \\r, \\t –Ω–∞ –ø—Ä–æ–±–µ–ª\n",
    "    text = re.sub(r'[\\n\\r\\t]+', ' ', text)\n",
    "    \n",
    "    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "\n",
    "    # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª –∏ —Ç–æ—á–∫—É (–µ—Å–ª–∏ —Ç–æ—á–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)\n",
    "    text = re.sub(r'(?<!\\.)\\s*\\.\\s*', '. ', text)  # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –ø–æ—Å–ª–µ –∑–∞–º–µ–Ω—ã –µ—Å—Ç—å —Ç–æ—á–∫–∞ –∏ –ø—Ä–æ–±–µ–ª\n",
    "    text = re.sub(r'\\s*\\.\\s*(?!\\.)', ' ', text)  # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–µ—Ä–µ–¥ —Ç–æ—á–∫–æ–π, –µ—Å–ª–∏ —Ç–æ—á–∫–∞ –µ—Å—Ç—å\n",
    "    \n",
    "    # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è —Ç–æ—á–∫–æ–π, —É–±–∏—Ä–∞–µ–º –µ—ë\n",
    "    text = re.sub(r'\\s*\\.$', '', text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n",
    "def split_into_sentences(text):\n",
    "    doc = nlp(clean_text(text))\n",
    "    return [sent.text for sent in doc.sents]\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n",
    "def split_reviews_into_sentences(batch):\n",
    "    batch['sentences'] = [split_into_sentences(text) for text in batch['corrected_text']]\n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(split_reviews_into_sentences, batched=True, batch_size=8)\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º Dataset –æ–±—Ä–∞—Ç–Ω–æ –≤ pandas DataFrame\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "# –í—ã–ø–æ–ª–Ω–∏–º explode –ø–æ —Å—Ç–æ–ª–±—Ü—É —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏\n",
    "df_exploded = df.explode('sentences').reset_index(drop=True)\n",
    "\n",
    "# –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ —Å—Ç–æ–ª–±—Ü—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ—è–≤–∏–ª–∏—Å—å –ø–æ—Å–ª–µ explode\n",
    "df_exploded = df_exploded.drop(columns=[col for col in df_exploded.columns if col.startswith('__index_level_')])\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º DataFrame –æ–±—Ä–∞—Ç–Ω–æ –≤ Hugging Face Dataset\n",
<<<<<<< HEAD
    "dataset_exploded = Dataset.from_pandas(df_exploded)\n",
    "\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "def compute_sentence_embeddings(sentences):\n",
    "    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ø–∏—Å–æ–∫, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏\n",
    "    sentences = [str(sentence) for sentence in sentences if isinstance(sentence, str)]\n",
    "    \n",
    "    if not sentences:\n",
    "        raise ValueError(\"Input contains no valid strings.\")\n",
    "\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with autocast():  # –ò—Å–ø–æ–ª—å–∑—É–µ–º mixed precision –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è\n",
    "            outputs = model(**inputs)\n",
    "    \n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "def compute_embeddings_after_explode(batch):\n",
    "    sentences = batch['sentences']\n",
    "\n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤ batch —è–≤–ª—è—é—Ç—Å—è —Å—Ç—Ä–æ–∫–∞–º–∏\n",
    "    valid_sentences = [str(sentence) for sentence in sentences if isinstance(sentence, str)]\n",
    "    \n",
    "    if not valid_sentences:\n",
    "        batch['sentence_embeddings'] = [[]] * len(sentences)  # –ï—Å–ª–∏ –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏\n",
    "        return batch\n",
    "\n",
    "    embeddings = compute_sentence_embeddings(valid_sentences)\n",
    "\n",
    "    # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∫ —Ç–∏–ø—É float32 –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏\n",
    "    embeddings = embeddings.astype(np.float32)\n",
    "\n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
    "    if len(embeddings) != len(valid_sentences):\n",
    "        raise ValueError(\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.\")\n",
    "    \n",
    "    # –ï—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∏—Å—Ö–æ–¥–Ω—ã–º, –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "    final_embeddings = []\n",
    "    embed_idx = 0\n",
    "    for sentence in sentences:\n",
    "        if isinstance(sentence, str):\n",
    "            final_embeddings.append(embeddings[embed_idx])\n",
    "            embed_idx += 1\n",
    "        else:\n",
    "            final_embeddings.append(np.zeros(embeddings.shape[1], dtype=np.float32))  # –î–æ–±–∞–≤–ª—è–µ–º –Ω—É–ª–µ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
    "\n",
    "    batch['sentence_embeddings'] = final_embeddings\n",
    "    return batch\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "dataset = dataset_exploded.map(compute_embeddings_after_explode, batched=True, batch_size=128)\n"
=======
    "dataset_exploded = Dataset.from_pandas(df_exploded)"
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, BertConfig\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import hdbscan  # HDBSCAN –¥–ª—è –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ –≤ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–µ Hugging Face\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (GPU –∏–ª–∏ CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π\n",
    "config = BertConfig.from_pretrained('./reviews_keywords/fine_tuned_model', output_hidden_states=True)\n",
    "tokenizer = BertTokenizerFast.from_pretrained('./reviews_keywords/fine_tuned_model')\n",
    "model = BertForSequenceClassification.from_pretrained('./reviews_keywords/fine_tuned_model', config=config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
=======
   "execution_count": 11,
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤:   0%|                                                                                                                                                                        | 0/65 [00:00<?, ?it/s]/tmp/ipykernel_1209/1947295901.py:59: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–º–µ—à–∞–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65/65 [00:10<00:00,  6.32it/s]\n"
=======
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:13<00:00,  1.54it/s]\n"
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>Unnamed: 0</th>\n",
=======
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
       "      <th>review_full_text</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "      <th>corrected_text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
       "      <td>0</td>\n",
       "      <td>–†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>–†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.</td>\n",
       "      <td>–†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>–ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>–ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...</td>\n",
       "      <td>–ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥.</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>–ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>–ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...</td>\n",
       "      <td>–ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏—Å–ø—ã—Ç—ã–≤–∞—Ç—å</td>\n",
=======
       "      <td>–ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...</td>\n",
       "      <td>5</td>\n",
       "      <td>Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...</td>\n",
       "      <td>/–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>https://www.wildberries.ru/catalog/208661951/f...</td>\n",
       "      <td>–ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...</td>\n",
       "      <td>–ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...</td>\n",
       "      <td>5</td>\n",
       "      <td>Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...</td>\n",
       "      <td>/–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>https://www.wildberries.ru/catalog/208661951/f...</td>\n",
       "      <td>–ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...</td>\n",
       "      <td>–∑–∞–∫–∞–∑–∞—Ç—å</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ù—É —Ö–æ—Ä–æ—à–∞—è –∫–µ–ø–∫–∞, –Ω–æ —Ç–æ–ª—å–∫–æ –∫–æ–∑—ã—Ä–µ–∫ –Ω–µ–º–Ω–æ–≥–æ –¥–ª...</td>\n",
       "      <td>5</td>\n",
       "      <td>Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...</td>\n",
       "      <td>/–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>https://www.wildberries.ru/catalog/208661951/f...</td>\n",
       "      <td>–ù—É —Ö–æ—Ä–æ—à–∞—è –∫–µ–ø–∫–∞, –Ω–æ —Ç–æ–ª—å–∫–æ –∫–æ–∑—ã—Ä–µ–∫ –Ω–µ–º–Ω–æ–≥–æ –¥–ª...</td>\n",
       "      <td>–ù—É —Ö–æ—Ä–æ—à–∞—è –∫–µ–ø–∫–∞, –Ω–æ —Ç–æ–ª—å–∫–æ –∫–æ–∑—ã—Ä–µ–∫ –Ω–µ–º–Ω–æ–≥–æ –¥–ª...</td>\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
<<<<<<< HEAD
       "      <td>2</td>\n",
       "      <td>–ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>–ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...</td>\n",
       "      <td>–ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...</td>\n",
=======
       "      <td>–ù—É—É—É —Ç–∞–∫–∞—è —Å–µ–±–µ, –ø–æ—Å–∞–¥–∫–∞ –Ω–µ –≥–ª—É–±–æ–∫–∞—è, –∑–∞—Ç—è–Ω—É–ª–∞...</td>\n",
       "      <td>4</td>\n",
       "      <td>Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...</td>\n",
       "      <td>/–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>https://www.wildberries.ru/catalog/208661951/f...</td>\n",
       "      <td>–ù—É—É—É —Ç–∞–∫–∞—è —Å–µ–±–µ, –ø–æ—Å–∞–¥–∫–∞ –Ω–µ –≥–ª—É–±–æ–∫–∞—è, –∑–∞—Ç—è–Ω—É–ª–∞...</td>\n",
       "      <td>–ù—É—É—É —Ç–∞–∫–∞—è —Å–µ–±–µ, –ø–æ—Å–∞–¥–∫–∞ –Ω–µ –≥–ª—É–±–æ–∫–∞—è, –∑–∞—Ç—è–Ω—É–ª–∞...</td>\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
<<<<<<< HEAD
       "      <td>3</td>\n",
       "      <td>–õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>–õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...</td>\n",
       "      <td>–õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è.</td>\n",
=======
       "      <td>–ö–µ–ø–∫–∞ –±–µ—Å—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è, –ø–µ—Ä–µ–¥–Ω–∏–π —à–æ–≤ –∫–æ—Å–æ–π, –Ω–∞ –≥–æ–ª...</td>\n",
       "      <td>3</td>\n",
       "      <td>Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...</td>\n",
       "      <td>/–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>https://www.wildberries.ru/catalog/208661951/f...</td>\n",
       "      <td>–ö–µ–ø–∫–∞ –±–µ—Å—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è, –ø–µ—Ä–µ–¥–Ω–∏–π —à–æ–≤ –∫–æ—Å–æ–π, –Ω–∞ –≥–æ–ª...</td>\n",
       "      <td>–ö–µ–ø–∫–∞ –±–µ—Å—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è, –ø–µ—Ä–µ–¥–Ω–∏–π —à–æ–≤ –∫–æ—Å–æ–π, –Ω–∞ –≥–æ–ª...</td>\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "   Unnamed: 0                                   review_full_text  \\\n",
       "0           0                                   –†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.   \n",
       "1           1  –ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...   \n",
       "2           1  –ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...   \n",
       "3           2  –ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...   \n",
       "4           3  –õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...   \n",
       "\n",
       "   review_rating                                            product  \\\n",
       "0              5  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...   \n",
       "1              5  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...   \n",
       "2              5  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...   \n",
       "3              5  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...   \n",
       "4              5  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...   \n",
       "\n",
       "              category                                                url  \\\n",
       "0  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "1  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "2  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "3  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "4  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "\n",
       "                                      corrected_text  \\\n",
       "0                                   –†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.   \n",
       "1  –ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...   \n",
       "2  –ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...   \n",
       "3  –ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...   \n",
       "4  –õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...   \n",
       "\n",
       "                                           sentences  __index_level_0__  \\\n",
       "0                                    –†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ                  0   \n",
       "1                   –ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥.                  1   \n",
       "2                             –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏—Å–ø—ã—Ç—ã–≤–∞—Ç—å                  2   \n",
       "3  –ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...                  3   \n",
       "4                                   –õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è.                  4   \n",
       "\n",
       "   predictions  \n",
       "0        False  \n",
       "1        False  \n",
=======
       "                                    review_full_text  review_rating  \\\n",
       "0  –ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...              5   \n",
       "1  –ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...              5   \n",
       "2  –ù—É —Ö–æ—Ä–æ—à–∞—è –∫–µ–ø–∫–∞, –Ω–æ —Ç–æ–ª—å–∫–æ –∫–æ–∑—ã—Ä–µ–∫ –Ω–µ–º–Ω–æ–≥–æ –¥–ª...              5   \n",
       "3  –ù—É—É—É —Ç–∞–∫–∞—è —Å–µ–±–µ, –ø–æ—Å–∞–¥–∫–∞ –Ω–µ –≥–ª—É–±–æ–∫–∞—è, –∑–∞—Ç—è–Ω—É–ª–∞...              4   \n",
       "4  –ö–µ–ø–∫–∞ –±–µ—Å—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è, –ø–µ—Ä–µ–¥–Ω–∏–π —à–æ–≤ –∫–æ—Å–æ–π, –Ω–∞ –≥–æ–ª...              3   \n",
       "\n",
       "                                             product  \\\n",
       "0  Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...   \n",
       "1  Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...   \n",
       "2  Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...   \n",
       "3  Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...   \n",
       "4  Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...   \n",
       "\n",
       "                            category  \\\n",
       "0  /–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "1  /–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "2  /–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "3  /–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "4  /–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.wildberries.ru/catalog/208661951/f...   \n",
       "1  https://www.wildberries.ru/catalog/208661951/f...   \n",
       "2  https://www.wildberries.ru/catalog/208661951/f...   \n",
       "3  https://www.wildberries.ru/catalog/208661951/f...   \n",
       "4  https://www.wildberries.ru/catalog/208661951/f...   \n",
       "\n",
       "                                      corrected_text  \\\n",
       "0  –ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...   \n",
       "1  –ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...   \n",
       "2  –ù—É —Ö–æ—Ä–æ—à–∞—è –∫–µ–ø–∫–∞, –Ω–æ —Ç–æ–ª—å–∫–æ –∫–æ–∑—ã—Ä–µ–∫ –Ω–µ–º–Ω–æ–≥–æ –¥–ª...   \n",
       "3  –ù—É—É—É —Ç–∞–∫–∞—è —Å–µ–±–µ, –ø–æ—Å–∞–¥–∫–∞ –Ω–µ –≥–ª—É–±–æ–∫–∞—è, –∑–∞—Ç—è–Ω—É–ª–∞...   \n",
       "4  –ö–µ–ø–∫–∞ –±–µ—Å—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è, –ø–µ—Ä–µ–¥–Ω–∏–π —à–æ–≤ –∫–æ—Å–æ–π, –Ω–∞ –≥–æ–ª...   \n",
       "\n",
       "                                           sentences  __index_level_0__  \\\n",
       "0  –ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...                  0   \n",
       "1                                           –∑–∞–∫–∞–∑–∞—Ç—å                  1   \n",
       "2  –ù—É —Ö–æ—Ä–æ—à–∞—è –∫–µ–ø–∫–∞, –Ω–æ —Ç–æ–ª—å–∫–æ –∫–æ–∑—ã—Ä–µ–∫ –Ω–µ–º–Ω–æ–≥–æ –¥–ª...                  2   \n",
       "3  –ù—É—É—É —Ç–∞–∫–∞—è —Å–µ–±–µ, –ø–æ—Å–∞–¥–∫–∞ –Ω–µ –≥–ª—É–±–æ–∫–∞—è, –∑–∞—Ç—è–Ω—É–ª–∞...                  3   \n",
       "4  –ö–µ–ø–∫–∞ –±–µ—Å—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è, –ø–µ—Ä–µ–¥–Ω–∏–π —à–æ–≤ –∫–æ—Å–æ–π, –Ω–∞ –≥–æ–ª...                  4   \n",
       "\n",
       "   predictions  \n",
       "0         True  \n",
       "1         True  \n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
       "2         True  \n",
       "3         True  \n",
       "4         True  "
      ]
     },
<<<<<<< HEAD
     "execution_count": 7,
=======
     "execution_count": 11,
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"  # –í–∫–ª—é—á–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (GPU –∏–ª–∏ CPU)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
=======
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ FP16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\n",
    "tokenizer = BertTokenizerFast.from_pretrained('./reviews_keywords/fine_tuned_model')\n",
    "model = BertForSequenceClassification.from_pretrained('./reviews_keywords/fine_tuned_model').to(device)\n",
    "\n",
    "# –ü–µ—Ä–µ–≤–æ–¥ –º–æ–¥–µ–ª–∏ –≤ —Ä–µ–∂–∏–º FP16, –µ—Å–ª–∏ —ç—Ç–æ –≤–æ–∑–º–æ–∂–Ω–æ\n",
<<<<<<< HEAD
    "if use_cuda:\n",
=======
    "if device.type == \"cuda\":\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
    "    model = model.half()\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)\n",
    "reviews = dataset_exploded[\"sentences\"]\n",
    "\n",
<<<<<<< HEAD
    "# –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "reviews = [str(review) for review in reviews if isinstance(review, str) and review.strip()]\n",
    "\n",
=======
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ Dataset –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–∑—ã–≤–æ–≤\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, tokenizer, max_len=128):\n",
    "        self.reviews = reviews\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = self.reviews[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {key: val.flatten() for key, val in encoding.items()}\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏ DataLoader\n",
    "dataset = ReviewDataset(reviews, tokenizer)\n",
<<<<<<< HEAD
    "batch_size = 32  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–±—ä–µ–º–∞ –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏ GPU\n",
=======
    "batch_size = 128\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞\n",
    "predictions = []\n",
    "\n",
<<<<<<< HEAD
    "from torch.cuda.amp import autocast  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º autocast –¥–ª—è —Å–º–µ—à–∞–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏\n",
    "\n",
    "for batch in tqdm(dataloader, desc=\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤\"):\n",
    "    batch = {key: val.to(device) for key, val in batch.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with autocast():  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–º–µ—à–∞–Ω–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs[0] if isinstance(outputs, tuple) else outputs.logits\n",
    "            probabilities = torch.softmax(logits, dim=-1)\n",
    "            batch_predictions = (probabilities[:, 1] > 0.7).cpu().numpy()  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ä–æ–≥ 0.7\n",
    "            predictions.extend(batch_predictions)\n",
=======
    "for batch in tqdm(dataloader, desc=\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤\"):\n",
    "    batch = {key: val.to(device) for key, val in batch.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs[0] if isinstance(outputs, tuple) else outputs.logits\n",
    "        probabilities = torch.softmax(logits, dim=-1)\n",
    "        batch_predictions = (probabilities[:, 1] > 0.9).cpu().numpy()  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ä–æ–≥ 0.6 –≤–º–µ—Å—Ç–æ 0.5\n",
    "        predictions.extend(batch_predictions)\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ DataFrame, –µ—Å–ª–∏ —ç—Ç–æ –µ—â–µ –Ω–µ —Å–¥–µ–ª–∞–Ω–æ\n",
    "if not isinstance(dataset_exploded, pd.DataFrame):\n",
    "    dataset_exploded = pd.DataFrame(dataset_exploded)\n",
    "\n",
<<<<<<< HEAD
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¥–ª–∏–Ω—ã\n",
    "if len(predictions) != len(dataset_exploded):\n",
    "    print(f\"Warning: Length of predictions ({len(predictions)}) does not match length of index ({len(dataset_exploded)})\")\n",
    "    \n",
    "    # –ü—Ä–∏–º–µ—Ä: –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "    if len(predictions) < len(dataset_exploded):\n",
    "        missing_count = len(dataset_exploded) - len(predictions)\n",
    "        predictions.extend([0] * missing_count)  # –î–æ–±–∞–≤–ª—è–µ–º –Ω—É–ª–∏ –≤ —Å–ª—É—á–∞–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "\n",
    "    elif len(predictions) > len(dataset_exploded):\n",
    "        predictions = predictions[:len(dataset_exploded)]  # –û–±—Ä–µ–∑–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "\n",
    "# –ü—Ä–∏—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∫ –¥–∞—Ç–∞—Å–µ—Ç—É\n",
    "dataset_exploded['predictions'] = predictions\n",
    "dataset_exploded.head()\n",
    "\n"
=======
    "# –ü—Ä–∏—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∫ –¥–∞—Ç–∞—Å–µ—Ç—É\n",
    "dataset_exploded['predictions'] = predictions\n",
    "dataset_exploded.head()\n"
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_full_text</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "      <th>corrected_text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...</td>\n",
       "      <td>5</td>\n",
       "      <td>Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...</td>\n",
       "      <td>/–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>https://www.wildberries.ru/catalog/208661951/f...</td>\n",
       "      <td>–ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...</td>\n",
       "      <td>–ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...</td>\n",
       "      <td>5</td>\n",
       "      <td>Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...</td>\n",
       "      <td>/–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>https://www.wildberries.ru/catalog/208661951/f...</td>\n",
       "      <td>–ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...</td>\n",
       "      <td>–∑–∞–∫–∞–∑–∞—Ç—å</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ù—É —Ö–æ—Ä–æ—à–∞—è –∫–µ–ø–∫–∞, –Ω–æ —Ç–æ–ª—å–∫–æ –∫–æ–∑—ã—Ä–µ–∫ –Ω–µ–º–Ω–æ–≥–æ –¥–ª...</td>\n",
       "      <td>5</td>\n",
       "      <td>Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...</td>\n",
       "      <td>/–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>https://www.wildberries.ru/catalog/208661951/f...</td>\n",
       "      <td>–ù—É —Ö–æ—Ä–æ—à–∞—è –∫–µ–ø–∫–∞, –Ω–æ —Ç–æ–ª—å–∫–æ –∫–æ–∑—ã—Ä–µ–∫ –Ω–µ–º–Ω–æ–≥–æ –¥–ª...</td>\n",
       "      <td>–ù—É —Ö–æ—Ä–æ—à–∞—è –∫–µ–ø–∫–∞, –Ω–æ —Ç–æ–ª—å–∫–æ –∫–æ–∑—ã—Ä–µ–∫ –Ω–µ–º–Ω–æ–≥–æ –¥–ª...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–ù—É—É—É —Ç–∞–∫–∞—è —Å–µ–±–µ, –ø–æ—Å–∞–¥–∫–∞ –Ω–µ –≥–ª—É–±–æ–∫–∞—è, –∑–∞—Ç—è–Ω—É–ª–∞...</td>\n",
       "      <td>4</td>\n",
       "      <td>Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...</td>\n",
       "      <td>/–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>https://www.wildberries.ru/catalog/208661951/f...</td>\n",
       "      <td>–ù—É—É—É —Ç–∞–∫–∞—è —Å–µ–±–µ, –ø–æ—Å–∞–¥–∫–∞ –Ω–µ –≥–ª—É–±–æ–∫–∞—è, –∑–∞—Ç—è–Ω—É–ª–∞...</td>\n",
       "      <td>–ù—É—É—É —Ç–∞–∫–∞—è —Å–µ–±–µ, –ø–æ—Å–∞–¥–∫–∞ –Ω–µ –≥–ª—É–±–æ–∫–∞—è, –∑–∞—Ç—è–Ω—É–ª–∞...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–ö–µ–ø–∫–∞ –±–µ—Å—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è, –ø–µ—Ä–µ–¥–Ω–∏–π —à–æ–≤ –∫–æ—Å–æ–π, –Ω–∞ –≥–æ–ª...</td>\n",
       "      <td>3</td>\n",
       "      <td>Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...</td>\n",
       "      <td>/–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>https://www.wildberries.ru/catalog/208661951/f...</td>\n",
       "      <td>–ö–µ–ø–∫–∞ –±–µ—Å—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è, –ø–µ—Ä–µ–¥–Ω–∏–π —à–æ–≤ –∫–æ—Å–æ–π, –Ω–∞ –≥–æ–ª...</td>\n",
       "      <td>–ö–µ–ø–∫–∞ –±–µ—Å—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è, –ø–µ—Ä–µ–¥–Ω–∏–π —à–æ–≤ –∫–æ—Å–æ–π, –Ω–∞ –≥–æ–ª...</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>–ö–∞–∫ –º–∞–º–∞ —Å–∫–∞–∑–∞–ª–∞:\" –û, —ç—Ç–æ —Ä—É—Å—Å–∫–∞—è —Å—É–º–∫–∞ \"üòÅ\\n–ü–æ...</td>\n",
       "      <td>5</td>\n",
       "      <td>S.LAVIA / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –º–∞–ª–µ–Ω—å–∫–∞—è –∫—Ä–æ—Å—Å-–±–æ–¥–∏</td>\n",
       "      <td>/–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>https://www.wildberries.ru/catalog/12487419/fe...</td>\n",
       "      <td>–ö–∞–∫ –º–∞–º–∞ —Å–∫–∞–∑–∞–ª–∞:\" –û, —ç—Ç–æ —Ä—É—Å—Å–∫–∞—è —Å—É–º–∫–∞ \"üòÅ\\n–ü–æ...</td>\n",
       "      <td>–ö–∞–∫ –º–∞–º–∞ —Å–∫–∞–∑–∞–ª–∞:\" –û, —ç—Ç–æ —Ä—É—Å—Å–∫–∞—è —Å—É–º–∫–∞ \"üòÅ –ü–æ–∫...</td>\n",
       "      <td>2618</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>–ü—Ä–∏—à–ª–∞ –≤ –∏–¥–µ–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, –æ—á–µ–Ω—å –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å...</td>\n",
       "      <td>5</td>\n",
       "      <td>S.LAVIA / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –º–∞–ª–µ–Ω—å–∫–∞—è –∫—Ä–æ—Å—Å-–±–æ–¥–∏</td>\n",
       "      <td>/–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>https://www.wildberries.ru/catalog/12487419/fe...</td>\n",
       "      <td>–ü—Ä–∏—à–ª–∞ –≤ –∏–¥–µ–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, –æ—á–µ–Ω—å –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å...</td>\n",
       "      <td>–ü—Ä–∏—à–ª–∞ –≤ –∏–¥–µ–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, –æ—á–µ–Ω—å –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å...</td>\n",
       "      <td>2622</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>–°—É–º–∫–∞ –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å. –£–¥–æ–±–Ω–∞—è, –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å–Ω–∞—è) –∑–∞ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>S.LAVIA / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –º–∞–ª–µ–Ω—å–∫–∞—è –∫—Ä–æ—Å—Å-–±–æ–¥–∏</td>\n",
       "      <td>/–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>https://www.wildberries.ru/catalog/12487419/fe...</td>\n",
       "      <td>–°—É–º–∫–∞ –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å. –£–¥–æ–±–Ω–∞—è, –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å–Ω–∞—è) –∑–∞ ...</td>\n",
       "      <td>–Ω–∞–¥–µ—é—Å—å, –±—ã—Å—Ç—Ä–æ –Ω–µ –æ–±–ª–µ–∑–µ—Ç</td>\n",
       "      <td>2624</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>–ú–∞–ª–µ–Ω—å–∫–∞—è, –Ω–æ –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å–Ω–∞—è. –ê–∫–∫—É—Ä–∞—Ç–Ω–æ —Å—à–∏—Ç–∞, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>S.LAVIA / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –º–∞–ª–µ–Ω—å–∫–∞—è –∫—Ä–æ—Å—Å-–±–æ–¥–∏</td>\n",
       "      <td>/–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>https://www.wildberries.ru/catalog/12487419/fe...</td>\n",
       "      <td>–ú–∞–ª–µ–Ω—å–∫–∞—è, –Ω–æ –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å–Ω–∞—è. –ê–∫–∫—É—Ä–∞—Ç–Ω–æ —Å—à–∏—Ç–∞, ...</td>\n",
       "      <td>–ú–∞–ª–µ–Ω—å–∫–∞—è, –Ω–æ –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å–Ω–∞—è –ê–∫–∫—É—Ä–∞—Ç–Ω–æ —Å—à–∏—Ç–∞, –≤...</td>\n",
       "      <td>2625</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>–ö–ª–∞—Å—Å–Ω–∞—è —Å—É–º–æ—á–∫–∞. –Ø –¥—É–º–∞–ª–∞ –æ–Ω–∞ –º–Ω–µ –±—É–¥–µ—Ç –±–æ–ª—å—à...</td>\n",
       "      <td>5</td>\n",
       "      <td>S.LAVIA / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –º–∞–ª–µ–Ω—å–∫–∞—è –∫—Ä–æ—Å—Å-–±–æ–¥–∏</td>\n",
       "      <td>/–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã</td>\n",
       "      <td>https://www.wildberries.ru/catalog/12487419/fe...</td>\n",
       "      <td>–ö–ª–∞—Å—Å–Ω–∞—è —Å—É–º–æ—á–∫–∞. –Ø –¥—É–º–∞–ª–∞ –æ–Ω–∞ –º–Ω–µ –±—É–¥–µ—Ç –±–æ–ª—å—à...</td>\n",
       "      <td>–ö–ª–∞—Å—Å–Ω–∞—è —Å—É–º–æ—á–∫–∞ –Ø –¥—É–º–∞–ª–∞ –æ–Ω–∞ –º–Ω–µ –±—É–¥–µ—Ç –±–æ–ª—å—à–µ...</td>\n",
       "      <td>2627</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1230 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       review_full_text  review_rating  \\\n",
       "0     –ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...              5   \n",
       "1     –ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...              5   \n",
       "2     –ù—É —Ö–æ—Ä–æ—à–∞—è –∫–µ–ø–∫–∞, –Ω–æ —Ç–æ–ª—å–∫–æ –∫–æ–∑—ã—Ä–µ–∫ –Ω–µ–º–Ω–æ–≥–æ –¥–ª...              5   \n",
       "3     –ù—É—É—É —Ç–∞–∫–∞—è —Å–µ–±–µ, –ø–æ—Å–∞–¥–∫–∞ –Ω–µ –≥–ª—É–±–æ–∫–∞—è, –∑–∞—Ç—è–Ω—É–ª–∞...              4   \n",
       "4     –ö–µ–ø–∫–∞ –±–µ—Å—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è, –ø–µ—Ä–µ–¥–Ω–∏–π —à–æ–≤ –∫–æ—Å–æ–π, –Ω–∞ –≥–æ–ª...              3   \n",
       "...                                                 ...            ...   \n",
       "2618  –ö–∞–∫ –º–∞–º–∞ —Å–∫–∞–∑–∞–ª–∞:\" –û, —ç—Ç–æ —Ä—É—Å—Å–∫–∞—è —Å—É–º–∫–∞ \"üòÅ\\n–ü–æ...              5   \n",
       "2622  –ü—Ä–∏—à–ª–∞ –≤ –∏–¥–µ–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, –æ—á–µ–Ω—å –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å...              5   \n",
       "2624  –°—É–º–∫–∞ –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å. –£–¥–æ–±–Ω–∞—è, –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å–Ω–∞—è) –∑–∞ ...              5   \n",
       "2625  –ú–∞–ª–µ–Ω—å–∫–∞—è, –Ω–æ –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å–Ω–∞—è. –ê–∫–∫—É—Ä–∞—Ç–Ω–æ —Å—à–∏—Ç–∞, ...              5   \n",
       "2627  –ö–ª–∞—Å—Å–Ω–∞—è —Å—É–º–æ—á–∫–∞. –Ø –¥—É–º–∞–ª–∞ –æ–Ω–∞ –º–Ω–µ –±—É–¥–µ—Ç –±–æ–ª—å—à...              5   \n",
       "\n",
       "                                                product  \\\n",
       "0     Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...   \n",
       "1     Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...   \n",
       "2     Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...   \n",
       "3     Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...   \n",
       "4     Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...   \n",
       "...                                                 ...   \n",
       "2618   S.LAVIA / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –º–∞–ª–µ–Ω—å–∫–∞—è –∫—Ä–æ—Å—Å-–±–æ–¥–∏   \n",
       "2622   S.LAVIA / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –º–∞–ª–µ–Ω—å–∫–∞—è –∫—Ä–æ—Å—Å-–±–æ–¥–∏   \n",
       "2624   S.LAVIA / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –º–∞–ª–µ–Ω—å–∫–∞—è –∫—Ä–æ—Å—Å-–±–æ–¥–∏   \n",
       "2625   S.LAVIA / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –º–∞–ª–µ–Ω—å–∫–∞—è –∫—Ä–æ—Å—Å-–±–æ–¥–∏   \n",
       "2627   S.LAVIA / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –º–∞–ª–µ–Ω—å–∫–∞—è –∫—Ä–æ—Å—Å-–±–æ–¥–∏   \n",
       "\n",
       "                               category  \\\n",
       "0     /–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "1     /–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "2     /–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "3     /–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "4     /–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "...                                 ...   \n",
       "2618  /–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "2622  /–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "2624  /–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "2625  /–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "2627  /–ñ–µ–Ω—â–∏–Ω–∞–º/–ü–ª—è–∂–Ω–∞—è –º–æ–¥–∞/–ê–∫—Å–µ—Å—Å—É–∞—Ä—ã   \n",
       "\n",
       "                                                    url  \\\n",
       "0     https://www.wildberries.ru/catalog/208661951/f...   \n",
       "1     https://www.wildberries.ru/catalog/208661951/f...   \n",
       "2     https://www.wildberries.ru/catalog/208661951/f...   \n",
       "3     https://www.wildberries.ru/catalog/208661951/f...   \n",
       "4     https://www.wildberries.ru/catalog/208661951/f...   \n",
       "...                                                 ...   \n",
       "2618  https://www.wildberries.ru/catalog/12487419/fe...   \n",
       "2622  https://www.wildberries.ru/catalog/12487419/fe...   \n",
       "2624  https://www.wildberries.ru/catalog/12487419/fe...   \n",
       "2625  https://www.wildberries.ru/catalog/12487419/fe...   \n",
       "2627  https://www.wildberries.ru/catalog/12487419/fe...   \n",
       "\n",
       "                                         corrected_text  \\\n",
       "0     –ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...   \n",
       "1     –ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...   \n",
       "2     –ù—É —Ö–æ—Ä–æ—à–∞—è –∫–µ–ø–∫–∞, –Ω–æ —Ç–æ–ª—å–∫–æ –∫–æ–∑—ã—Ä–µ–∫ –Ω–µ–º–Ω–æ–≥–æ –¥–ª...   \n",
       "3     –ù—É—É—É —Ç–∞–∫–∞—è —Å–µ–±–µ, –ø–æ—Å–∞–¥–∫–∞ –Ω–µ –≥–ª—É–±–æ–∫–∞—è, –∑–∞—Ç—è–Ω—É–ª–∞...   \n",
       "4     –ö–µ–ø–∫–∞ –±–µ—Å—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è, –ø–µ—Ä–µ–¥–Ω–∏–π —à–æ–≤ –∫–æ—Å–æ–π, –Ω–∞ –≥–æ–ª...   \n",
       "...                                                 ...   \n",
       "2618  –ö–∞–∫ –º–∞–º–∞ —Å–∫–∞–∑–∞–ª–∞:\" –û, —ç—Ç–æ —Ä—É—Å—Å–∫–∞—è —Å—É–º–∫–∞ \"üòÅ\\n–ü–æ...   \n",
       "2622  –ü—Ä–∏—à–ª–∞ –≤ –∏–¥–µ–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, –æ—á–µ–Ω—å –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å...   \n",
       "2624  –°—É–º–∫–∞ –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å. –£–¥–æ–±–Ω–∞—è, –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å–Ω–∞—è) –∑–∞ ...   \n",
       "2625  –ú–∞–ª–µ–Ω—å–∫–∞—è, –Ω–æ –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å–Ω–∞—è. –ê–∫–∫—É—Ä–∞—Ç–Ω–æ —Å—à–∏—Ç–∞, ...   \n",
       "2627  –ö–ª–∞—Å—Å–Ω–∞—è —Å—É–º–æ—á–∫–∞. –Ø –¥—É–º–∞–ª–∞ –æ–Ω–∞ –º–Ω–µ –±—É–¥–µ—Ç –±–æ–ª—å—à...   \n",
       "\n",
       "                                              sentences  __index_level_0__  \\\n",
       "0     –ß—É–º–æ–≤–∞—è –∫–µ–ø–∫–∞, —Å –º—É–∂–µ–º –ø–æ–¥–µ–ª–∏—Ç—å –Ω–µ –º–æ–∂–µ–º, –ø—Ä–∏–¥...                  0   \n",
       "1                                              –∑–∞–∫–∞–∑–∞—Ç—å                  1   \n",
       "2     –ù—É —Ö–æ—Ä–æ—à–∞—è –∫–µ–ø–∫–∞, –Ω–æ —Ç–æ–ª—å–∫–æ –∫–æ–∑—ã—Ä–µ–∫ –Ω–µ–º–Ω–æ–≥–æ –¥–ª...                  2   \n",
       "3     –ù—É—É—É —Ç–∞–∫–∞—è —Å–µ–±–µ, –ø–æ—Å–∞–¥–∫–∞ –Ω–µ –≥–ª—É–±–æ–∫–∞—è, –∑–∞—Ç—è–Ω—É–ª–∞...                  3   \n",
       "4     –ö–µ–ø–∫–∞ –±–µ—Å—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è, –ø–µ—Ä–µ–¥–Ω–∏–π —à–æ–≤ –∫–æ—Å–æ–π, –Ω–∞ –≥–æ–ª...                  4   \n",
       "...                                                 ...                ...   \n",
       "2618  –ö–∞–∫ –º–∞–º–∞ —Å–∫–∞–∑–∞–ª–∞:\" –û, —ç—Ç–æ —Ä—É—Å—Å–∫–∞—è —Å—É–º–∫–∞ \"üòÅ –ü–æ–∫...               2618   \n",
       "2622  –ü—Ä–∏—à–ª–∞ –≤ –∏–¥–µ–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, –æ—á–µ–Ω—å –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å...               2622   \n",
       "2624                         –Ω–∞–¥–µ—é—Å—å, –±—ã—Å—Ç—Ä–æ –Ω–µ –æ–±–ª–µ–∑–µ—Ç               2624   \n",
       "2625  –ú–∞–ª–µ–Ω—å–∫–∞—è, –Ω–æ –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å–Ω–∞—è –ê–∫–∫—É—Ä–∞—Ç–Ω–æ —Å—à–∏—Ç–∞, –≤...               2625   \n",
       "2627  –ö–ª–∞—Å—Å–Ω–∞—è —Å—É–º–æ—á–∫–∞ –Ø –¥—É–º–∞–ª–∞ –æ–Ω–∞ –º–Ω–µ –±—É–¥–µ—Ç –±–æ–ª—å—à–µ...               2627   \n",
       "\n",
       "      predictions  \n",
       "0            True  \n",
       "1            True  \n",
       "2            True  \n",
       "3            True  \n",
       "4            True  \n",
       "...           ...  \n",
       "2618         True  \n",
       "2622         True  \n",
       "2624         True  \n",
       "2625         True  \n",
       "2627         True  \n",
       "\n",
       "[1230 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_exploded[dataset_exploded.predictions == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
<<<<<<< HEAD
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "logging.basicConfig(filename='./reviews_keywords/clustering.log', \n",
    "                    level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ spaCy –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞\n",
    "nlp = spacy.load(\"ru_core_news_lg\")\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories and products:   0%|                                                                                                                                                          | 0/16 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Processing categories and products: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:06<00:00,  2.49it/s]\n"
=======
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Organizing clusters for Averkator / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è —Å–ø–æ—Ä—Ç–∏–≤–Ω–∞—è: 116it [00:00, 712356.17it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.83s/it]\n",
      "Organizing clusters for Binoni / –ö–µ–ø–∫–∞ –∂–µ–Ω—Å–∫–∞—è –±–µ–π—Å–±–æ–ª–∫–∞ –ª–µ—Ç–Ω—è—è –∫–æ–∑—ã—Ä–µ–∫ –æ—Ç —Å–æ–ª–Ω—Ü–∞ –¥–ª—è —Å–ø–æ—Ä—Ç–∞: 111it [00:00, 683653.07it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.67s/it]\n",
      "Organizing clusters for Femberry / –ë–µ–π—Å–±–æ–ª–∫–∞ —Å –ø—Ä–∏–Ω—Ç–æ–º: 31it [00:00, 220005.79it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 8507.72it/s]\n",
      "Organizing clusters for Fishka / –ö–µ–ø–∫–∞ –∂–µ–Ω—Å–∫–∞—è –±–µ–ª–∞—è: 95it [00:00, 742009.09it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.54s/it]\n",
      "Organizing clusters for G.T / –ë–µ–π—Å–±–æ–ª–∫–∞ –±–µ–∑ –∫–æ–∑—ã—Ä—å–∫–∞ –∫–µ–ø–∫–∞ –¥–æ–∫–µ—Ä –≤–∞—Ä–µ–Ω–∫–∞ docker cap: 80it [00:00, 783982.06it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.38s/it]\n",
      "Organizing clusters for Lia De Rosa / –ë–µ–π—Å–±–æ–ª–∫–∞ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–∞—è —Å–ø–æ—Ä—Ç–∏–≤–Ω–∞—è: 85it [00:00, 608388.81it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.81s/it]\n",
      "Organizing clusters for Lia De Rosa / –ë–µ–π—Å–±–æ–ª–∫–∞ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–∞—è —Å–ø–æ—Ä—Ç–∏–≤–Ω–∞—è Los Angeles: 85it [00:00, 724625.69it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.80s/it]\n",
      "Organizing clusters for Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York NY LA –ù—å—é –ô–æ—Ä–∫: 210it [00:00, 770607.03it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:15<00:00, 15.09s/it]\n",
      "Organizing clusters for NS New style bags / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –º–∞–ª–µ–Ω—å–∫–∞—è –Ω–∞—Ç—É—Ä–∞–ª—å–Ω–∞—è –∫–æ–∂–∞ –∫—Ä–æ—Å—Å-–±–æ–¥–∏: 88it [00:00, 707085.73it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.21s/it]\n",
      "Organizing clusters for RAVOLTA.HOME / –ü–∞–Ω–∞–º–∞ –ª–µ—Ç–Ω—è—è —Å —à–∏—Ä–æ–∫–∏–º–∏ –ø–æ–ª—è–º–∏ –∏ –∑–∞–≤—è–∑–∫–∞–º–∏: 62it [00:00, 471099.36it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.85s/it]\n",
      "Organizing clusters for S.LAVIA / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –±–æ–ª—å—à–∞—è –∫—Ä–æ—Å—Å-–±–æ–¥–∏: 67it [00:00, 503617.15it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.87s/it]\n",
      "Organizing clusters for S.LAVIA / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –º–∞–ª–µ–Ω—å–∫–∞—è –∫—Ä–æ—Å—Å-–±–æ–¥–∏: 57it [00:00, 627494.30it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.00s/it]\n",
      "Organizing clusters for –ü–∞–Ω–∏ –≤ –ü–∞–Ω–∞–º–µ / –®–ª—è–ø–∞ –ø–ª—è–∂–Ω–∞—è –ª–µ—Ç–Ω—è—è: 112it [00:00, 565978.37it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.96s/it]\n",
      "Organizing clusters for –ü—É—Ö–æ–≤—ã–π –º–∞—Ä–∫–µ—Ç –ì—É–ª—å–º–∏—Ä–∞ / –®–ª—è–ø–∞ –ª–µ—Ç–Ω—è—è –ø–∞–Ω–∞–º–∞ –ø–ª–µ—Ç—ë–Ω–∞—è –ø–ª—è–∂–Ω–∞—è: 31it [00:00, 347656.21it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 8388.61it/s]\n"
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_category</th>\n",
=======
       "      <th>product</th>\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
       "      <th>cluster_sentences</th>\n",
       "      <th>key_thought</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–°–Ω–∞—Ä—è–∂—ë–Ω–Ω–∞—è –º–∞—Å—Å–∞ –º–æ–µ–≥–æ –∞–≤—Ç–æ 850 –∫–≥, –∫–ª–∏—Ä–µ–Ω—Å 1...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏ –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ \"–≤—ã—Å–∫–æ—á–∏—Ç—å\" –∏–∑ —Å–Ω–µ–∂–Ω–æ–≥–æ –º–µ—Å...</td>\n",
       "      <td>1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–µ —Ç—Ä–∞–∫–∏, –∏—Å–ø—ã—Ç–∞–ª–∏ –Ω–∞ –≥–∞–∑–µ–ª–∏ | –û—Ç–ª–∏—á–Ω—ã–µ ...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ —Ç—Ä–∞–∫–∏, –Ω–∞ –æ—â—É–ø—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ—á–Ω—ã–µ</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–ù–∞ –≤–∏–¥ –ø—Ä–æ—á–Ω—ã–µ –∏ –∫–æ–ª—é—á–∏–µ. | –í—Ä–æ–¥–µ –ø—Ä–æ—á–Ω—ã–µ. | –ù...</td>\n",
       "      <td>–ù–∞ –≤–∏–¥ –∫—Ä–µ–ø–∫–∏–µ.</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>.. | (—Ç–∞–∫ —Å–∫–∞–∑–∞–ª). | ( | .</td>\n",
       "      <td>..</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–´–†–£–ß–ê–ô–ö–ê / –ê–Ω—Ç–∏–±—É–∫—Å –ü—Ä–æ—Ç–∏–≤–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–ù–µ –∑–Ω–∞—é, –∫–∞–∫ –ø–æ–≤–µ–¥–µ—Ç —Å–µ–±—è –Ω–∞ –º–æ—Ä–æ–∑–µ –ø–æ–¥ –∫–æ–ª–µ—Å–æ...</td>\n",
       "      <td>–ù–µ –≤—ã—Ä—É—á–∞—Ç—å –¥–∞–∂–µ –ª–µ—Ç–æ–º, —á—É—Ç–æ–∫ —Å–µ–ª –≤ –Ω–µ–±–æ–ª—å—à—É—é ...</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–´–†–£–ß–ê–ô–ö–ê / –ê–Ω—Ç–∏–±—É–∫—Å –ü—Ä–æ—Ç–∏–≤–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞. | –¢—Ä–∞–∫–∏ –º–æ—â–Ω—ã–µ, –≤ –¥–µ...</td>\n",
       "      <td>–í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞.</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–ü–æ—Å–º–æ—Ç—Ä–∏ –∏ –Ω–∞ –∫–∞–∫–æ–π –ø–µ—Ä–∏–æ–¥ —Ö–≤–∞—Ç–∏—Ç | –ü–æ—Å–º–æ—Ç—Ä–∏–º ...</td>\n",
       "      <td>–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Å–∫–æ–ª—å–∫–æ —Ö–≤–∞—Ç–∏—Ç</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–º—ã–ú—ã–æ—á–Ω–æ –±—É–¥–µ–º –∑–∞–∫–∞–∑—ã–≤–∞—Ç—å –µ—â—ë! | –ë—É–¥—É –∑–∞–∫–∞–∑—ã–≤–∞...</td>\n",
       "      <td>–ë—É–¥—É –∑–∞–∫–∞–∑—ã–≤–∞—Ç—å –µ—â—ë.</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>.. | –¥‚Ä¶. | .</td>\n",
       "      <td>..</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é –∑–∞–±—ã–ª —Å–¥–µ–ª–∞—Ç—å —Ñ–æ—Ç–æ \"–¥–æ\" | –§–æ—Ç–æ ¬´–¥–æ...</td>\n",
       "      <td>–§–æ—Ç–æ ¬´–¥–æ¬ª –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é –Ω–µ —Å–¥–µ–ª–∞–ª–∞, —Ç–æ–ª—å–∫–æ ¬´–ø–æ—Å–ª–µ¬ª</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–û—Ç—Ç–∏—Ä–∞–ª –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä –æ—Ç —Å–ª–µ–¥–æ–≤ —Ä–∂–∞–≤—ã—Ö –±...</td>\n",
       "      <td>–£–¥–∞–ª—è–ª \"–∂—É—á–∫–∏\" –Ω–∞ –¥–≤–µ—Ä—è—Ö –∞–≤—Ç–æ.</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞. | –í –¥–µ–ª–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª...</td>\n",
       "      <td>–í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞.</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>.. | ...</td>\n",
       "      <td>..</td>\n",
       "      <td>3</td>\n",
=======
       "      <td>Averkator / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è —Å–ø–æ—Ä—Ç–∏–≤–Ω–∞—è</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞, —Ö–æ—Ä–æ—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –¶–≤–µ—Ç –∫—Ä–∞—Å–∏–≤—ã...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∞—è,–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –∫–µ–ø–∫–∞ –ù–∏—Ç–∫–∏ –Ω–µ –≥–¥–µ –Ω–µ —Ç–æ—Ä...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Averkator / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è —Å–ø–æ—Ä—Ç–∏–≤–Ω–∞—è</td>\n",
       "      <td>–ö–ª–∞—Å—Å–Ω–∞—è –∫–µ–ø–∫–∞! | –û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞ ! | –û—Ç–ª–∏—á–Ω–∞—è ...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞ !</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Binoni / –ö–µ–ø–∫–∞ –∂–µ–Ω—Å–∫–∞—è –±–µ–π—Å–±–æ–ª–∫–∞ –ª–µ—Ç–Ω—è—è –∫–æ–∑—ã—Ä–µ...</td>\n",
       "      <td>–ö–µ–ø–∫–∞ –∫–ª–∞—Å—Å–Ω–∞—è üëçüèª | –ó–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–∞—è –∫–µ–ø–∫–∞ –°–æ–≤–µ—Ç—É...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞, —Å–º–æ—Ç—Ä–∏—Ç—Å—è –∑–¥–æ—Ä–æ–≤–æ!</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Binoni / –ö–µ–ø–∫–∞ –∂–µ–Ω—Å–∫–∞—è –±–µ–π—Å–±–æ–ª–∫–∞ –ª–µ—Ç–Ω—è—è –∫–æ–∑—ã—Ä–µ...</td>\n",
       "      <td>–ò–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –∫–µ–ø–∫–∞, —á—É—Ç—å –≤–µ–ª–∏–∫–æ–≤–∞—Ç–∞, –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ...</td>\n",
       "      <td>–ö—Ä–∞—Å–∏–≤–æ —Å–º–æ—Ç—Ä–∏—Ç—Å—è –∏ –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ –≤–æ–ª–æ—Å—ã, –∫–æ–∑—ã—Ä–µ...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Binoni / –ö–µ–ø–∫–∞ –∂–µ–Ω—Å–∫–∞—è –±–µ–π—Å–±–æ–ª–∫–∞ –ª–µ—Ç–Ω—è—è –∫–æ–∑—ã—Ä–µ...</td>\n",
       "      <td>–ö–æ–∑—ã—Ä—ë–∫ –æ—Ç–ª–∏—á–Ω—ã–π! | –∫–æ–∑—ã—Ä—ë–∫ | –•–æ—Ä–æ—à–∏–π –∫–æ–∑—ã—Ä–µ–∫,...</td>\n",
       "      <td>–ö–ª–∞—Å—Å–Ω—ã–π –∫–æ–∑—ã—Ä–µ–∫!üëç</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Femberry / –ë–µ–π—Å–±–æ–ª–∫–∞ —Å –ø—Ä–∏–Ω—Ç–æ–º</td>\n",
       "      <td>–ö—Ä–∞—Å–∏–≤–∞—è –∫–µ–ø–∫–∞ , –Ω–æ –æ–≥—Ä–æ–≤–Ω–∞—è –Ω–µ –∑–Ω–∞—é –Ω–∞ –∫–∞–∫—É—é ...</td>\n",
       "      <td>–ö–µ–ø–∫–∞ –Ω–µ–ø–ª–æ—Ö–∞—è, –Ω–æ –Ω–∞ 56 —Ä–∞–∑–º–µ—Ä –≤–µ–ª–∏–∫–æ–≤–∞—Ç–∞, –≥–ª...</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fishka / –ö–µ–ø–∫–∞ –∂–µ–Ω—Å–∫–∞—è –±–µ–ª–∞—è</td>\n",
       "      <td>–•–æ—Ä–æ—à–∞—è –∫–µ–ø–∫–∞, —É–ø–∞–∫–æ–≤–∞–Ω–∞ —Ö–æ—Ä–æ—à–æ - –ø—Ä–∏—à–ª–∞ –≤ –ø–∞–∫...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∞—è –∫–µ–ø–∫–∞, —É–ø–∞–∫–æ–≤–∞–Ω–∞ —Ö–æ—Ä–æ—à–æ - –ø—Ä–∏—à–ª–∞ –≤ –ø–∞–∫...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fishka / –ö–µ–ø–∫–∞ –∂–µ–Ω—Å–∫–∞—è –±–µ–ª–∞—è</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞! | –ö–µ–ø–∫–∞ —Ö–æ—Ä–æ—à–∞—è | –û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø...</td>\n",
       "      <td>–û—á–µ–Ω—å –∫—Ä—É—Ç–∞—è –∫–µ–ø–∫–∞ ‚úÖüëç</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>G.T / –ë–µ–π—Å–±–æ–ª–∫–∞ –±–µ–∑ –∫–æ–∑—ã—Ä—å–∫–∞ –∫–µ–ø–∫–∞ –¥–æ–∫–µ—Ä –≤–∞—Ä–µ–Ω...</td>\n",
       "      <td>–∞–±–∞–ª–¥–µ–Ω–Ω–∞—è, —Å–æ–≤–µ—Ç—É—é, –Ω–µ –ø–æ–∂–∞–ª–µ–µ—Ç–µ –∏ –ø–æ —Ä–∞–∑–º–µ—Ä—É...</td>\n",
       "      <td>–ù–µ —á–∏—Å—Ç–æ –±–µ–ª–∞—è, —Å–∫–æ—Ä–µ–µ –º–æ–ª–æ—á–Ω–∞—è –ù–∞–º —Å –º—É–∂–µ–º –ø–æ...</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G.T / –ë–µ–π—Å–±–æ–ª–∫–∞ –±–µ–∑ –∫–æ–∑—ã—Ä—å–∫–∞ –∫–µ–ø–∫–∞ –¥–æ–∫–µ—Ä –≤–∞—Ä–µ–Ω...</td>\n",
       "      <td>–î–æ–≤–æ–ª—å–Ω–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –•–æ—Ä–æ—à–∞—è —Ç–∫–∞–Ω—å –ü–æ—Å...</td>\n",
       "      <td>–ö–µ–ø–∫–∞ –æ—Ç–ª–∏—á–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞, —Ö–±, –∏ –Ω–µ—Ç —Ç–≤—ë—Ä–¥–æ–π –≤—Å...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lia De Rosa / –ë–µ–π—Å–±–æ–ª–∫–∞ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–∞—è —Å–ø–æ—Ä—Ç–∏–≤–Ω–∞—è</td>\n",
       "      <td>–û–±—ã—á–Ω–∞—è –∫–µ–ø–∫–∞, –Ω–µ–º–Ω–æ–≥–æ –∂–º–µ—Ç –ë—Ä–∞–ª–∞ –¥–ª—è –∫—Ä–∞—Å–æ—Ç—ã,...</td>\n",
       "      <td>–ö–µ–ø–∫–∞ –≤—Ä–æ–¥–µ —Ö–æ—Ä–æ—à–∞—è, –∂–∞—Ä–∫–æ –≤ –Ω–µ–π –Ω–µ–º–Ω–æ–≥–æ, –ø–æ—Ç–æ...</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lia De Rosa / –ë–µ–π—Å–±–æ–ª–∫–∞ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–∞—è —Å–ø–æ—Ä—Ç–∏–≤–Ω–∞—è</td>\n",
       "      <td>–ö–µ–ø–∫–∞ –æ—á–µ–Ω—å —Å—Ç–∏–ª—å–Ω–∞—è, –∫—Ä–∞—Å–∏–≤–∞—è –í—Å–µ —Å–¥–µ–ª–∞–Ω–æ –∞–∫–∫...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞, –º—è–≥–∫–∞—è</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lia De Rosa / –ë–µ–π—Å–±–æ–ª–∫–∞ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–∞—è —Å–ø–æ—Ä—Ç–∏–≤–Ω–∞...</td>\n",
       "      <td>–û–±—ã—á–Ω–∞—è –∫–µ–ø–∫–∞, –Ω–µ–º–Ω–æ–≥–æ –∂–º–µ—Ç –ë—Ä–∞–ª–∞ –¥–ª—è –∫—Ä–∞—Å–æ—Ç—ã,...</td>\n",
       "      <td>–ö–µ–ø–∫–∞ –≤—Ä–æ–¥–µ —Ö–æ—Ä–æ—à–∞—è, –∂–∞—Ä–∫–æ –≤ –Ω–µ–π –Ω–µ–º–Ω–æ–≥–æ, –ø–æ—Ç–æ...</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lia De Rosa / –ë–µ–π—Å–±–æ–ª–∫–∞ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–∞—è —Å–ø–æ—Ä—Ç–∏–≤–Ω–∞...</td>\n",
       "      <td>–ö–µ–ø–∫–∞ –æ—á–µ–Ω—å —Å—Ç–∏–ª—å–Ω–∞—è, –∫—Ä–∞—Å–∏–≤–∞—è –í—Å–µ —Å–¥–µ–ª–∞–Ω–æ –∞–∫–∫...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞, –º—è–≥–∫–∞—è</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...</td>\n",
       "      <td>—Å–Ω–∞—á–∞–ª–∞ –≤—Å–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å, —Ç–æ–ª—å–∫–æ –ø–æ –º–µ–ª–æ—á–∏ —Ç–æ—Ä—á...</td>\n",
       "      <td>–ù–æ—Ä–º–∞–ª—å–Ω–∞—è, —á—Ç–æ–± —Å —Ä–µ–±–µ–Ω–∫–æ–º –≥—É–ª—è—Ç—å, —Å–≤–µ—Ä—Ö—É —É—à–∏...</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...</td>\n",
       "      <td>–û—Ç—Ç–µ–Ω–æ–∫ –ø—Ä–æ—Å—Ç–æ üî•üî•üî• –¥–∞–≤–Ω–æ –∏—Å–∫–∞–ª–∞ –ø–æ–¥—Ö–æ–¥—è—â—É—é –∫–µ–ø...</td>\n",
       "      <td>–û—Ç—Ç–µ–Ω–æ–∫ –ø—Ä–æ—Å—Ç–æ üî•üî•üî• –¥–∞–≤–Ω–æ –∏—Å–∫–∞–ª–∞ –ø–æ–¥—Ö–æ–¥—è—â—É—é –∫–µ–ø...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...</td>\n",
       "      <td>–ö–µ–ø–∫–∞ –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å)) | –ö–µ–ø–∫–∞ —Ç–æ–ø,—Å–æ–≤–µ—Ç—É—é | –ö–µ–ø–∫...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞)</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...</td>\n",
       "      <td>–ö–ª–∞—Å—Å–Ω–∞—è –∫–µ–ø–∫–∞ —Å–º–æ—Ç—Ä–∏—Ç—Å—è –Ω–∞–º–Ω–æ–≥–æ –¥–æ—Ä–æ–∂–µ –∏ –ª—É—á—à...</td>\n",
       "      <td>–ö–ª–∞—Å—Å–Ω–∞—è –∫–µ–ø–∫–∞ –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ –ø–æ—à–∏—Ç–∞ –∏ –≤—ã—à–∏–≤–∫–∞ –∞–∫...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞, –∑–∞ —Å–≤–æ—é —Ü–µ–Ω—É –≤–æ–æ–±—â–µ —Å—É–ø–µ—Ä üëçüëç |...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞ , –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å )</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NS New style bags / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –º–∞–ª–µ–Ω—å–∫–∞...</td>\n",
       "      <td>üî• –¶–≤–µ—Ç –∏–∑—É–º—Ä—É–¥–Ω—ã–π - –ø—Ä–æ—Å—Ç–æüí•üí•üí• –ü—Ä–µ–ª–µ—Å—Ç—å - –∞–∫–∫—É—Ä...</td>\n",
       "      <td>üî• –¶–≤–µ—Ç –∏–∑—É–º—Ä—É–¥–Ω—ã–π - –ø—Ä–æ—Å—Ç–æüí•üí•üí• –ü—Ä–µ–ª–µ—Å—Ç—å - –∞–∫–∫—É—Ä...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RAVOLTA.HOME / –ü–∞–Ω–∞–º–∞ –ª–µ—Ç–Ω—è—è —Å —à–∏—Ä–æ–∫–∏–º–∏ –ø–æ–ª—è–º–∏...</td>\n",
       "      <td>–°–∏–¥–∏—Ç –Ω–∞ –≥–æ–ª–æ–≤–µ –æ—Ç–ª–∏—á–Ω–æ –£–¥–æ–±–Ω–æ, —á—Ç–æ –ø–æ–ª—è–º –º–æ–∂–Ω...</td>\n",
       "      <td>–ü–∞–Ω–∞–º–∫–∞ –≤–æ—Å—Ö–∏—Ç–∏—Ç–µ–ª—å–Ω–∞—è, –ø–æ–ª—è –ø—Ä–æ—á–Ω—ã–µ, –∑–∞—â–∏—â–∞—é—Ç...</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RAVOLTA.HOME / –ü–∞–Ω–∞–º–∞ –ª–µ—Ç–Ω—è—è —Å —à–∏—Ä–æ–∫–∏–º–∏ –ø–æ–ª—è–º–∏...</td>\n",
       "      <td>–ù–∞ –≤–∏–¥ –Ω–µ–ø–ª–æ—Ö–æ, –Ω–æ –Ω–∞ –≥–æ–ª–æ–≤—É –µ–µ –Ω–∞–¥–æ –ø—Ä–∏–∫–ª–∞–¥—ã–≤...</td>\n",
       "      <td>–ù–µ –ø–æ–¥–æ—à–ª–∞, —Å–∞–º–∞ –ø–∞–Ω–∞–º–∞ —Å–∏–¥–∏—Ç –Ω–∏–∂–µ –±—Ä–æ–≤–µ–π, –∞ –∫...</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RAVOLTA.HOME / –ü–∞–Ω–∞–º–∞ –ª–µ—Ç–Ω—è—è —Å —à–∏—Ä–æ–∫–∏–º–∏ –ø–æ–ª—è–º–∏...</td>\n",
       "      <td>, –Ω–æ –º–Ω–µ –Ω–µ –ø–æ–¥–æ—à–ª–∞ | –ú–Ω–µ –Ω–µ –ø–æ–¥–æ—à–ª–∞</td>\n",
       "      <td>–ú–Ω–µ –Ω–µ –ø–æ–¥–æ—à–ª–∞</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RAVOLTA.HOME / –ü–∞–Ω–∞–º–∞ –ª–µ—Ç–Ω—è—è —Å —à–∏—Ä–æ–∫–∏–º–∏ –ø–æ–ª—è–º–∏...</td>\n",
       "      <td>–ö–ª–∞—Å—Å–Ω–∞—è –ø–∞–Ω–∞–º–∞! | —Ö–æ—Ä–æ—à–∞—è –ø–∞–Ω–∞–º–∫–∞ | –û—Ç–ª–∏—á–Ω–∞—è ...</td>\n",
       "      <td>—Ö–æ—Ä–æ—à–∞—è –ø–∞–Ω–∞–º–∫–∞</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>S.LAVIA / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –±–æ–ª—å—à–∞—è –∫—Ä–æ—Å—Å-–±–æ–¥–∏</td>\n",
       "      <td>–ú–Ω–µ –ø–æ–∫–∞–∑–∞–ª–∞—Å—å –≤–µ–ª–∏–∫–æ–≤–∞—Ç–∞, —Ö–æ—Ç–µ–ª–∞ —á—É—Ç—å –º–µ–Ω—å—à–µ ...</td>\n",
       "      <td>–ó–∞–±—Ä–∞–ª–∞ —Å –ø—É–Ω–∫—Ç–∞ –≤—ã–¥–∞—á–∏, –ø—ã—Ç–∞—é—Å—å —É–±–µ–¥–∏—Ç—å —Å–µ–±—è ...</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S.LAVIA / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –±–æ–ª—å—à–∞—è –∫—Ä–æ—Å—Å-–±–æ–¥–∏</td>\n",
       "      <td>–°—É–º–∫–∞ –æ—á–µ–Ω—å –º–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å –î–æ–ª–≥–æ –∏—Å–∫–∞–ª–∞ –≤–º–µ—Å—Ç...</td>\n",
       "      <td>–°—É–º–∫–∞ –æ—á–µ–Ω—å –º–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å –î–æ–ª–≥–æ –∏—Å–∫–∞–ª–∞ –≤–º–µ—Å—Ç...</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>–ü–∞–Ω–∏ –≤ –ü–∞–Ω–∞–º–µ / –®–ª—è–ø–∞ –ø–ª—è–∂–Ω–∞—è –ª–µ—Ç–Ω—è—è</td>\n",
       "      <td>–®–ª—è–ø–∞ —Å—É–ø–µ—Ä, –∫—Ä–∞—Å–∏–≤–∞—è –∏ —É–¥–æ–±–Ω–∞—è –ú–æ–∂–Ω–æ —Ä–µ–≥—É–ª–∏—Ä–æ...</td>\n",
       "      <td>–®–ª—è–ø–∫–∞ –∫–ª–∞—Å—Å–Ω–∞—è –∑–∞ —Ç–∞–∫–∏–µ –¥–µ–Ω—å–≥–∏ –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø...</td>\n",
       "      <td>1147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>–ü–∞–Ω–∏ –≤ –ü–∞–Ω–∞–º–µ / –®–ª—è–ø–∞ –ø–ª—è–∂–Ω–∞—è –ª–µ—Ç–Ω—è—è</td>\n",
       "      <td>–®–ª—è–ø–∞ –ø—Ä–∏—à–ª–∞ –≤ –∏–¥–µ–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, –Ω–∏—Å–∫–æ–ª—å–∫–æ ...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–∞—è —à–ª—è–ø–∫–∞)))</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>–ü—É—Ö–æ–≤—ã–π –º–∞—Ä–∫–µ—Ç –ì—É–ª—å–º–∏—Ä–∞ / –®–ª—è–ø–∞ –ª–µ—Ç–Ω—è—è –ø–∞–Ω–∞–º–∞ ...</td>\n",
       "      <td>–û–∫–∞–∑–∞–ª–∞—Å—å –≤–µ–ª–∏–∫–∞ –Ø –≤ –Ω–µ–π –≤—ã–≥–ª—è–¥–µ–ª–∞ –Ω–µ–ª–µ–ø–æ ( | ...</td>\n",
       "      <td>–®–ª—è–ø–∫–∞ –æ—á–µ–Ω—å –∫–ª–∞—Å—Å–Ω–∞—è, –Ω–æ –Ω–µ —Å–º–æ–≥–ª–∞ –≤—ã–∫—É–ø–∏—Ç—å, ...</td>\n",
       "      <td>281</td>\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                                 category  \\\n",
       "0                     /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "1                     /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "2                     /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "3                     /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "4                     /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "5                     /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "6   /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "7   /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "8   /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "9   /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "10  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "11  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "12  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "\n",
       "                                              product  avg_rating  \\\n",
       "0   –í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...    0.819588   \n",
       "1   –í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...    0.819588   \n",
       "2   –í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...    0.819588   \n",
       "3   –í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...    0.819588   \n",
       "4   –í–´–†–£–ß–ê–ô–ö–ê / –ê–Ω—Ç–∏–±—É–∫—Å –ü—Ä–æ—Ç–∏–≤–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ ...    0.842975   \n",
       "5   –í–´–†–£–ß–ê–ô–ö–ê / –ê–Ω—Ç–∏–±—É–∫—Å –ü—Ä–æ—Ç–∏–≤–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ ...    0.842975   \n",
       "6   –ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...    0.704545   \n",
       "7   –ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...    0.704545   \n",
       "8   –ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...    0.704545   \n",
       "9   –ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...    0.853933   \n",
       "10  –ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...    0.853933   \n",
       "11  –ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...    0.853933   \n",
       "12  –ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...    0.853933   \n",
       "\n",
       "   rating_category                                  cluster_sentences  \\\n",
       "0          neutral  –°–Ω–∞—Ä—è–∂—ë–Ω–Ω–∞—è –º–∞—Å—Å–∞ –º–æ–µ–≥–æ –∞–≤—Ç–æ 850 –∫–≥, –∫–ª–∏—Ä–µ–Ω—Å 1...   \n",
       "1          neutral  –û—Ç–ª–∏—á–Ω—ã–µ —Ç—Ä–∞–∫–∏, –∏—Å–ø—ã—Ç–∞–ª–∏ –Ω–∞ –≥–∞–∑–µ–ª–∏ | –û—Ç–ª–∏—á–Ω—ã–µ ...   \n",
       "2          neutral  –ù–∞ –≤–∏–¥ –ø—Ä–æ—á–Ω—ã–µ –∏ –∫–æ–ª—é—á–∏–µ. | –í—Ä–æ–¥–µ –ø—Ä–æ—á–Ω—ã–µ. | –ù...   \n",
       "3          neutral                         .. | (—Ç–∞–∫ —Å–∫–∞–∑–∞–ª). | ( | .   \n",
       "4          neutral  –ù–µ –∑–Ω–∞—é, –∫–∞–∫ –ø–æ–≤–µ–¥–µ—Ç —Å–µ–±—è –Ω–∞ –º–æ—Ä–æ–∑–µ –ø–æ–¥ –∫–æ–ª–µ—Å–æ...   \n",
       "5          neutral  –í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞. | –¢—Ä–∞–∫–∏ –º–æ—â–Ω—ã–µ, –≤ –¥–µ...   \n",
       "6          neutral  –ü–æ—Å–º–æ—Ç—Ä–∏ –∏ –Ω–∞ –∫–∞–∫–æ–π –ø–µ—Ä–∏–æ–¥ —Ö–≤–∞—Ç–∏—Ç | –ü–æ—Å–º–æ—Ç—Ä–∏–º ...   \n",
       "7          neutral  –º—ã–ú—ã–æ—á–Ω–æ –±—É–¥–µ–º –∑–∞–∫–∞–∑—ã–≤–∞—Ç—å –µ—â—ë! | –ë—É–¥—É –∑–∞–∫–∞–∑—ã–≤–∞...   \n",
       "8          neutral                                       .. | –¥‚Ä¶. | .   \n",
       "9          neutral  –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é –∑–∞–±—ã–ª —Å–¥–µ–ª–∞—Ç—å —Ñ–æ—Ç–æ \"–¥–æ\" | –§–æ—Ç–æ ¬´–¥–æ...   \n",
       "10         neutral  –û—Ç—Ç–∏—Ä–∞–ª –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä –æ—Ç —Å–ª–µ–¥–æ–≤ —Ä–∂–∞–≤—ã—Ö –±...   \n",
       "11         neutral  –í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞. | –í –¥–µ–ª–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª...   \n",
       "12         neutral                                           .. | ...   \n",
       "\n",
       "                                          key_thought  word_count  \n",
       "0   –•–æ—Ä–æ—à–∏ –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ \"–≤—ã—Å–∫–æ—á–∏—Ç—å\" –∏–∑ —Å–Ω–µ–∂–Ω–æ–≥–æ –º–µ—Å...        1081  \n",
       "1          –•–æ—Ä–æ—à–∏–µ —Ç—Ä–∞–∫–∏, –Ω–∞ –æ—â—É–ø—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ—á–Ω—ã–µ          15  \n",
       "2                                     –ù–∞ –≤–∏–¥ –∫—Ä–µ–ø–∫–∏–µ.          12  \n",
       "3                                                  ..           8  \n",
       "4   –ù–µ –≤—ã—Ä—É—á–∞—Ç—å –¥–∞–∂–µ –ª–µ—Ç–æ–º, —á—É—Ç–æ–∫ —Å–µ–ª –≤ –Ω–µ–±–æ–ª—å—à—É—é ...         432  \n",
       "5                           –í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞.          37  \n",
       "6                         –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Å–∫–æ–ª—å–∫–æ —Ö–≤–∞—Ç–∏—Ç          16  \n",
       "7                                –ë—É–¥—É –∑–∞–∫–∞–∑—ã–≤–∞—Ç—å –µ—â—ë.          13  \n",
       "8                                                  ..           5  \n",
       "9    –§–æ—Ç–æ ¬´–¥–æ¬ª –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é –Ω–µ —Å–¥–µ–ª–∞–ª–∞, —Ç–æ–ª—å–∫–æ ¬´–ø–æ—Å–ª–µ¬ª          24  \n",
       "10                     –£–¥–∞–ª—è–ª \"–∂—É—á–∫–∏\" –Ω–∞ –¥–≤–µ—Ä—è—Ö –∞–≤—Ç–æ.          24  \n",
       "11                          –í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞.          14  \n",
       "12                                                 ..           3  "
=======
       "                                              product  \\\n",
       "0                 Averkator / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è —Å–ø–æ—Ä—Ç–∏–≤–Ω–∞—è   \n",
       "1                 Averkator / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è —Å–ø–æ—Ä—Ç–∏–≤–Ω–∞—è   \n",
       "2   Binoni / –ö–µ–ø–∫–∞ –∂–µ–Ω—Å–∫–∞—è –±–µ–π—Å–±–æ–ª–∫–∞ –ª–µ—Ç–Ω—è—è –∫–æ–∑—ã—Ä–µ...   \n",
       "3   Binoni / –ö–µ–ø–∫–∞ –∂–µ–Ω—Å–∫–∞—è –±–µ–π—Å–±–æ–ª–∫–∞ –ª–µ—Ç–Ω—è—è –∫–æ–∑—ã—Ä–µ...   \n",
       "4   Binoni / –ö–µ–ø–∫–∞ –∂–µ–Ω—Å–∫–∞—è –±–µ–π—Å–±–æ–ª–∫–∞ –ª–µ—Ç–Ω—è—è –∫–æ–∑—ã—Ä–µ...   \n",
       "5                      Femberry / –ë–µ–π—Å–±–æ–ª–∫–∞ —Å –ø—Ä–∏–Ω—Ç–æ–º   \n",
       "6                        Fishka / –ö–µ–ø–∫–∞ –∂–µ–Ω—Å–∫–∞—è –±–µ–ª–∞—è   \n",
       "7                        Fishka / –ö–µ–ø–∫–∞ –∂–µ–Ω—Å–∫–∞—è –±–µ–ª–∞—è   \n",
       "8   G.T / –ë–µ–π—Å–±–æ–ª–∫–∞ –±–µ–∑ –∫–æ–∑—ã—Ä—å–∫–∞ –∫–µ–ø–∫–∞ –¥–æ–∫–µ—Ä –≤–∞—Ä–µ–Ω...   \n",
       "9   G.T / –ë–µ–π—Å–±–æ–ª–∫–∞ –±–µ–∑ –∫–æ–∑—ã—Ä—å–∫–∞ –∫–µ–ø–∫–∞ –¥–æ–∫–µ—Ä –≤–∞—Ä–µ–Ω...   \n",
       "10    Lia De Rosa / –ë–µ–π—Å–±–æ–ª–∫–∞ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–∞—è —Å–ø–æ—Ä—Ç–∏–≤–Ω–∞—è   \n",
       "11    Lia De Rosa / –ë–µ–π—Å–±–æ–ª–∫–∞ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–∞—è —Å–ø–æ—Ä—Ç–∏–≤–Ω–∞—è   \n",
       "12  Lia De Rosa / –ë–µ–π—Å–±–æ–ª–∫–∞ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–∞—è —Å–ø–æ—Ä—Ç–∏–≤–Ω–∞...   \n",
       "13  Lia De Rosa / –ë–µ–π—Å–±–æ–ª–∫–∞ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–∞—è —Å–ø–æ—Ä—Ç–∏–≤–Ω–∞...   \n",
       "14  Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...   \n",
       "15  Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...   \n",
       "16  Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...   \n",
       "17  Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...   \n",
       "18  Limastar accessories / –ö–µ–ø–∫–∞ –ª–µ—Ç–Ω—è—è New York N...   \n",
       "19  NS New style bags / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –º–∞–ª–µ–Ω—å–∫–∞...   \n",
       "20  RAVOLTA.HOME / –ü–∞–Ω–∞–º–∞ –ª–µ—Ç–Ω—è—è —Å —à–∏—Ä–æ–∫–∏–º–∏ –ø–æ–ª—è–º–∏...   \n",
       "21  RAVOLTA.HOME / –ü–∞–Ω–∞–º–∞ –ª–µ—Ç–Ω—è—è —Å —à–∏—Ä–æ–∫–∏–º–∏ –ø–æ–ª—è–º–∏...   \n",
       "22  RAVOLTA.HOME / –ü–∞–Ω–∞–º–∞ –ª–µ—Ç–Ω—è—è —Å —à–∏—Ä–æ–∫–∏–º–∏ –ø–æ–ª—è–º–∏...   \n",
       "23  RAVOLTA.HOME / –ü–∞–Ω–∞–º–∞ –ª–µ—Ç–Ω—è—è —Å —à–∏—Ä–æ–∫–∏–º–∏ –ø–æ–ª—è–º–∏...   \n",
       "24     S.LAVIA / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –±–æ–ª—å—à–∞—è –∫—Ä–æ—Å—Å-–±–æ–¥–∏   \n",
       "25     S.LAVIA / –°—É–º–∫–∞ —á–µ—Ä–µ–∑ –ø–ª–µ—á–æ –±–æ–ª—å—à–∞—è –∫—Ä–æ—Å—Å-–±–æ–¥–∏   \n",
       "26               –ü–∞–Ω–∏ –≤ –ü–∞–Ω–∞–º–µ / –®–ª—è–ø–∞ –ø–ª—è–∂–Ω–∞—è –ª–µ—Ç–Ω—è—è   \n",
       "27               –ü–∞–Ω–∏ –≤ –ü–∞–Ω–∞–º–µ / –®–ª—è–ø–∞ –ø–ª—è–∂–Ω–∞—è –ª–µ—Ç–Ω—è—è   \n",
       "28  –ü—É—Ö–æ–≤—ã–π –º–∞—Ä–∫–µ—Ç –ì—É–ª—å–º–∏—Ä–∞ / –®–ª—è–ø–∞ –ª–µ—Ç–Ω—è—è –ø–∞–Ω–∞–º–∞ ...   \n",
       "\n",
       "                                    cluster_sentences  \\\n",
       "0   –û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞, —Ö–æ—Ä–æ—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –¶–≤–µ—Ç –∫—Ä–∞—Å–∏–≤—ã...   \n",
       "1   –ö–ª–∞—Å—Å–Ω–∞—è –∫–µ–ø–∫–∞! | –û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞ ! | –û—Ç–ª–∏—á–Ω–∞—è ...   \n",
       "2   –ö–µ–ø–∫–∞ –∫–ª–∞—Å—Å–Ω–∞—è üëçüèª | –ó–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–∞—è –∫–µ–ø–∫–∞ –°–æ–≤–µ—Ç—É...   \n",
       "3   –ò–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –∫–µ–ø–∫–∞, —á—É—Ç—å –≤–µ–ª–∏–∫–æ–≤–∞—Ç–∞, –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ...   \n",
       "4   –ö–æ–∑—ã—Ä—ë–∫ –æ—Ç–ª–∏—á–Ω—ã–π! | –∫–æ–∑—ã—Ä—ë–∫ | –•–æ—Ä–æ—à–∏–π –∫–æ–∑—ã—Ä–µ–∫,...   \n",
       "5   –ö—Ä–∞—Å–∏–≤–∞—è –∫–µ–ø–∫–∞ , –Ω–æ –æ–≥—Ä–æ–≤–Ω–∞—è –Ω–µ –∑–Ω–∞—é –Ω–∞ –∫–∞–∫—É—é ...   \n",
       "6   –•–æ—Ä–æ—à–∞—è –∫–µ–ø–∫–∞, —É–ø–∞–∫–æ–≤–∞–Ω–∞ —Ö–æ—Ä–æ—à–æ - –ø—Ä–∏—à–ª–∞ –≤ –ø–∞–∫...   \n",
       "7   –û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞! | –ö–µ–ø–∫–∞ —Ö–æ—Ä–æ—à–∞—è | –û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø...   \n",
       "8   –∞–±–∞–ª–¥–µ–Ω–Ω–∞—è, —Å–æ–≤–µ—Ç—É—é, –Ω–µ –ø–æ–∂–∞–ª–µ–µ—Ç–µ –∏ –ø–æ —Ä–∞–∑–º–µ—Ä—É...   \n",
       "9   –î–æ–≤–æ–ª—å–Ω–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –•–æ—Ä–æ—à–∞—è —Ç–∫–∞–Ω—å –ü–æ—Å...   \n",
       "10  –û–±—ã—á–Ω–∞—è –∫–µ–ø–∫–∞, –Ω–µ–º–Ω–æ–≥–æ –∂–º–µ—Ç –ë—Ä–∞–ª–∞ –¥–ª—è –∫—Ä–∞—Å–æ—Ç—ã,...   \n",
       "11  –ö–µ–ø–∫–∞ –æ—á–µ–Ω—å —Å—Ç–∏–ª—å–Ω–∞—è, –∫—Ä–∞—Å–∏–≤–∞—è –í—Å–µ —Å–¥–µ–ª–∞–Ω–æ –∞–∫–∫...   \n",
       "12  –û–±—ã—á–Ω–∞—è –∫–µ–ø–∫–∞, –Ω–µ–º–Ω–æ–≥–æ –∂–º–µ—Ç –ë—Ä–∞–ª–∞ –¥–ª—è –∫—Ä–∞—Å–æ—Ç—ã,...   \n",
       "13  –ö–µ–ø–∫–∞ –æ—á–µ–Ω—å —Å—Ç–∏–ª—å–Ω–∞—è, –∫—Ä–∞—Å–∏–≤–∞—è –í—Å–µ —Å–¥–µ–ª–∞–Ω–æ –∞–∫–∫...   \n",
       "14  —Å–Ω–∞—á–∞–ª–∞ –≤—Å–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å, —Ç–æ–ª—å–∫–æ –ø–æ –º–µ–ª–æ—á–∏ —Ç–æ—Ä—á...   \n",
       "15  –û—Ç—Ç–µ–Ω–æ–∫ –ø—Ä–æ—Å—Ç–æ üî•üî•üî• –¥–∞–≤–Ω–æ –∏—Å–∫–∞–ª–∞ –ø–æ–¥—Ö–æ–¥—è—â—É—é –∫–µ–ø...   \n",
       "16  –ö–µ–ø–∫–∞ –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å)) | –ö–µ–ø–∫–∞ —Ç–æ–ø,—Å–æ–≤–µ—Ç—É—é | –ö–µ–ø–∫...   \n",
       "17  –ö–ª–∞—Å—Å–Ω–∞—è –∫–µ–ø–∫–∞ —Å–º–æ—Ç—Ä–∏—Ç—Å—è –Ω–∞–º–Ω–æ–≥–æ –¥–æ—Ä–æ–∂–µ –∏ –ª—É—á—à...   \n",
       "18  –û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞, –∑–∞ —Å–≤–æ—é —Ü–µ–Ω—É –≤–æ–æ–±—â–µ —Å—É–ø–µ—Ä üëçüëç |...   \n",
       "19  üî• –¶–≤–µ—Ç –∏–∑—É–º—Ä—É–¥–Ω—ã–π - –ø—Ä–æ—Å—Ç–æüí•üí•üí• –ü—Ä–µ–ª–µ—Å—Ç—å - –∞–∫–∫—É—Ä...   \n",
       "20  –°–∏–¥–∏—Ç –Ω–∞ –≥–æ–ª–æ–≤–µ –æ—Ç–ª–∏—á–Ω–æ –£–¥–æ–±–Ω–æ, —á—Ç–æ –ø–æ–ª—è–º –º–æ–∂–Ω...   \n",
       "21  –ù–∞ –≤–∏–¥ –Ω–µ–ø–ª–æ—Ö–æ, –Ω–æ –Ω–∞ –≥–æ–ª–æ–≤—É –µ–µ –Ω–∞–¥–æ –ø—Ä–∏–∫–ª–∞–¥—ã–≤...   \n",
       "22               , –Ω–æ –º–Ω–µ –Ω–µ –ø–æ–¥–æ—à–ª–∞ | –ú–Ω–µ –Ω–µ –ø–æ–¥–æ—à–ª–∞   \n",
       "23  –ö–ª–∞—Å—Å–Ω–∞—è –ø–∞–Ω–∞–º–∞! | —Ö–æ—Ä–æ—à–∞—è –ø–∞–Ω–∞–º–∫–∞ | –û—Ç–ª–∏—á–Ω–∞—è ...   \n",
       "24  –ú–Ω–µ –ø–æ–∫–∞–∑–∞–ª–∞—Å—å –≤–µ–ª–∏–∫–æ–≤–∞—Ç–∞, —Ö–æ—Ç–µ–ª–∞ —á—É—Ç—å –º–µ–Ω—å—à–µ ...   \n",
       "25  –°—É–º–∫–∞ –æ—á–µ–Ω—å –º–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å –î–æ–ª–≥–æ –∏—Å–∫–∞–ª–∞ –≤–º–µ—Å—Ç...   \n",
       "26  –®–ª—è–ø–∞ —Å—É–ø–µ—Ä, –∫—Ä–∞—Å–∏–≤–∞—è –∏ —É–¥–æ–±–Ω–∞—è –ú–æ–∂–Ω–æ —Ä–µ–≥—É–ª–∏—Ä–æ...   \n",
       "27  –®–ª—è–ø–∞ –ø—Ä–∏—à–ª–∞ –≤ –∏–¥–µ–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, –Ω–∏—Å–∫–æ–ª—å–∫–æ ...   \n",
       "28  –û–∫–∞–∑–∞–ª–∞—Å—å –≤–µ–ª–∏–∫–∞ –Ø –≤ –Ω–µ–π –≤—ã–≥–ª—è–¥–µ–ª–∞ –Ω–µ–ª–µ–ø–æ ( | ...   \n",
       "\n",
       "                                          key_thought  word_count  \n",
       "0   –•–æ—Ä–æ—à–∞—è,–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –∫–µ–ø–∫–∞ –ù–∏—Ç–∫–∏ –Ω–µ –≥–¥–µ –Ω–µ —Ç–æ—Ä...          50  \n",
       "1                                    –û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞ !          12  \n",
       "2                  –û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞, —Å–º–æ—Ç—Ä–∏—Ç—Å—è –∑–¥–æ—Ä–æ–≤–æ!          83  \n",
       "3   –ö—Ä–∞—Å–∏–≤–æ —Å–º–æ—Ç—Ä–∏—Ç—Å—è –∏ –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ –≤–æ–ª–æ—Å—ã, –∫–æ–∑—ã—Ä–µ...          36  \n",
       "4                                  –ö–ª–∞—Å—Å–Ω—ã–π –∫–æ–∑—ã—Ä–µ–∫!üëç          15  \n",
       "5   –ö–µ–ø–∫–∞ –Ω–µ–ø–ª–æ—Ö–∞—è, –Ω–æ –Ω–∞ 56 —Ä–∞–∑–º–µ—Ä –≤–µ–ª–∏–∫–æ–≤–∞—Ç–∞, –≥–ª...         245  \n",
       "6   –•–æ—Ä–æ—à–∞—è –∫–µ–ø–∫–∞, —É–ø–∞–∫–æ–≤–∞–Ω–∞ —Ö–æ—Ä–æ—à–æ - –ø—Ä–∏—à–ª–∞ –≤ –ø–∞–∫...         111  \n",
       "7                               –û—á–µ–Ω—å –∫—Ä—É—Ç–∞—è –∫–µ–ø–∫–∞ ‚úÖüëç          53  \n",
       "8   –ù–µ —á–∏—Å—Ç–æ –±–µ–ª–∞—è, —Å–∫–æ—Ä–µ–µ –º–æ–ª–æ—á–Ω–∞—è –ù–∞–º —Å –º—É–∂–µ–º –ø–æ...         264  \n",
       "9   –ö–µ–ø–∫–∞ –æ—Ç–ª–∏—á–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞, —Ö–±, –∏ –Ω–µ—Ç —Ç–≤—ë—Ä–¥–æ–π –≤—Å...         154  \n",
       "10  –ö–µ–ø–∫–∞ –≤—Ä–æ–¥–µ —Ö–æ—Ä–æ—à–∞—è, –∂–∞—Ä–∫–æ –≤ –Ω–µ–π –Ω–µ–º–Ω–æ–≥–æ, –ø–æ—Ç–æ...         443  \n",
       "11                             –û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞, –º—è–≥–∫–∞—è          54  \n",
       "12  –ö–µ–ø–∫–∞ –≤—Ä–æ–¥–µ —Ö–æ—Ä–æ—à–∞—è, –∂–∞—Ä–∫–æ –≤ –Ω–µ–π –Ω–µ–º–Ω–æ–≥–æ, –ø–æ—Ç–æ...         443  \n",
       "13                             –û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞, –º—è–≥–∫–∞—è          54  \n",
       "14  –ù–æ—Ä–º–∞–ª—å–Ω–∞—è, —á—Ç–æ–± —Å —Ä–µ–±–µ–Ω–∫–æ–º –≥—É–ª—è—Ç—å, —Å–≤–µ—Ä—Ö—É —É—à–∏...         228  \n",
       "15  –û—Ç—Ç–µ–Ω–æ–∫ –ø—Ä–æ—Å—Ç–æ üî•üî•üî• –¥–∞–≤–Ω–æ –∏—Å–∫–∞–ª–∞ –ø–æ–¥—Ö–æ–¥—è—â—É—é –∫–µ–ø...         141  \n",
       "16                                    –û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞)         122  \n",
       "17  –ö–ª–∞—Å—Å–Ω–∞—è –∫–µ–ø–∫–∞ –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ –ø–æ—à–∏—Ç–∞ –∏ –≤—ã—à–∏–≤–∫–∞ –∞–∫...          34  \n",
       "18            –û—Ç–ª–∏—á–Ω–∞—è –∫–µ–ø–∫–∞ , –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å )          22  \n",
       "19  üî• –¶–≤–µ—Ç –∏–∑—É–º—Ä—É–¥–Ω—ã–π - –ø—Ä–æ—Å—Ç–æüí•üí•üí• –ü—Ä–µ–ª–µ—Å—Ç—å - –∞–∫–∫—É—Ä...          77  \n",
       "20  –ü–∞–Ω–∞–º–∫–∞ –≤–æ—Å—Ö–∏—Ç–∏—Ç–µ–ª—å–Ω–∞—è, –ø–æ–ª—è –ø—Ä–æ—á–Ω—ã–µ, –∑–∞—â–∏—â–∞—é—Ç...         211  \n",
       "21  –ù–µ –ø–æ–¥–æ—à–ª–∞, —Å–∞–º–∞ –ø–∞–Ω–∞–º–∞ —Å–∏–¥–∏—Ç –Ω–∏–∂–µ –±—Ä–æ–≤–µ–π, –∞ –∫...         122  \n",
       "22                                     –ú–Ω–µ –Ω–µ –ø–æ–¥–æ—à–ª–∞           9  \n",
       "23                                    —Ö–æ—Ä–æ—à–∞—è –ø–∞–Ω–∞–º–∫–∞           8  \n",
       "24  –ó–∞–±—Ä–∞–ª–∞ —Å –ø—É–Ω–∫—Ç–∞ –≤—ã–¥–∞—á–∏, –ø—ã—Ç–∞—é—Å—å —É–±–µ–¥–∏—Ç—å —Å–µ–±—è ...         407  \n",
       "25  –°—É–º–∫–∞ –æ—á–µ–Ω—å –º–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å –î–æ–ª–≥–æ –∏—Å–∫–∞–ª–∞ –≤–º–µ—Å—Ç...         226  \n",
       "26  –®–ª—è–ø–∫–∞ –∫–ª–∞—Å—Å–Ω–∞—è –∑–∞ —Ç–∞–∫–∏–µ –¥–µ–Ω—å–≥–∏ –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø...        1147  \n",
       "27                                 –û—Ç–ª–∏—á–Ω–∞—è —à–ª—è–ø–∫–∞)))          72  \n",
       "28  –®–ª—è–ø–∫–∞ –æ—á–µ–Ω—å –∫–ª–∞—Å—Å–Ω–∞—è, –Ω–æ –Ω–µ —Å–º–æ–≥–ª–∞ –≤—ã–∫—É–ø–∏—Ç—å, ...         281  "
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
<<<<<<< HEAD
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import DBSCAN\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, BertConfig\n",
    "import hdbscan\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from tqdm import tqdm\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏\n",
    "config = BertConfig.from_pretrained('./reviews_keywords/fine_tuned_model', output_hidden_states=True)\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π\n",
    "model = BertForSequenceClassification.from_pretrained('./reviews_keywords/fine_tuned_model', config=config).to(device)\n",
    "\n",
    "# –ü–µ—Ä–µ–≤–æ–¥ –º–æ–¥–µ–ª–∏ –≤ —Ä–µ–∂–∏–º FP16, –µ—Å–ª–∏ —ç—Ç–æ –≤–æ–∑–º–æ–∂–Ω–æ\n",
    "if torch.cuda.is_available():\n",
    "    model = model.half()\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\n",
    "tokenizer = BertTokenizerFast.from_pretrained('./reviews_keywords/fine_tuned_model')\n",
=======
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, BertConfig\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ –≤ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–µ Hugging Face\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (GPU –∏–ª–∏ CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "logging.basicConfig(filename='./reviews_keywords/clustering.log', \n",
    "                    level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ spaCy –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞\n",
    "nlp = spacy.load(\"ru_core_news_lg\")\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π\n",
    "config = BertConfig.from_pretrained('./reviews_keywords/fine_tuned_model', output_hidden_states=True)\n",
    "tokenizer = BertTokenizerFast.from_pretrained('./reviews_keywords/fine_tuned_model')\n",
    "model = BertForSequenceClassification.from_pretrained('./reviews_keywords/fine_tuned_model', config=config).to(device)\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ü–µ–Ω—Ç—Ä–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞ (—Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞)\n",
    "def find_centroid(embeddings):\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
<<<<<<< HEAD
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "def compute_sentence_embeddings(sentences):\n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö\n",
    "    if not all(isinstance(sentence, str) and sentence.strip() for sentence in sentences):\n",
    "        raise ValueError(\"All items in the input must be non-empty strings.\")\n",
    "    \n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π\n",
    "        if outputs.hidden_states is None:\n",
    "            raise ValueError(\"–ú–æ–¥–µ–ª—å –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∫—Ä—ã—Ç—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏.\")\n",
    "        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–∫—Ä—ã—Ç—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è\n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "    embeddings = hidden_states.mean(dim=1).cpu().numpy()\n",
    "    return embeddings\n",
    "\n",
=======
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –∫–ª—é—á–µ–≤–æ–π –º—ã—Å–ª–∏ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ\n",
    "def extract_key_thought(cluster_sentences):\n",
    "    sentences = cluster_sentences.split(\" | \")\n",
    "    \n",
    "    embeddings = compute_sentence_embeddings(sentences)\n",
    "    \n",
    "    centroid = find_centroid(embeddings)\n",
    "    similarities = cosine_similarity(embeddings, [centroid])\n",
    "    key_sentence_index = np.argmax(similarities)\n",
    "    \n",
    "    return sentences[key_sentence_index]\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Ç–µ—Ä–µ\n",
    "def count_words(cluster_sentences):\n",
    "    words = cluster_sentences.split()\n",
    "    return len(words)\n",
    "\n",
<<<<<<< HEAD
=======
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "def compute_sentence_embeddings(sentences):\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # –ü–æ–ª—É—á–∞–µ–º —Å–∫—Ä—ã—Ç—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è\n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "    embeddings = hidden_states.mean(dim=1).cpu().numpy()\n",
    "    return embeddings\n",
    "\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∫—Ä—É–ø–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "def recluster_large_cluster(cluster_sentences, eps=0.1, min_samples=2):\n",
    "    sentences = cluster_sentences.split(\" | \")\n",
    "    \n",
    "    embeddings = compute_sentence_embeddings(sentences)\n",
    "    \n",
    "    re_clustering = DBSCAN(eps=eps, min_samples=min_samples, metric=\"cosine\").fit(embeddings)\n",
    "    \n",
    "    re_cluster_dict = {}\n",
    "    for idx, label in enumerate(re_clustering.labels_):\n",
    "        if label == -1:\n",
    "            continue\n",
    "        label_str = str(label)\n",
    "        if label_str not in re_cluster_dict:\n",
    "            re_cluster_dict[label_str] = []\n",
    "        re_cluster_dict[label_str].append(sentences[idx])\n",
    "    \n",
    "    return [\" | \".join(cluster) for cluster in re_cluster_dict.values()]\n",
    "\n",
    "# –†–µ–∫—É—Ä—Å–∏–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∫—Ä—É–ø–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
<<<<<<< HEAD
    "def recursive_clustering(cluster_sentences, threshold, eps=0.22, min_samples=3, min_eps=0.02):\n",
    "    current_eps = eps\n",
    "    current_min_samples = min_samples\n",
=======
    "def recursive_clustering(cluster_sentences, threshold, eps=0.25, min_samples=3, min_eps=0.05):\n",
    "    current_eps = eps\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
    "    new_clusters = [cluster_sentences]\n",
    "\n",
    "    while True:\n",
    "        next_clusters = []\n",
    "        reclustered_any = False\n",
    "        \n",
    "        for cluster in new_clusters:\n",
    "            if count_words(cluster) > threshold:\n",
    "                while current_eps >= min_eps:\n",
<<<<<<< HEAD
    "                    reclustered = recluster_large_cluster(cluster, eps=current_eps, min_samples=current_min_samples)\n",
    "                    \n",
=======
    "                    reclustered = recluster_large_cluster(cluster, eps=current_eps, min_samples=min_samples)\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
    "                    if len(reclustered) > 1:\n",
    "                        next_clusters.extend(reclustered)\n",
    "                        reclustered_any = True\n",
    "                        break  # –ö–ª–∞—Å—Ç–µ—Ä —É—Å–ø–µ—à–Ω–æ —Ä–∞–∑–¥–µ–ª–µ–Ω, –≤—ã—Ö–æ–¥–∏–º –∏–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ —Ü–∏–∫–ª–∞\n",
    "                    else:\n",
<<<<<<< HEAD
    "                        if current_eps > min_eps:\n",
    "                            current_eps -= 0.05  # –£–º–µ–Ω—å—à–∞–µ–º eps –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞\n",
=======
    "                        current_eps -= 0.02  # –£–º–µ–Ω—å—à–∞–µ–º eps –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
    "                \n",
    "                if len(reclustered) == 1:\n",
    "                    # –ï—Å–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä —Ç–∞–∫ –∏ –Ω–µ –±—ã–ª —Ä–∞–∑–¥–µ–ª–µ–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –æ–±—Ä–∞—Ç–Ω–æ\n",
    "                    next_clusters.append(cluster)\n",
    "            else:\n",
    "                next_clusters.append(cluster)\n",
    "        \n",
    "        new_clusters = next_clusters\n",
    "        \n",
    "        if not reclustered_any:\n",
    "            break\n",
    "    \n",
    "    return new_clusters\n",
    "\n",
<<<<<<< HEAD
    "# –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∏ –ø—Ä–æ–¥—É–∫—Ç–∞–º\n",
    "final_result = pd.DataFrame()\n",
    "\n",
    "# –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ category –∏ product\n",
    "for (category_name, product_name), group in tqdm(dataset_exploded[dataset_exploded[\"predictions\"] == 1].groupby(['category', 'product']), desc=\"Processing categories and products\"):\n",
    "    all_sentences = group['sentences'].tolist()\n",
    "\n",
    "    if not all_sentences:\n",
    "        continue  # –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å, –µ—Å–ª–∏ –Ω–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
    "\n",
    "    try:\n",
    "        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –±–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ –±–∞—Ç—á–∏\n",
    "        all_embeddings = compute_sentence_embeddings(all_sentences)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in computing embeddings for product {product_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º HDBSCAN –∏ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏\n",
    "    distance_matrix = squareform(pdist(all_embeddings, metric='cosine'))\n",
    "    clustering = hdbscan.HDBSCAN(min_samples=3, metric='precomputed').fit(distance_matrix)\n",
    "\n",
    "    cluster_dict = {}\n",
    "    for idx, label in enumerate(clustering.labels_):\n",
=======
    "# –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –ø–æ —Ç–æ–≤–∞—Ä–∞–º\n",
    "final_result = pd.DataFrame()\n",
    "\n",
    "for product_name, group in dataset_exploded[dataset_exploded[\"predictions\"] == 1].groupby('product'):\n",
    "    all_sentences = group['sentences'].tolist()\n",
    "\n",
    "    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –±–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ –±–∞—Ç—á–∏\n",
    "    all_embeddings = compute_sentence_embeddings(all_sentences)\n",
    "\n",
    "    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏\n",
    "    clustering = DBSCAN(eps=0.25, min_samples=3, metric=\"cosine\").fit(all_embeddings)\n",
    "\n",
    "    cluster_dict = {}\n",
    "    for idx, label in tqdm(enumerate(clustering.labels_), desc=f\"Organizing clusters for {product_name}\"):\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
    "        if label == -1:\n",
    "            continue\n",
    "        label_str = str(label)\n",
    "        if label_str not in cluster_dict:\n",
    "            cluster_dict[label_str] = set()\n",
    "        cluster_dict[label_str].add(all_sentences[idx])\n",
    "\n",
    "    clusters = [\" | \".join(sentences) for sentences in cluster_dict.values()]\n",
<<<<<<< HEAD
    "\n",
    "    if not clusters:\n",
    "        continue  # –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å, –µ—Å–ª–∏ –Ω–µ—Ç –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "\n",
    "    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º review_rating –≤ 1 –∏ 0\n",
    "    group['binary_rating'] = group['review_rating'].apply(lambda x: 1 if x in [4, 5] else 0)\n",
    "\n",
    "    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –¥–ª—è —ç—Ç–æ–π –≥—Ä—É–ø–ø—ã\n",
    "    avg_rating = group['binary_rating'].mean()\n",
    "    \n",
    "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, positive –∏–ª–∏ negative\n",
    "    rating_category = 'positive' if avg_rating > 0.7 else 'neutral'\n",
    "    rating_category = 'neutral' if avg_rating > 0.5 else 'negative'\n",
    "\n",
    "    # –£—Å–ª–æ–≤–∏–µ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ—Ä–æ–≥–æ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è threshold\n",
    "    if len(clusters) == 1:\n",
    "        cluster_word_count = count_words(clusters[0])\n",
    "        if cluster_word_count > 20:\n",
    "            threshold = cluster_word_count / 2\n",
    "        else:\n",
    "            threshold = cluster_word_count  # –û—Å—Ç–∞–≤–ª—è–µ–º threshold –∫–∞–∫ –µ—Å—Ç—å\n",
    "    else:\n",
    "        # –í –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—É—é –ª–æ–≥–∏–∫—É –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –ø–æ—Ä–æ–≥–∞\n",
    "        threshold = np.min([np.mean([count_words(cluster) for cluster in clusters]) * 1.5, 250])\n",
    "\n",
    "    final_clusters = []\n",
    "    for cluster in clusters:\n",
    "        if count_words(cluster) > threshold:\n",
    "            final_clusters.extend(recursive_clustering(cluster, threshold))\n",
    "        else:\n",
    "            final_clusters.append(cluster)\n",
    "\n",
    "    # –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ ‚Äî 3\n",
    "    while len(final_clusters) < 3 and any(count_words(cluster) > threshold for cluster in final_clusters):\n",
    "        largest_cluster = max(final_clusters, key=count_words)\n",
    "        final_clusters.remove(largest_cluster)\n",
    "        new_clusters = recursive_clustering(largest_cluster, threshold)\n",
    "        \n",
    "        if len(new_clusters) <= 1:\n",
    "            final_clusters.append(largest_cluster)\n",
    "            break\n",
    "\n",
    "        final_clusters.extend(new_clusters)\n",
    "\n",
    "    df_exploded_sorted = pd.DataFrame({\n",
    "        'category': category_name,\n",
    "        'product': product_name,\n",
    "        'avg_rating': avg_rating,\n",
    "        'rating_category': rating_category,\n",
    "        'cluster_sentences': final_clusters\n",
    "    })\n",
=======
    "    threshold = np.min([np.mean([count_words(cluster) for cluster in clusters]) * 1.5  ,  450])\n",
    "\n",
    "    final_clusters = []\n",
    "    for cluster in tqdm(clusters, desc=\"Recursive clustering\"):\n",
    "        final_clusters.extend(recursive_clustering(cluster, threshold))\n",
    "\n",
    "    df_exploded_sorted = pd.DataFrame({'product': product_name, 'cluster_sentences': final_clusters})\n",
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
    "    df_exploded_sorted['word_count'] = df_exploded_sorted['cluster_sentences'].apply(count_words)\n",
    "    df_exploded_sorted['key_thought'] = df_exploded_sorted['cluster_sentences'].apply(extract_key_thought)\n",
    "\n",
    "    df_exploded_sorted = df_exploded_sorted.sort_values(by='word_count', ascending=False)\n",
    "\n",
    "    final_result = pd.concat([final_result, df_exploded_sorted], ignore_index=True)\n",
    "\n",
    "# –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
<<<<<<< HEAD
    "display(final_result[['category', 'product', 'avg_rating', 'rating_category', 'cluster_sentences', 'key_thought', 'word_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>word_count</th>\n",
       "      <th>key_thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–°–Ω–∞—Ä—è–∂—ë–Ω–Ω–∞—è –º–∞—Å—Å–∞ –º–æ–µ–≥–æ –∞–≤—Ç–æ 850 –∫–≥, –∫–ª–∏—Ä–µ–Ω—Å 1...</td>\n",
       "      <td>1081</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏ –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ \"–≤—ã—Å–∫–æ—á–∏—Ç—å\" –∏–∑ —Å–Ω–µ–∂–Ω–æ–≥–æ –º–µ—Å...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–µ —Ç—Ä–∞–∫–∏, –∏—Å–ø—ã—Ç–∞–ª–∏ –Ω–∞ –≥–∞–∑–µ–ª–∏ | –û—Ç–ª–∏—á–Ω—ã–µ ...</td>\n",
       "      <td>15</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ —Ç—Ä–∞–∫–∏, –Ω–∞ –æ—â—É–ø—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ—á–Ω—ã–µ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–ù–∞ –≤–∏–¥ –ø—Ä–æ—á–Ω—ã–µ –∏ –∫–æ–ª—é—á–∏–µ. | –í—Ä–æ–¥–µ –ø—Ä–æ—á–Ω—ã–µ. | –ù...</td>\n",
       "      <td>12</td>\n",
       "      <td>–ù–∞ –≤–∏–¥ –∫—Ä–µ–ø–∫–∏–µ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–´–†–£–ß–ê–ô–ö–ê / –ê–Ω—Ç–∏–±—É–∫—Å –ü—Ä–æ—Ç–∏–≤–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–ù–µ –∑–Ω–∞—é, –∫–∞–∫ –ø–æ–≤–µ–¥–µ—Ç —Å–µ–±—è –Ω–∞ –º–æ—Ä–æ–∑–µ –ø–æ–¥ –∫–æ–ª–µ—Å–æ...</td>\n",
       "      <td>432</td>\n",
       "      <td>–ù–µ –≤—ã—Ä—É—á–∞—Ç—å –¥–∞–∂–µ –ª–µ—Ç–æ–º, —á—É—Ç–æ–∫ —Å–µ–ª –≤ –Ω–µ–±–æ–ª—å—à—É—é ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>–í–´–†–£–ß–ê–ô–ö–ê / –ê–Ω—Ç–∏–±—É–∫—Å –ü—Ä–æ—Ç–∏–≤–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞. | –¢—Ä–∞–∫–∏ –º–æ—â–Ω—ã–µ, –≤ –¥–µ...</td>\n",
       "      <td>37</td>\n",
       "      <td>–í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–ü–æ—Å–º–æ—Ç—Ä–∏ –∏ –Ω–∞ –∫–∞–∫–æ–π –ø–µ—Ä–∏–æ–¥ —Ö–≤–∞—Ç–∏—Ç | –ü–æ—Å–º–æ—Ç—Ä–∏–º ...</td>\n",
       "      <td>16</td>\n",
       "      <td>–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Å–∫–æ–ª—å–∫–æ —Ö–≤–∞—Ç–∏—Ç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–º—ã–ú—ã–æ—á–Ω–æ –±—É–¥–µ–º –∑–∞–∫–∞–∑—ã–≤–∞—Ç—å –µ—â—ë! | –ë—É–¥—É –∑–∞–∫–∞–∑—ã–≤–∞...</td>\n",
       "      <td>13</td>\n",
       "      <td>–ë—É–¥—É –∑–∞–∫–∞–∑—ã–≤–∞—Ç—å –µ—â—ë.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é –∑–∞–±—ã–ª —Å–¥–µ–ª–∞—Ç—å —Ñ–æ—Ç–æ \"–¥–æ\" | –§–æ—Ç–æ ¬´–¥–æ...</td>\n",
       "      <td>24</td>\n",
       "      <td>–§–æ—Ç–æ ¬´–¥–æ¬ª –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é –Ω–µ —Å–¥–µ–ª–∞–ª–∞, —Ç–æ–ª—å–∫–æ ¬´–ø–æ—Å–ª–µ¬ª</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–û—Ç—Ç–∏—Ä–∞–ª –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä –æ—Ç —Å–ª–µ–¥–æ–≤ —Ä–∂–∞–≤—ã—Ö –±...</td>\n",
       "      <td>24</td>\n",
       "      <td>–£–¥–∞–ª—è–ª \"–∂—É—á–∫–∏\" –Ω–∞ –¥–≤–µ—Ä—è—Ö –∞–≤—Ç–æ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è</td>\n",
       "      <td>–ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>–í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞. | –í –¥–µ–ª–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª...</td>\n",
       "      <td>14</td>\n",
       "      <td>–í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 category  \\\n",
       "0                     /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "1                     /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "2                     /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "4                     /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "5                     /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "6   /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "7   /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "9   /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "10  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "11  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/–ê–≤—Ç–æ–∫–æ—Å–º–µ—Ç–∏–∫–∞ –∏ –∞–≤—Ç–æ—Ö–∏–º–∏—è   \n",
       "\n",
       "                                              product  avg_rating  \\\n",
       "0   –í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...    0.819588   \n",
       "1   –í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...    0.819588   \n",
       "2   –í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª...    0.819588   \n",
       "4   –í–´–†–£–ß–ê–ô–ö–ê / –ê–Ω—Ç–∏–±—É–∫—Å –ü—Ä–æ—Ç–∏–≤–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ ...    0.842975   \n",
       "5   –í–´–†–£–ß–ê–ô–ö–ê / –ê–Ω—Ç–∏–±—É–∫—Å –ü—Ä–æ—Ç–∏–≤–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ ...    0.842975   \n",
       "6   –ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...    0.704545   \n",
       "7   –ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä...    0.704545   \n",
       "9   –ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...    0.853933   \n",
       "10  –ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...    0.853933   \n",
       "11  –ü–æ–ª–∏–ö–æ–º–ü–ª–∞—Å—Ç / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å —Ä–∂–∞–≤...    0.853933   \n",
       "\n",
       "   rating_category                                  cluster_sentences  \\\n",
       "0          neutral  –°–Ω–∞—Ä—è–∂—ë–Ω–Ω–∞—è –º–∞—Å—Å–∞ –º–æ–µ–≥–æ –∞–≤—Ç–æ 850 –∫–≥, –∫–ª–∏—Ä–µ–Ω—Å 1...   \n",
       "1          neutral  –û—Ç–ª–∏—á–Ω—ã–µ —Ç—Ä–∞–∫–∏, –∏—Å–ø—ã—Ç–∞–ª–∏ –Ω–∞ –≥–∞–∑–µ–ª–∏ | –û—Ç–ª–∏—á–Ω—ã–µ ...   \n",
       "2          neutral  –ù–∞ –≤–∏–¥ –ø—Ä–æ—á–Ω—ã–µ –∏ –∫–æ–ª—é—á–∏–µ. | –í—Ä–æ–¥–µ –ø—Ä–æ—á–Ω—ã–µ. | –ù...   \n",
       "4          neutral  –ù–µ –∑–Ω–∞—é, –∫–∞–∫ –ø–æ–≤–µ–¥–µ—Ç —Å–µ–±—è –Ω–∞ –º–æ—Ä–æ–∑–µ –ø–æ–¥ –∫–æ–ª–µ—Å–æ...   \n",
       "5          neutral  –í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞. | –¢—Ä–∞–∫–∏ –º–æ—â–Ω—ã–µ, –≤ –¥–µ...   \n",
       "6          neutral  –ü–æ—Å–º–æ—Ç—Ä–∏ –∏ –Ω–∞ –∫–∞–∫–æ–π –ø–µ—Ä–∏–æ–¥ —Ö–≤–∞—Ç–∏—Ç | –ü–æ—Å–º–æ—Ç—Ä–∏–º ...   \n",
       "7          neutral  –º—ã–ú—ã–æ—á–Ω–æ –±—É–¥–µ–º –∑–∞–∫–∞–∑—ã–≤–∞—Ç—å –µ—â—ë! | –ë—É–¥—É –∑–∞–∫–∞–∑—ã–≤–∞...   \n",
       "9          neutral  –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é –∑–∞–±—ã–ª —Å–¥–µ–ª–∞—Ç—å —Ñ–æ—Ç–æ \"–¥–æ\" | –§–æ—Ç–æ ¬´–¥–æ...   \n",
       "10         neutral  –û—Ç—Ç–∏—Ä–∞–ª –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä –æ—Ç —Å–ª–µ–¥–æ–≤ —Ä–∂–∞–≤—ã—Ö –±...   \n",
       "11         neutral  –í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞. | –í –¥–µ–ª–µ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª...   \n",
       "\n",
       "    word_count                                        key_thought  \n",
       "0         1081  –•–æ—Ä–æ—à–∏ –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ \"–≤—ã—Å–∫–æ—á–∏—Ç—å\" –∏–∑ —Å–Ω–µ–∂–Ω–æ–≥–æ –º–µ—Å...  \n",
       "1           15         –•–æ—Ä–æ—à–∏–µ —Ç—Ä–∞–∫–∏, –Ω–∞ –æ—â—É–ø—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ—á–Ω—ã–µ  \n",
       "2           12                                    –ù–∞ –≤–∏–¥ –∫—Ä–µ–ø–∫–∏–µ.  \n",
       "4          432  –ù–µ –≤—ã—Ä—É—á–∞—Ç—å –¥–∞–∂–µ –ª–µ—Ç–æ–º, —á—É—Ç–æ–∫ —Å–µ–ª –≤ –Ω–µ–±–æ–ª—å—à—É—é ...  \n",
       "5           37                          –í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞.  \n",
       "6           16                        –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Å–∫–æ–ª—å–∫–æ —Ö–≤–∞—Ç–∏—Ç  \n",
       "7           13                               –ë—É–¥—É –∑–∞–∫–∞–∑—ã–≤–∞—Ç—å –µ—â—ë.  \n",
       "9           24   –§–æ—Ç–æ ¬´–¥–æ¬ª –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é –Ω–µ —Å–¥–µ–ª–∞–ª–∞, —Ç–æ–ª—å–∫–æ ¬´–ø–æ—Å–ª–µ¬ª  \n",
       "10          24                     –£–¥–∞–ª—è–ª \"–∂—É—á–∫–∏\" –Ω–∞ –¥–≤–µ—Ä—è—Ö –∞–≤—Ç–æ.  \n",
       "11          14                          –í –¥–µ–ª–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π —Å word_count <= 10 –∏ –∫–ª—é—á–µ–≤–æ–π –º—ã—Å–ª—å—é –º–µ–Ω–µ–µ 3 —Å–∏–º–≤–æ–ª–æ–≤\n",
    "final_result = final_result[((final_result['word_count'] > 10) & (final_result['key_thought'].str.len() > 5))]\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.to_csv(\"./reviews_keywords/feedbackfueltest.csv\")"
=======
    "display(final_result[['product', 'cluster_sentences', 'key_thought', 'word_count']])\n"
>>>>>>> b14be5c320a240755c77445befa9981916720ddc
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
