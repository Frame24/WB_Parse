{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'torch.storage.UntypedStorage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 325\u001b[0m\n\u001b[1;32m    321\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_reviews(dataset_exploded)\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m--> 325\u001b[0m reviews_keywords \u001b[38;5;241m=\u001b[39m \u001b[43mReviewsKeywords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./reviews_keywords/wildberries_reviews.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./reviews_keywords/fine_tuned_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m final_result \u001b[38;5;241m=\u001b[39m reviews_keywords\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    328\u001b[0m final_result\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[59], line 36\u001b[0m, in \u001b[0;36mReviewsKeywords.__init__\u001b[0;34m(self, csv_path, model_path, spacy_model)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer_my \u001b[38;5;241m=\u001b[39m BertTokenizerFast\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_path)\n\u001b[1;32m     35\u001b[0m  \u001b[38;5;66;03m# Загрузка модели для классификации\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassification_model \u001b[38;5;241m=\u001b[39m \u001b[43mBertForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Загрузка базовой модели для получения эмбеддингов\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_model \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_path)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3738\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_pt:\n\u001b[1;32m   3736\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sharded \u001b[38;5;129;01mand\u001b[39;00m state_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3737\u001b[0m         \u001b[38;5;66;03m# Time to load the checkpoint\u001b[39;00m\n\u001b[0;32m-> 3738\u001b[0m         state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3740\u001b[0m     \u001b[38;5;66;03m# set dtype to instantiate the model under:\u001b[39;00m\n\u001b[1;32m   3741\u001b[0m     \u001b[38;5;66;03m# 1. If torch_dtype is not None, we use that dtype\u001b[39;00m\n\u001b[1;32m   3742\u001b[0m     \u001b[38;5;66;03m# 2. If torch_dtype is \"auto\", we auto-detect dtype from the loaded state_dict, by checking its first\u001b[39;00m\n\u001b[1;32m   3743\u001b[0m     \u001b[38;5;66;03m#    weights entry that is of a floating type - we assume all floating dtype weights are of the same dtype\u001b[39;00m\n\u001b[1;32m   3744\u001b[0m     \u001b[38;5;66;03m# we also may have config.torch_dtype available, but we won't rely on it till v5\u001b[39;00m\n\u001b[1;32m   3745\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:556\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file, is_quantized)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlx\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    553\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe safetensors archive passed at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not contain the valid metadata. Make sure \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    554\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou save your model with the `save_pretrained` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    555\u001b[0m         )\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msafe_load_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    559\u001b[0m         (is_deepspeed_zero3_enabled() \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mis_initialized() \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mget_rank() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0())\n\u001b[1;32m    561\u001b[0m     ) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/safetensors/torch.py:313\u001b[0m, in \u001b[0;36mload_file\u001b[0;34m(filename, device)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m safe_open(filename, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 313\u001b[0m         result[k] \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mValueError\u001b[0m: could not determine the shape of object type 'torch.storage.UntypedStorage'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pyarrow.parquet as pq\n",
    "import dask.dataframe as dd\n",
    "import spacy\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, BertTokenizerFast, BertForSequenceClassification, BertConfig\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, Dataset as TorchDataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import hdbscan\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import logging\n",
    "import re\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "class ReviewsKeywords:\n",
    "    def __init__(self, csv_path, model_path, spacy_model=\"ru_core_news_lg\"):\n",
    "        self.csv_path = csv_path\n",
    "        self.model_path = model_path\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if self.device == \"cuda\":\n",
    "            import cudf.pandas  # Импортирование cuDF и активация его использования\n",
    "            cudf.pandas.install()\n",
    "        os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"  # Включаем параллелизм токенизатора для ускорения\n",
    "        self.tokenizer_my = BertTokenizerFast.from_pretrained(self.model_path)\n",
    "         # Загрузка модели для классификации\n",
    "        self.classification_model = BertForSequenceClassification.from_pretrained(self.model_path).to(self.device)\n",
    "        # Загрузка базовой модели для получения эмбеддингов\n",
    "        self.embedding_model = AutoModel.from_pretrained(self.model_path).to(self.device)\n",
    "        \n",
    "        # Загрузка модели и токенайзера от Сбербанка\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('sberbank-ai/sbert_large_nlu_ru')\n",
    "        self.embedding_model = AutoModel.from_pretrained('sberbank-ai/sbert_large_nlu_ru').to(self.device)\n",
    "        \n",
    "        spacy.prefer_gpu()\n",
    "        self.nlp = spacy.load(spacy_model, disable=[\"ner\", \"tagger\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "        \n",
    "        self.df = pd.read_csv(self.csv_path, nrows=1000)\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text):\n",
    "        text = re.sub(r'[\\n\\r\\t]+|\\s{2,}', ' ', text)\n",
    "        text = re.sub(r'(?<!\\.)\\s*\\.\\s*|\\s*\\.\\s*(?!\\.)', '. ', text)\n",
    "        return text.strip().rstrip('.')\n",
    "\n",
    "    def split_reviews_into_sentences(self, batch):\n",
    "        cleaned_texts = [self.clean_text(text) for text in batch['corrected_text']]\n",
    "        docs = list(self.nlp.pipe(cleaned_texts, batch_size=64))\n",
    "        batch['sentences'] = [[sent.text for sent in doc.sents] for doc in docs]\n",
    "        return batch\n",
    "\n",
    "    def process_reviews(self):\n",
    "        dataset = Dataset.from_pandas(self.df)\n",
    "        dataset = dataset.map(self.split_reviews_into_sentences, batched=True, batch_size=32)\n",
    "        self.df = dataset.to_pandas()\n",
    "        df_exploded = self.df.explode('sentences').reset_index(drop=True)\n",
    "        df_exploded = df_exploded.drop(columns=[col for col in df_exploded.columns if col.startswith('__index_level_')])\n",
    "        return Dataset.from_pandas(df_exploded)\n",
    "\n",
    "    def compute_sentence_embeddings(self, sentences):\n",
    "        sentences = [str(sentence) for sentence in sentences if isinstance(sentence, str)]\n",
    "        if not sentences:\n",
    "            raise ValueError(\"Input contains no valid strings.\")\n",
    "        inputs = self.tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.embedding_model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "    def compute_embeddings_after_explode(self, batch):\n",
    "        sentences = batch['sentences']\n",
    "        valid_sentences = [str(sentence) for sentence in sentences if isinstance(sentence, str)]\n",
    "        if not valid_sentences:\n",
    "            batch['sentence_embeddings'] = [[]] * len(sentences)\n",
    "            return batch\n",
    "        embeddings = self.compute_sentence_embeddings(valid_sentences)\n",
    "        embeddings = embeddings.astype(np.float32)\n",
    "        final_embeddings = []\n",
    "        embed_idx = 0\n",
    "        for sentence in sentences:\n",
    "            if isinstance(sentence, str):\n",
    "                final_embeddings.append(embeddings[embed_idx])\n",
    "                embed_idx += 1\n",
    "            else:\n",
    "                final_embeddings.append(np.zeros(embeddings.shape[1], dtype=np.float32))\n",
    "        batch['sentence_embeddings'] = final_embeddings\n",
    "        return batch\n",
    "\n",
    "    def apply_embeddings(self, dataset_exploded):\n",
    "        return dataset_exploded.map(self.compute_embeddings_after_explode, batched=True, batch_size=128)\n",
    "\n",
    "    def extract_key_thought(self, cluster_sentences):\n",
    "        sentences = cluster_sentences.split(\" | \")\n",
    "        embeddings = self.compute_sentence_embeddings(sentences)\n",
    "        centroid = np.mean(embeddings, axis=0)\n",
    "        similarities = cosine_similarity(embeddings, [centroid])\n",
    "        key_sentence_index = np.argmax(similarities)\n",
    "        return sentences[key_sentence_index]\n",
    "\n",
    "    def count_words(self, cluster_sentences):\n",
    "        words = cluster_sentences.split()\n",
    "        return len(words)\n",
    "\n",
    "    def recluster_large_cluster(self, cluster_sentences, eps=0.1, min_samples=2):\n",
    "        sentences = cluster_sentences.split(\" | \")\n",
    "        embeddings = self.compute_sentence_embeddings(sentences)\n",
    "        re_clustering = DBSCAN(eps=eps, min_samples=min_samples, metric=\"cosine\").fit(embeddings)\n",
    "        re_cluster_dict = {}\n",
    "        for idx, label in enumerate(re_clustering.labels_):\n",
    "            if label == -1:\n",
    "                continue\n",
    "            label_str = str(label)\n",
    "            if label_str not in re_cluster_dict:\n",
    "                re_cluster_dict[label_str] = []\n",
    "            re_cluster_dict[label_str].append(sentences[idx])\n",
    "        return [\" | \".join(cluster) for cluster in re_cluster_dict.values()]\n",
    "\n",
    "    def recursive_clustering(self, cluster_sentences, threshold, eps=0.22, min_samples=3, min_eps=0.02):\n",
    "        current_eps = eps\n",
    "        current_min_samples = min_samples\n",
    "        new_clusters = [cluster_sentences]\n",
    "        while True:\n",
    "            next_clusters = []\n",
    "            reclustered_any = False\n",
    "            for cluster in new_clusters:\n",
    "                if self.count_words(cluster) > threshold:\n",
    "                    while current_eps >= min_eps:\n",
    "                        reclustered = self.recluster_large_cluster(cluster, eps=current_eps, min_samples=current_min_samples)\n",
    "                        if len(reclustered) > 1:\n",
    "                            next_clusters.extend(reclustered)\n",
    "                            reclustered_any = True\n",
    "                            break\n",
    "                        else:\n",
    "                            if current_eps > min_eps:\n",
    "                                current_eps -= 0.05\n",
    "                    if len(reclustered) == 1:\n",
    "                        next_clusters.append(cluster)\n",
    "                else:\n",
    "                    next_clusters.append(cluster)\n",
    "            new_clusters = next_clusters\n",
    "            if not reclustered_any:\n",
    "                break\n",
    "        return new_clusters\n",
    "\n",
    "    def generate_predictions(self, dataset_exploded):\n",
    "        tokenizer = self.tokenizer_my\n",
    "        model = self.classification_model\n",
    "        if self.device == torch.device(\"cuda\"):\n",
    "            model = model.half()\n",
    "\n",
    "        reviews = dataset_exploded[\"sentences\"]\n",
    "        reviews = [str(review) for review in reviews if isinstance(review, str) and review.strip()]\n",
    "\n",
    "        class ReviewDataset(TorchDataset):\n",
    "            def __init__(self, reviews, tokenizer, max_len=128):\n",
    "                self.reviews = reviews\n",
    "                self.tokenizer = tokenizer\n",
    "                self.max_len = max_len\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.reviews)\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                review = self.reviews[idx]\n",
    "                encoding = self.tokenizer.encode_plus(\n",
    "                    review,\n",
    "                    add_special_tokens=True,\n",
    "                    max_length=self.max_len,\n",
    "                    return_token_type_ids=False,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_attention_mask=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                return {key: val.flatten() for key, val in encoding.items()}\n",
    "\n",
    "        dataset = ReviewDataset(reviews, tokenizer)\n",
    "        batch_size = 32\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        from torch.cuda.amp import autocast\n",
    "\n",
    "        for batch in tqdm(dataloader, desc=\"Предсказание отзывов\"):\n",
    "            batch = {key: val.to(self.device) for key, val in batch.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                with autocast():  # Используем смешанную точность\n",
    "                    outputs = model(**batch)\n",
    "                    logits = outputs[0] if isinstance(outputs, tuple) else outputs.logits\n",
    "                    probabilities = torch.softmax(logits, dim=-1)\n",
    "                    batch_predictions = (probabilities[:, 1] > 0.7).cpu().numpy()  # Используем порог 0.7\n",
    "                    predictions.extend(batch_predictions)\n",
    "\n",
    "        if len(predictions) != len(dataset_exploded):\n",
    "            print(f\"Warning: Length of predictions ({len(predictions)}) does not match length of index ({len(dataset_exploded)})\")\n",
    "            if len(predictions) < len(dataset_exploded):\n",
    "                missing_count = len(dataset_exploded) - len(predictions)\n",
    "                predictions.extend([0] * missing_count)\n",
    "            elif len(predictions) > len(dataset_exploded):\n",
    "                predictions = predictions[:len(dataset_exploded)]\n",
    "        dataset_exploded = dataset_exploded.add_column(\"predictions\", predictions)\n",
    "        return dataset_exploded\n",
    "\n",
    "    def process_group(self, category_name, product_name, group):\n",
    "        all_sentences = group['sentences'].tolist()\n",
    "        if not all_sentences:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        try:\n",
    "            all_embeddings = self.compute_sentence_embeddings(all_sentences)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in computing embeddings for product {product_name}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        distance_matrix = squareform(pdist(all_embeddings, metric='cosine'))\n",
    "        clustering = hdbscan.HDBSCAN(min_samples=3, metric='precomputed').fit(distance_matrix)\n",
    "\n",
    "        cluster_dict = {}\n",
    "        for idx, label in enumerate(clustering.labels_):\n",
    "            if label == -1:\n",
    "                continue\n",
    "            label_str = str(label)\n",
    "            if label_str not in cluster_dict:\n",
    "                cluster_dict[label_str] = set()\n",
    "            cluster_dict[label_str].add(all_sentences[idx])\n",
    "\n",
    "        clusters = [\" | \".join(sentences) for sentences in cluster_dict.values()]\n",
    "\n",
    "        if not clusters:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        group['binary_rating'] = group['review_rating'].apply(lambda x: 1 if x in [4, 5] else 0)\n",
    "        avg_rating = group['binary_rating'].mean()\n",
    "        rating_category = 'positive' if avg_rating > 0.7 else 'neutral'\n",
    "        rating_category = 'neutral' if avg_rating > 0.5 else 'negative'\n",
    "\n",
    "        threshold = self.determine_threshold(clusters)\n",
    "\n",
    "        final_clusters = []\n",
    "        for cluster in clusters:\n",
    "            if self.count_words(cluster) > threshold:\n",
    "                final_clusters.extend(self.recursive_clustering(cluster, threshold))\n",
    "            else:\n",
    "                final_clusters.append(cluster)\n",
    "\n",
    "        # Обеспечение минимального количества кластеров\n",
    "        final_clusters = self.ensure_minimum_clusters(final_clusters, threshold)\n",
    "\n",
    "        df_exploded_sorted = pd.DataFrame({\n",
    "            'category': category_name,\n",
    "            'product': product_name,\n",
    "            'avg_rating': avg_rating,\n",
    "            'rating_category': rating_category,\n",
    "            'cluster_sentences': final_clusters\n",
    "        })\n",
    "        df_exploded_sorted['word_count'] = df_exploded_sorted['cluster_sentences'].apply(self.count_words)\n",
    "        df_exploded_sorted['key_thought'] = df_exploded_sorted['cluster_sentences'].apply(self.extract_key_thought)\n",
    "        df_exploded_sorted = df_exploded_sorted.sort_values(by='word_count', ascending=False)\n",
    "\n",
    "        return df_exploded_sorted\n",
    "\n",
    "    def determine_threshold(self, clusters):\n",
    "        if len(clusters) == 1:\n",
    "            cluster_word_count = self.count_words(clusters[0])\n",
    "            if cluster_word_count > 20:\n",
    "                return cluster_word_count / 2\n",
    "            return cluster_word_count\n",
    "        return np.min([np.mean([self.count_words(cluster) for cluster in clusters]) * 1.5, 250])\n",
    "\n",
    "    def ensure_minimum_clusters(self, final_clusters, threshold):\n",
    "        while len(final_clusters) < 3 and any(self.count_words(cluster) > threshold for cluster in final_clusters):\n",
    "            largest_cluster = max(final_clusters, key=self.count_words)\n",
    "            final_clusters.remove(largest_cluster)\n",
    "            new_clusters = self.recursive_clustering(largest_cluster, threshold)\n",
    "            if len(new_clusters) <= 1:\n",
    "                final_clusters.append(largest_cluster)\n",
    "                break\n",
    "            final_clusters.extend(new_clusters)\n",
    "        return final_clusters\n",
    "    \n",
    "    def cluster_reviews(self, dataset_exploded):\n",
    "        # Фильтрация на основе предсказаний\n",
    "        dataset_filtered = dataset_exploded.filter(lambda x: x['predictions'] == 1)\n",
    "        \n",
    "        # Преобразование в pandas DataFrame для группировки\n",
    "        df_filtered = dataset_filtered.to_pandas()\n",
    "        grouped = df_filtered.groupby(['category', 'product'])\n",
    "\n",
    "        results = []\n",
    "        \n",
    "        # Последовательная обработка без параллелизма\n",
    "        for (category_name, product_name), group in tqdm(grouped, desc=\"Processing categories and products\"):\n",
    "            result_df = self.process_group(category_name, product_name, group)\n",
    "            if not result_df.empty:\n",
    "                results.append(result_df)\n",
    "\n",
    "        if results:  # Проверяем, что список results не пуст\n",
    "            final_result = pd.concat(results, ignore_index=True)\n",
    "            final_result = final_result[((final_result['word_count'] > 10) & (final_result['key_thought'].str.len() > 5))]\n",
    "            final_result.to_csv(\"./reviews_keywords/feedbackfueltest.csv\")\n",
    "        else:\n",
    "            print(\"No valid results to concatenate. Returning an empty DataFrame.\")\n",
    "            final_result = pd.DataFrame()  # Возвращаем пустой DataFrame, если нет данных для объединения\n",
    "        \n",
    "        return final_result\n",
    "\n",
    "    def run(self):\n",
    "        dataset_exploded = self.process_reviews()\n",
    "        dataset_exploded = self.apply_embeddings(dataset_exploded)\n",
    "        dataset_exploded = self.generate_predictions(dataset_exploded)\n",
    "        result = self.cluster_reviews(dataset_exploded)\n",
    "        return result\n",
    "\n",
    "\n",
    "reviews_keywords = ReviewsKeywords(csv_path=\"./reviews_keywords/wildberries_reviews.csv\",\n",
    "                                    model_path='./reviews_keywords/fine_tuned_model')\n",
    "final_result = reviews_keywords.run()\n",
    "final_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>word_count</th>\n",
       "      <th>key_thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВПМ / Антибукс - антипробуксовочные траки утол...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Переднее колесо закрылось в снегу, подложили п...</td>\n",
       "      <td>40</td>\n",
       "      <td>Переднее колесо закрылось в снегу, подложили п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВПМ / Антибукс - антипробуксовочные траки утол...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>neutral</td>\n",
       "      <td>На вид крепкие. | Вроде прочные. | На вид проч...</td>\n",
       "      <td>12</td>\n",
       "      <td>На вид крепкие.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>neutral</td>\n",
       "      <td>В деле не пробовал | В деле пока не пробовала....</td>\n",
       "      <td>37</td>\n",
       "      <td>В деле не пробовал</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>Пахнет и Точка / Ароматизатор в машину автопар...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Рекомендую, буду брать еще | Закажу | мыМыочно...</td>\n",
       "      <td>20</td>\n",
       "      <td>Буду заказывать ещё.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>Пахнет и Точка / Ароматизатор в машину автопар...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Еле пахнет. | Он даже не пахнет. | Пахнет каки...</td>\n",
       "      <td>13</td>\n",
       "      <td>Еле пахнет.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>Пахнет и Точка / Ароматизатор в машину автопар...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>neutral</td>\n",
       "      <td>🔥🔥🔥🔥🔥🔥 запах. | Запах огонь) | Запах огонь!!!!...</td>\n",
       "      <td>11</td>\n",
       "      <td>Запах 🔥!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Убирает ржавчину хорошо через 10-20 минут | Со...</td>\n",
       "      <td>76</td>\n",
       "      <td>Ржавчину убирает отлично.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Ржавчина уже хорошо въелась, пришлось нескольк...</td>\n",
       "      <td>38</td>\n",
       "      <td>Ржавчина уже хорошо въелась, пришлось нескольк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Фото «до» к сожалению не сделала, только «посл...</td>\n",
       "      <td>24</td>\n",
       "      <td>Фото «до» к сожалению не сделала, только «после»</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>neutral</td>\n",
       "      <td>В деле пока не пробовала. | В деле не пробовал...</td>\n",
       "      <td>14</td>\n",
       "      <td>В деле не пробовал</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 category  \\\n",
       "0                     /Автотовары/OFFroad   \n",
       "1                     /Автотовары/OFFroad   \n",
       "3                     /Автотовары/OFFroad   \n",
       "4   /Автотовары/Автокосметика и автохимия   \n",
       "5   /Автотовары/Автокосметика и автохимия   \n",
       "6   /Автотовары/Автокосметика и автохимия   \n",
       "7   /Автотовары/Автокосметика и автохимия   \n",
       "8   /Автотовары/Автокосметика и автохимия   \n",
       "9   /Автотовары/Автокосметика и автохимия   \n",
       "10  /Автотовары/Автокосметика и автохимия   \n",
       "\n",
       "                                              product  avg_rating  \\\n",
       "0   ВПМ / Антибукс - антипробуксовочные траки утол...    0.819588   \n",
       "1   ВПМ / Антибукс - антипробуксовочные траки утол...    0.819588   \n",
       "3   ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...    0.842975   \n",
       "4   Пахнет и Точка / Ароматизатор в машину автопар...    0.704545   \n",
       "5   Пахнет и Точка / Ароматизатор в машину автопар...    0.704545   \n",
       "6   Пахнет и Точка / Ароматизатор в машину автопар...    0.704545   \n",
       "7   ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "8   ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "9   ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "10  ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "\n",
       "   rating_category                                  cluster_sentences  \\\n",
       "0          neutral  Переднее колесо закрылось в снегу, подложили п...   \n",
       "1          neutral  На вид крепкие. | Вроде прочные. | На вид проч...   \n",
       "3          neutral  В деле не пробовал | В деле пока не пробовала....   \n",
       "4          neutral  Рекомендую, буду брать еще | Закажу | мыМыочно...   \n",
       "5          neutral  Еле пахнет. | Он даже не пахнет. | Пахнет каки...   \n",
       "6          neutral  🔥🔥🔥🔥🔥🔥 запах. | Запах огонь) | Запах огонь!!!!...   \n",
       "7          neutral  Убирает ржавчину хорошо через 10-20 минут | Со...   \n",
       "8          neutral  Ржавчина уже хорошо въелась, пришлось нескольк...   \n",
       "9          neutral  Фото «до» к сожалению не сделала, только «посл...   \n",
       "10         neutral  В деле пока не пробовала. | В деле не пробовал...   \n",
       "\n",
       "    word_count                                        key_thought  \n",
       "0           40  Переднее колесо закрылось в снегу, подложили п...  \n",
       "1           12                                    На вид крепкие.  \n",
       "3           37                                 В деле не пробовал  \n",
       "4           20                               Буду заказывать ещё.  \n",
       "5           13                                        Еле пахнет.  \n",
       "6           11                                         Запах 🔥!!!  \n",
       "7           76                          Ржавчину убирает отлично.  \n",
       "8           38  Ржавчина уже хорошо въелась, пришлось нескольк...  \n",
       "9           24   Фото «до» к сожалению не сделала, только «после»  \n",
       "10          14                                 В деле не пробовал  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>word_count</th>\n",
       "      <th>key_thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Спорт/Страйкбол и пейнтбол/Аксессуары</td>\n",
       "      <td>karbi / Рюкзак тактический туристический - кар...</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Много доп карманов, чехол от дождя, прорезинен...</td>\n",
       "      <td>203</td>\n",
       "      <td>Рюкзак вместительный, прочный, есть защитный ч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Спорт/Страйкбол и пейнтбол/Аксессуары</td>\n",
       "      <td>karbi / Рюкзак тактический туристический - кар...</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>neutral</td>\n",
       "      <td>В подарок шёл компас,, налобныйфонарь,, ножане...</td>\n",
       "      <td>69</td>\n",
       "      <td>В подарок положили фонарик налобный, компас и ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 category  \\\n",
       "0  /Спорт/Страйкбол и пейнтбол/Аксессуары   \n",
       "1  /Спорт/Страйкбол и пейнтбол/Аксессуары   \n",
       "\n",
       "                                             product  avg_rating  \\\n",
       "0  karbi / Рюкзак тактический туристический - кар...    0.797101   \n",
       "1  karbi / Рюкзак тактический туристический - кар...    0.797101   \n",
       "\n",
       "  rating_category                                  cluster_sentences  \\\n",
       "0         neutral  Много доп карманов, чехол от дождя, прорезинен...   \n",
       "1         neutral  В подарок шёл компас,, налобныйфонарь,, ножане...   \n",
       "\n",
       "   word_count                                        key_thought  \n",
       "0         203  Рюкзак вместительный, прочный, есть защитный ч...  \n",
       "1          69  В подарок положили фонарик налобный, компас и ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf.pandas  # Импортирование cuDF и активация его использования\n",
    "cudf.pandas.install()  # Установка cuDF как основного интерфейса для pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pyarrow.parquet as pq\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# # Чтение Parquet-файла с использованием pyarrow\n",
    "# table = pq.read_table('./reviews_keywords/wildberries_reviews_corrected.parquet')\n",
    "\n",
    "# # Преобразование в pandas DataFrame\n",
    "# df_pandas = table.to_pandas()\n",
    "\n",
    "# # Преобразование pandas DataFrame в Dask DataFrame\n",
    "# df_dask = dd.from_pandas(df_pandas, npartitions=100)  # Укажите количество нужных вам частей\n",
    "# df_pandas = None\n",
    "# table = None\n",
    "# import gc\n",
    "# gc.collect()\n",
    "# df_dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'cudf.core.dataframe.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype\n",
      "---  ------            --------------  -----\n",
      " 0   Unnamed: 0        1000 non-null   int64\n",
      " 1   review_full_text  1000 non-null   object\n",
      " 2   review_rating     1000 non-null   int64\n",
      " 3   product           1000 non-null   object\n",
      " 4   category          1000 non-null   object\n",
      " 5   url               1000 non-null   object\n",
      " 6   corrected_text    1000 non-null   object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 540.9+ KB\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv(\"./reviews_keywords/wildberries_reviews.csv\", nrows=1000)\n",
    "result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оставляем только по 5 записей для каждого уникального значения в столбце 'product'\n",
    "# result_limited = result.groupby('product').apply(lambda x: x.iloc[5:8]).reset_index(drop=True)\n",
    "result_limited = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, BertTokenizerFast\n",
    "import torch\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Проверка доступности GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import DBSCAN\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, BertConfig\n",
    "import hdbscan\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Загрузка дообученной модели и токенизатора\n",
    "# Загружаем конфигурацию модели\n",
    "\n",
    "\n",
    "# Загрузка модели и токенайзера от Сбербанка\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"./reviews_keywords/fine_tuned_model\")\n",
    "model = AutoModel.from_pretrained(\"./reviews_keywords/fine_tuned_model\").to(device)\n",
    "# Инициализируем модель с конфигурацией\n",
    "config = BertConfig.from_pretrained('./reviews_keywords/fine_tuned_model', output_hidden_states=True)\n",
    "model_classification = BertForSequenceClassification.from_pretrained('./reviews_keywords/fine_tuned_model', config=config).to(device)\n",
    "\n",
    "        # self.tokenizer_my = BertTokenizerFast.from_pretrained(self.model_path)\n",
    "        #  # Загрузка модели для классификации\n",
    "        # self.classification_model = BertForSequenceClassification.from_pretrained(self.model_path).to(self.device)\n",
    "        # # Загрузка базовой модели для получения эмбеддингов\n",
    "        # self.embedding_model = AutoModel.from_pretrained(self.model_path).to(self.device)\n",
    "\n",
    "spacy.prefer_gpu()\n",
    "# Загрузка и настройка модели SpaCy\n",
    "nlp = spacy.load(\"ru_core_news_lg\", disable=[\"ner\", \"tagger\", \"attribute_ruler\", \"lemmatizer\"])\n",
    "\n",
    "df = result_limited\n",
    "\n",
    "# Преобразование pandas DataFrame в Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837a44705b1d44828df1a47b43273697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629350b5326d44b08abba9becf88c64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2061 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[\\n\\r\\t]+|\\s{2,}', ' ', text)  # Объединяем шаги для замены пробелов\n",
    "    text = re.sub(r'(?<!\\.)\\s*\\.\\s*|\\s*\\.\\s*(?!\\.)', '. ', text)  # Оптимизация замены точки\n",
    "    return text.strip().rstrip('.')\n",
    "\n",
    "def split_reviews_into_sentences(batch):\n",
    "    # Очистка текстов\n",
    "    cleaned_texts = [clean_text(text) for text in batch['corrected_text']]\n",
    "    \n",
    "    # Обработка текстов с помощью nlp.pipe с указанием batch_size\n",
    "    docs = list(nlp.pipe(cleaned_texts, batch_size=64))  # Здесь 64 - пример значения\n",
    "\n",
    "    # Извлечение предложений\n",
    "    batch['sentences'] = [[sent.text for sent in doc.sents] for doc in docs]\n",
    "    \n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(split_reviews_into_sentences, batched=True, batch_size=32)\n",
    "\n",
    "# Преобразуем Dataset обратно в pandas DataFrame\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "# Выполним explode по столбцу с предложениями\n",
    "df_exploded = df.explode('sentences').reset_index(drop=True)\n",
    "\n",
    "# Удаляем лишние столбцы, которые появились после explode\n",
    "df_exploded = df_exploded.drop(columns=[col for col in df_exploded.columns if col.startswith('__index_level_')])\n",
    "\n",
    "# Преобразуем DataFrame обратно в Hugging Face Dataset\n",
    "dataset_exploded = Dataset.from_pandas(df_exploded)\n",
    "\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "def compute_sentence_embeddings(sentences):\n",
    "    # Фильтруем список, оставляя только строки\n",
    "    sentences = [str(sentence) for sentence in sentences if isinstance(sentence, str)]\n",
    "    \n",
    "    if not sentences:\n",
    "        raise ValueError(\"Input contains no valid strings.\")\n",
    "\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with autocast():  # Используем mixed precision для ускорения\n",
    "            outputs = model_classification(**inputs)\n",
    "    \n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "def compute_embeddings_after_explode(batch):\n",
    "    sentences = batch['sentences']\n",
    "\n",
    "    # Проверяем, что все элементы в batch являются строками\n",
    "    valid_sentences = [str(sentence) for sentence in sentences if isinstance(sentence, str)]\n",
    "    \n",
    "    if not valid_sentences:\n",
    "        batch['sentence_embeddings'] = [[]] * len(sentences)  # Если нет валидных предложений, возвращаем пустые эмбеддинги\n",
    "        return batch\n",
    "\n",
    "    embeddings = compute_sentence_embeddings(valid_sentences)\n",
    "\n",
    "    # Приведение эмбеддингов к типу float32 для консистентности\n",
    "    embeddings = embeddings.astype(np.float32)\n",
    "\n",
    "    # Проверяем, что количество эмбеддингов совпадает с количеством предложений\n",
    "    if len(embeddings) != len(valid_sentences):\n",
    "        raise ValueError(\"Количество эмбеддингов не совпадает с количеством предложений.\")\n",
    "    \n",
    "    # Если количество предложений после фильтрации не совпадает с исходным, корректируем выходные данные\n",
    "    final_embeddings = []\n",
    "    embed_idx = 0\n",
    "    for sentence in sentences:\n",
    "        if isinstance(sentence, str):\n",
    "            final_embeddings.append(embeddings[embed_idx])\n",
    "            embed_idx += 1\n",
    "        else:\n",
    "            final_embeddings.append(np.zeros(embeddings.shape[1], dtype=np.float32))  # Добавляем нулевые эмбеддинги для невалидных предложений\n",
    "\n",
    "    batch['sentence_embeddings'] = final_embeddings\n",
    "    return batch\n",
    "\n",
    "# Применение функции\n",
    "dataset = dataset_exploded.map(compute_embeddings_after_explode, batched=True, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, BertConfig\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import hdbscan  # HDBSCAN для более стабильной кластеризации с поддержкой кастомных метрик\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Предсказание отзывов:   0%|                                                                                                                                                                        | 0/65 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Предсказание отзывов: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 65/65 [00:11<00:00,  5.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_full_text</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "      <th>corrected_text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Работает хорошо.</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 3000lb 13...</td>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>Работает хорошо.</td>\n",
       "      <td>Работает хорошо</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Пришло быстро, все целое на вид. Завтра буду и...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 3000lb 13...</td>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>Пришло быстро, все целое на вид. Завтра буду и...</td>\n",
       "      <td>Пришло быстро, все целое на вид.</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Пришло быстро, все целое на вид. Завтра буду и...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 3000lb 13...</td>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>Пришло быстро, все целое на вид. Завтра буду и...</td>\n",
       "      <td>Завтра буду испытывать</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Купил на квадр для поднятия отвала, установка ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 3000lb 13...</td>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>Купил на квадр для поднятия отвала, установка ...</td>\n",
       "      <td>Купил на квадр для поднятия отвала, установка ...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Лебёдка хорошая. Но в инструкции ни слова про ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 3000lb 13...</td>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>Лебёдка хорошая. Но в инструкции ни слова про ...</td>\n",
       "      <td>Лебёдка хорошая.</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                   review_full_text  \\\n",
       "0           0                                   Работает хорошо.   \n",
       "1           1  Пришло быстро, все целое на вид. Завтра буду и...   \n",
       "2           1  Пришло быстро, все целое на вид. Завтра буду и...   \n",
       "3           2  Купил на квадр для поднятия отвала, установка ...   \n",
       "4           3  Лебёдка хорошая. Но в инструкции ни слова про ...   \n",
       "\n",
       "   review_rating                                            product  \\\n",
       "0              5  Shtapler / Лебедка электрическая 12v 3000lb 13...   \n",
       "1              5  Shtapler / Лебедка электрическая 12v 3000lb 13...   \n",
       "2              5  Shtapler / Лебедка электрическая 12v 3000lb 13...   \n",
       "3              5  Shtapler / Лебедка электрическая 12v 3000lb 13...   \n",
       "4              5  Shtapler / Лебедка электрическая 12v 3000lb 13...   \n",
       "\n",
       "              category                                                url  \\\n",
       "0  /Автотовары/OFFroad  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "1  /Автотовары/OFFroad  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "2  /Автотовары/OFFroad  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "3  /Автотовары/OFFroad  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "4  /Автотовары/OFFroad  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "\n",
       "                                      corrected_text  \\\n",
       "0                                   Работает хорошо.   \n",
       "1  Пришло быстро, все целое на вид. Завтра буду и...   \n",
       "2  Пришло быстро, все целое на вид. Завтра буду и...   \n",
       "3  Купил на квадр для поднятия отвала, установка ...   \n",
       "4  Лебёдка хорошая. Но в инструкции ни слова про ...   \n",
       "\n",
       "                                           sentences  __index_level_0__  \\\n",
       "0                                    Работает хорошо                  0   \n",
       "1                   Пришло быстро, все целое на вид.                  1   \n",
       "2                             Завтра буду испытывать                  2   \n",
       "3  Купил на квадр для поднятия отвала, установка ...                  3   \n",
       "4                                   Лебёдка хорошая.                  4   \n",
       "\n",
       "   predictions  \n",
       "0        False  \n",
       "1        False  \n",
       "2         True  \n",
       "3         True  \n",
       "4         True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Определение устройства (GPU или CPU)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Перевод модели в режим FP16, если это возможно\n",
    "if use_cuda:\n",
    "    model_classification = model_classification.half()\n",
    "\n",
    "# Пример данных (замените на реальные данные)\n",
    "reviews = dataset_exploded[\"sentences\"]\n",
    "\n",
    "# Очистка данных от некорректных значений\n",
    "reviews = [str(review) for review in reviews if isinstance(review, str) and review.strip()]\n",
    "\n",
    "# Создание кастомного Dataset для обработки отзывов\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, tokenizer, max_len=128):\n",
    "        self.reviews = reviews\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = self.reviews[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {key: val.flatten() for key, val in encoding.items()}\n",
    "\n",
    "# Создаем датасет и DataLoader\n",
    "dataset = ReviewDataset(reviews, tokenizer)\n",
    "batch_size = 32  # Размер батча можно изменить в зависимости от объема доступной памяти GPU\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Получение предсказаний с отображением прогресса\n",
    "predictions = []\n",
    "\n",
    "from torch.cuda.amp import autocast  # Импортируем autocast для смешанной точности\n",
    "\n",
    "for batch in tqdm(dataloader, desc=\"Предсказание отзывов\"):\n",
    "    batch = {key: val.to(device) for key, val in batch.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with autocast():  # Используем смешанную точность\n",
    "            outputs = model_classification(**batch)\n",
    "            logits = outputs[0] if isinstance(outputs, tuple) else outputs.logits\n",
    "            probabilities = torch.softmax(logits, dim=-1)\n",
    "            batch_predictions = (probabilities[:, 1] > 0.7).cpu().numpy()  # Используем порог 0.7\n",
    "            predictions.extend(batch_predictions)\n",
    "\n",
    "# Преобразование в DataFrame, если это еще не сделано\n",
    "if not isinstance(dataset_exploded, pd.DataFrame):\n",
    "    dataset_exploded = pd.DataFrame(dataset_exploded)\n",
    "\n",
    "# Проверка и обработка несоответствия длины\n",
    "if len(predictions) != len(dataset_exploded):\n",
    "    print(f\"Warning: Length of predictions ({len(predictions)}) does not match length of index ({len(dataset_exploded)})\")\n",
    "    \n",
    "    # Пример: Заполнение недостающих значений\n",
    "    if len(predictions) < len(dataset_exploded):\n",
    "        missing_count = len(dataset_exploded) - len(predictions)\n",
    "        predictions.extend([0] * missing_count)  # Добавляем нули в случае недостатка предсказаний\n",
    "\n",
    "    elif len(predictions) > len(dataset_exploded):\n",
    "        predictions = predictions[:len(dataset_exploded)]  # Обрезаем список предсказаний\n",
    "\n",
    "# Присоединение предсказаний к датасету\n",
    "dataset_exploded['predictions'] = predictions\n",
    "dataset_exploded.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Настройка логирования\n",
    "logging.basicConfig(filename='./reviews_keywords/clustering.log', \n",
    "                    level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Загрузка модели spaCy для русского языка\n",
    "nlp = spacy.load(\"ru_core_news_lg\")\n",
    "\n",
    "# Установка стоп-слов\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories and products: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Total words before clustering: 8981'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Total words thrown away during clustering: 5445'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Total words after clustering: 3894'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>key_thought</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>Hangkai / Лебедка электрическая влагозащитная ...</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>positive</td>\n",
       "      <td>Провод плюсовой тонкий 10мм, лучше сразу замен...</td>\n",
       "      <td>Рычаг свободного хода лебедки не герметичный, ...</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>MOTORin / Расширитель колёсных арок 40 мм</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>positive</td>\n",
       "      <td>без каркасной проволоки и пластинки ставятся л...</td>\n",
       "      <td>Для установки требуется частое сверление арок,...</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>MOTORin / расширители арок</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>positive</td>\n",
       "      <td>Расширители хорошие вот только пришлось для фо...</td>\n",
       "      <td>На вид огонь 🔥ещё не ставил</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 3000lb 13...</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Купил на квадр для поднятия отвала, установка ...</td>\n",
       "      <td>Отличная лебедка, но не подошла</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 3500lb 15...</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>positive</td>\n",
       "      <td>Хорошая лебедка, со своей задачей справляется ...</td>\n",
       "      <td>Нормальный лебёдка, но шумел, разобрался полож...</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 4500lb 20...</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>positive</td>\n",
       "      <td>Хорошая лебедка, со своей задачей справляется ...</td>\n",
       "      <td>Нормальный лебёдка, но шумел, разобрался полож...</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>Vixem / Лебедка автомобильная 12 v 4000 1814 к...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>Один метр троса зажали, смазки не много и та г...</td>\n",
       "      <td>Один метр троса зажали, смазки не много и та г...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВПМ / Антибукс - антипробуксовочные траки утол...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>positive</td>\n",
       "      <td>Не думаю, что газель выдержит у меня газель-4 ...</td>\n",
       "      <td>Зимняя резина пережевывает эти пластиковые ант...</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>positive</td>\n",
       "      <td>Иногда их выбрасывало из-под колес. | Хватало ...</td>\n",
       "      <td>Не выручать даже летом, чуток сел в небольшую ...</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>positive</td>\n",
       "      <td>В деле не пробовал | Траки мощные, в деле ещё ...</td>\n",
       "      <td>В деле пока не пробовала.</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ПК ЛИМ / Браслеты цепи противоскольжения</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>positive</td>\n",
       "      <td>Задний привод, выехать не мог, одел цепи, выех...</td>\n",
       "      <td>Протягивать ленту с той стороны колеса, одурев...</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ПК ЛИМ / Цепи противоскольжения для легковых а...</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>positive</td>\n",
       "      <td>Задний привод, выехать не мог, одел цепи, выех...</td>\n",
       "      <td>Протягивать ленту с той стороны колеса, одурев...</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>Фрегат Лифт Подвеска / Лифт комплект рессоры К...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>positive</td>\n",
       "      <td>На вид не плохие, но к сожалению на уаз профи ...</td>\n",
       "      <td>Встали как родные устанавливал на петро пикапа</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>Пахнет и Точка / Ароматизатор в машину автопар...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>positive</td>\n",
       "      <td>Небольшой лайфхак, чтоб аромат пах, снимите пл...</td>\n",
       "      <td>Полная фигня, запах вкусный, но его просто нет...</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>positive</td>\n",
       "      <td>Отчистил этим средством всю ржавчину. | Утром ...</td>\n",
       "      <td>Был рыжик под задним стеклом, убрал его просто...</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>positive</td>\n",
       "      <td>.. | ...</td>\n",
       "      <td>..</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 category  \\\n",
       "0                     /Автотовары/OFFroad   \n",
       "1                     /Автотовары/OFFroad   \n",
       "2                     /Автотовары/OFFroad   \n",
       "3                     /Автотовары/OFFroad   \n",
       "4                     /Автотовары/OFFroad   \n",
       "5                     /Автотовары/OFFroad   \n",
       "6                     /Автотовары/OFFroad   \n",
       "7                     /Автотовары/OFFroad   \n",
       "8                     /Автотовары/OFFroad   \n",
       "9                     /Автотовары/OFFroad   \n",
       "10                    /Автотовары/OFFroad   \n",
       "11                    /Автотовары/OFFroad   \n",
       "12                    /Автотовары/OFFroad   \n",
       "13  /Автотовары/Автокосметика и автохимия   \n",
       "14  /Автотовары/Автокосметика и автохимия   \n",
       "15  /Автотовары/Автокосметика и автохимия   \n",
       "\n",
       "                                              product  avg_rating  \\\n",
       "0   Hangkai / Лебедка электрическая влагозащитная ...    0.873016   \n",
       "1           MOTORin / Расширитель колёсных арок 40 мм    0.937500   \n",
       "2                          MOTORin / расширители арок    0.722222   \n",
       "3   Shtapler / Лебедка электрическая 12v 3000lb 13...    0.647059   \n",
       "4   Shtapler / Лебедка электрическая 12v 3500lb 15...    0.843750   \n",
       "5   Shtapler / Лебедка электрическая 12v 4500lb 20...    0.843750   \n",
       "6   Vixem / Лебедка автомобильная 12 v 4000 1814 к...    1.000000   \n",
       "7   ВПМ / Антибукс - антипробуксовочные траки утол...    0.819588   \n",
       "8   ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...    0.842975   \n",
       "9   ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...    0.842975   \n",
       "10           ПК ЛИМ / Браслеты цепи противоскольжения    0.840000   \n",
       "11  ПК ЛИМ / Цепи противоскольжения для легковых а...    0.840000   \n",
       "12  Фрегат Лифт Подвеска / Лифт комплект рессоры К...    0.750000   \n",
       "13  Пахнет и Точка / Ароматизатор в машину автопар...    0.704545   \n",
       "14  ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "15  ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "\n",
       "   rating_category                                  cluster_sentences  \\\n",
       "0         positive  Провод плюсовой тонкий 10мм, лучше сразу замен...   \n",
       "1         positive  без каркасной проволоки и пластинки ставятся л...   \n",
       "2         positive  Расширители хорошие вот только пришлось для фо...   \n",
       "3          neutral  Купил на квадр для поднятия отвала, установка ...   \n",
       "4         positive  Хорошая лебедка, со своей задачей справляется ...   \n",
       "5         positive  Хорошая лебедка, со своей задачей справляется ...   \n",
       "6         positive  Один метр троса зажали, смазки не много и та г...   \n",
       "7         positive  Не думаю, что газель выдержит у меня газель-4 ...   \n",
       "8         positive  Иногда их выбрасывало из-под колес. | Хватало ...   \n",
       "9         positive  В деле не пробовал | Траки мощные, в деле ещё ...   \n",
       "10        positive  Задний привод, выехать не мог, одел цепи, выех...   \n",
       "11        positive  Задний привод, выехать не мог, одел цепи, выех...   \n",
       "12        positive  На вид не плохие, но к сожалению на уаз профи ...   \n",
       "13        positive  Небольшой лайфхак, чтоб аромат пах, снимите пл...   \n",
       "14        positive  Отчистил этим средством всю ржавчину. | Утром ...   \n",
       "15        positive                                           .. | ...   \n",
       "\n",
       "                                          key_thought  word_count  \n",
       "0   Рычаг свободного хода лебедки не герметичный, ...         335  \n",
       "1   Для установки требуется частое сверление арок,...         170  \n",
       "2                         На вид огонь 🔥ещё не ставил         138  \n",
       "3                     Отличная лебедка, но не подошла         138  \n",
       "4   Нормальный лебёдка, но шумел, разобрался полож...         233  \n",
       "5   Нормальный лебёдка, но шумел, разобрался полож...         233  \n",
       "6   Один метр троса зажали, смазки не много и та г...          41  \n",
       "7   Зимняя резина пережевывает эти пластиковые ант...         431  \n",
       "8   Не выручать даже летом, чуток сел в небольшую ...         371  \n",
       "9                           В деле пока не пробовала.          37  \n",
       "10  Протягивать ленту с той стороны колеса, одурев...         425  \n",
       "11  Протягивать ленту с той стороны колеса, одурев...         425  \n",
       "12     Встали как родные устанавливал на петро пикапа          41  \n",
       "13  Полная фигня, запах вкусный, но его просто нет...         389  \n",
       "14  Был рыжик под задним стеклом, убрал его просто...         484  \n",
       "15                                                 ..           3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_words_before = 0\n",
    "total_words_thrown = 0\n",
    "total_words_after = 0\n",
    "\n",
    "# Перевод модели в режим FP16, если это возможно\n",
    "if torch.cuda.is_available():\n",
    "    model_classification = model_classification.half()\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def automatic_dbscan_params(embeddings, target_percentile=0.8, min_samples_factor=0.1):\n",
    "    n_samples = len(embeddings)\n",
    "    logging.info(f\"n_samples: {n_samples}\")\n",
    "    n_neighbors = min(15, n_samples)\n",
    "    \n",
    "    neighbors = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')\n",
    "    neighbors_fit = neighbors.fit(embeddings)\n",
    "    distances, indices = neighbors_fit.kneighbors(embeddings)\n",
    "    \n",
    "    eps = np.percentile(distances[:, n_neighbors - 1], target_percentile)\n",
    "    \n",
    "    # Убедимся, что eps положительное значение\n",
    "    if eps <= 0:\n",
    "        eps = 0.001  # Задаем минимально допустимое значение\n",
    "    \n",
    "    min_samples = 4 #max(int(n_samples * min_samples_factor), 2)\n",
    "    \n",
    "    return eps, min_samples\n",
    "\n",
    "\n",
    "def find_centroid(embeddings):\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "def compute_sentence_embeddings(sentences):\n",
    "    if not all(isinstance(sentence, str) and sentence.strip() for sentence in sentences):\n",
    "        raise ValueError(\"All items in the input must be non-empty strings.\")\n",
    "    \n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model_classification(**inputs)\n",
    "        if outputs.hidden_states is None:\n",
    "            raise ValueError(\"Модель не возвращает скрытые состояния. Проверьте конфигурацию модели.\")\n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "    embeddings = hidden_states.mean(dim=1).cpu().numpy()\n",
    "    return embeddings\n",
    "\n",
    "def extract_key_thought(cluster_sentences):\n",
    "    sentences = cluster_sentences.split(\" | \")\n",
    "    embeddings = compute_sentence_embeddings(sentences)\n",
    "    centroid = find_centroid(embeddings)\n",
    "    similarities = cosine_similarity(embeddings, [centroid])\n",
    "    key_sentence_index = np.argmax(similarities)\n",
    "    return sentences[key_sentence_index]\n",
    "\n",
    "def count_words(cluster_sentences):\n",
    "    words = cluster_sentences.split()\n",
    "    return len(words)\n",
    "\n",
    "def recluster_large_cluster(cluster_sentences, eps=0.1, min_samples=2):\n",
    "    sentences = cluster_sentences.split(\" | \")\n",
    "    embeddings = compute_sentence_embeddings(sentences)\n",
    "    \n",
    "    re_clustering = DBSCAN(eps=eps, min_samples=min_samples, metric=\"cosine\").fit(embeddings)\n",
    "    \n",
    "    re_cluster_dict = {}\n",
    "    local_words_thrown = 0\n",
    "    \n",
    "    for idx, label in enumerate(re_clustering.labels_):\n",
    "        if label == -1:\n",
    "            local_words_thrown += count_words(sentences[idx])  # Учет слов, отнесенных к шуму\n",
    "            continue\n",
    "        label_str = str(label)\n",
    "        if label_str not in re_cluster_dict:\n",
    "            re_cluster_dict[label_str] = []\n",
    "        re_cluster_dict[label_str].append(sentences[idx])\n",
    "    \n",
    "    return [\" | \".join(cluster) for cluster in re_cluster_dict.values()], local_words_thrown\n",
    "\n",
    "def dynamic_recursive_clustering(cluster_sentences, threshold, max_iterations=10):\n",
    "    new_clusters = [cluster_sentences]\n",
    "    iteration = 0\n",
    "    total_words_thrown_recursive = 0\n",
    "\n",
    "    while iteration < max_iterations:\n",
    "        next_clusters = []\n",
    "        reclustered_any = False\n",
    "        \n",
    "        for cluster in new_clusters:\n",
    "            if count_words(cluster) > threshold:\n",
    "                sentences = cluster.split(\" | \")\n",
    "                embeddings = compute_sentence_embeddings(sentences)\n",
    "                current_eps, current_min_samples = automatic_dbscan_params(embeddings)\n",
    "\n",
    "                reclustered, words_thrown = recluster_large_cluster(cluster, eps=current_eps, min_samples=current_min_samples)\n",
    "                total_words_thrown_recursive += words_thrown\n",
    "                \n",
    "                if len(reclustered) > 1:\n",
    "                    next_clusters.extend(reclustered)\n",
    "                    reclustered_any = True\n",
    "                else:\n",
    "                    next_clusters.append(cluster)\n",
    "                logging.info(f\"current_eps: {current_eps} current_min_samples: {current_min_samples} count_words(cluster): {count_words(cluster)}\")\n",
    "            else:\n",
    "                next_clusters.append(cluster)\n",
    "        \n",
    "        new_clusters = next_clusters\n",
    "        iteration += 1\n",
    "\n",
    "        if not reclustered_any:\n",
    "            break\n",
    "\n",
    "    return new_clusters, total_words_thrown_recursive\n",
    "\n",
    "# Основной процесс кластеризации по категориям и продуктам\n",
    "def count_words_before_clustering(sentences):\n",
    "    words = \" \".join(sentences).split()\n",
    "    return len(words)\n",
    "\n",
    "final_result = pd.DataFrame()\n",
    "\n",
    "for (category_name, product_name), group in tqdm(dataset_exploded[dataset_exploded[\"predictions\"] == 1].groupby(['category', 'product']), desc=\"Processing categories and products\"):\n",
    "    all_sentences = group['sentences'].tolist()\n",
    "\n",
    "    if not all_sentences:\n",
    "        continue\n",
    "\n",
    "    # Подсчет слов до кластеризации\n",
    "    total_words_before += count_words_before_clustering(all_sentences)\n",
    "\n",
    "    all_embeddings = compute_sentence_embeddings(all_sentences)\n",
    "    \n",
    "    eps, min_samples = automatic_dbscan_params(all_embeddings)\n",
    "\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples, metric='cosine').fit(all_embeddings)\n",
    "    \n",
    "    cluster_dict = {}\n",
    "    local_words_thrown = 0\n",
    "    \n",
    "    for idx, label in enumerate(clustering.labels_):\n",
    "        if label == -1:\n",
    "            local_words_thrown += count_words(all_sentences[idx])  # Учет слов, отнесенных к шуму\n",
    "            continue\n",
    "        label_str = str(label)\n",
    "        if label_str not in cluster_dict:\n",
    "            cluster_dict[label_str] = set()\n",
    "        cluster_dict[label_str].add(all_sentences[idx])\n",
    "\n",
    "    total_words_thrown += local_words_thrown\n",
    "\n",
    "    clusters = [\" | \".join(sentences) for sentences in cluster_dict.values()]\n",
    "\n",
    "    if not clusters:\n",
    "        continue\n",
    "\n",
    "    group['binary_rating'] = group['review_rating'].apply(lambda x: 1 if x in [4, 5] else 0)\n",
    "    avg_rating = group['binary_rating'].mean()\n",
    "    rating_category = 'positive' if avg_rating > 0.7 else 'neutral' if avg_rating > 0.5 else 'negative'\n",
    "\n",
    "    threshold = np.min([np.mean([count_words(cluster) for cluster in clusters]) * 1.5, 250])\n",
    "\n",
    "    final_clusters = []\n",
    "    for cluster in clusters:\n",
    "        if count_words(cluster) > threshold:\n",
    "            reclustered_clusters, words_thrown_recursive = dynamic_recursive_clustering(cluster, threshold)\n",
    "            total_words_thrown += words_thrown_recursive\n",
    "            final_clusters.extend(reclustered_clusters)\n",
    "        else:\n",
    "            final_clusters.append(cluster)\n",
    "\n",
    "    df_exploded_sorted = pd.DataFrame({\n",
    "        'category': category_name,\n",
    "        'product': product_name,\n",
    "        'avg_rating': avg_rating,\n",
    "        'rating_category': rating_category,\n",
    "        'cluster_sentences': final_clusters\n",
    "    })\n",
    "    \n",
    "    df_exploded_sorted['word_count'] = df_exploded_sorted['cluster_sentences'].apply(count_words)\n",
    "    total_words_after += df_exploded_sorted['word_count'].sum()\n",
    "    \n",
    "    df_exploded_sorted['key_thought'] = df_exploded_sorted['cluster_sentences'].apply(extract_key_thought)\n",
    "    df_exploded_sorted = df_exploded_sorted.sort_values(by='word_count', ascending=False)\n",
    "\n",
    "    final_result = pd.concat([final_result, df_exploded_sorted], ignore_index=True)\n",
    "\n",
    "# Показать результат\n",
    "display(f\"Total words before clustering: {total_words_before}\")\n",
    "display(f\"Total words thrown away during clustering: {total_words_thrown}\")\n",
    "display(f\"Total words after clustering: {total_words_after}\")\n",
    "display(final_result[['category', 'product', 'avg_rating', 'rating_category', 'cluster_sentences', 'key_thought', 'word_count']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>word_count</th>\n",
       "      <th>key_thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 3500lb 15...</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>positive</td>\n",
       "      <td>Хорошая лебедка, со своей задачей справляется ...</td>\n",
       "      <td>138</td>\n",
       "      <td>Нормальный лебёдка, но шумел, разобрался полож...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 4500lb 20...</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>positive</td>\n",
       "      <td>Хорошая лебедка, со своей задачей справляется ...</td>\n",
       "      <td>138</td>\n",
       "      <td>Нормальный лебёдка, но шумел, разобрался полож...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>MOTORin / Расширитель колёсных арок 40 мм</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>positive</td>\n",
       "      <td>Пришло с опозданием на два дня позже на ниву в...</td>\n",
       "      <td>83</td>\n",
       "      <td>Сами расширители арок нормальные, но ставить н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 3000lb 13...</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Но в инструкции ни слова про сборку и креплени...</td>\n",
       "      <td>60</td>\n",
       "      <td>При первой поездки в лес, барабан отломился ко...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>MOTORin / расширители арок</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>positive</td>\n",
       "      <td>Расширители хорошие вот только пришлось для фо...</td>\n",
       "      <td>47</td>\n",
       "      <td>На вид огонь 🔥ещё не ставил</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>Vixem / Лебедка автомобильная 12 v 4000 1814 к...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>Один метр троса зажали, смазки не много и та г...</td>\n",
       "      <td>41</td>\n",
       "      <td>Один метр троса зажали, смазки не много и та г...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>Фрегат Лифт Подвеска / Лифт комплект рессоры К...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>positive</td>\n",
       "      <td>На вид не плохие, но к сожалению на уаз профи ...</td>\n",
       "      <td>41</td>\n",
       "      <td>Встали как родные устанавливал на петро пикапа</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>MOTORin / расширители арок</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>positive</td>\n",
       "      <td>Монтажный комплект не полный, должна быть ещё ...</td>\n",
       "      <td>22</td>\n",
       "      <td>Монтажный комплект не полный, должна быть ещё ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>Autobrand_AED / Дополнительная led фара 30w с ...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>negative</td>\n",
       "      <td>Светят хорошо | Пользоваться невозможно | Но ч...</td>\n",
       "      <td>19</td>\n",
       "      <td>Но через месяц сгорел один диод, второй ещё че...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>MOTORin / Расширители арок 60 Эк</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>Отличная резинка на откатные ворота!!! | Должн...</td>\n",
       "      <td>12</td>\n",
       "      <td>Должно хватить длины, пока не установлено!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>Shtapler / Лебедка электрическая 12v 3000lb 13...</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Просто крутая лебёдка! | Лебёдка хорошая.</td>\n",
       "      <td>6</td>\n",
       "      <td>Просто крутая лебёдка!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>MOTORin / расширители арок</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>positive</td>\n",
       "      <td>Здравствуйте! | Зачем вы обманываете?</td>\n",
       "      <td>5</td>\n",
       "      <td>Зачем вы обманываете?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               category                                            product  \\\n",
       "8   /Автотовары/OFFroad  Shtapler / Лебедка электрическая 12v 3500lb 15...   \n",
       "9   /Автотовары/OFFroad  Shtapler / Лебедка электрическая 12v 4500lb 20...   \n",
       "2   /Автотовары/OFFroad          MOTORin / Расширитель колёсных арок 40 мм   \n",
       "6   /Автотовары/OFFroad  Shtapler / Лебедка электрическая 12v 3000lb 13...   \n",
       "3   /Автотовары/OFFroad                         MOTORin / расширители арок   \n",
       "10  /Автотовары/OFFroad  Vixem / Лебедка автомобильная 12 v 4000 1814 к...   \n",
       "11  /Автотовары/OFFroad  Фрегат Лифт Подвеска / Лифт комплект рессоры К...   \n",
       "4   /Автотовары/OFFroad                         MOTORin / расширители арок   \n",
       "0   /Автотовары/OFFroad  Autobrand_AED / Дополнительная led фара 30w с ...   \n",
       "1   /Автотовары/OFFroad                   MOTORin / Расширители арок 60 Эк   \n",
       "7   /Автотовары/OFFroad  Shtapler / Лебедка электрическая 12v 3000lb 13...   \n",
       "5   /Автотовары/OFFroad                         MOTORin / расширители арок   \n",
       "\n",
       "    avg_rating rating_category  \\\n",
       "8     0.843750        positive   \n",
       "9     0.843750        positive   \n",
       "2     0.937500        positive   \n",
       "6     0.647059         neutral   \n",
       "3     0.722222        positive   \n",
       "10    1.000000        positive   \n",
       "11    0.750000        positive   \n",
       "4     0.722222        positive   \n",
       "0     0.333333        negative   \n",
       "1     1.000000        positive   \n",
       "7     0.647059         neutral   \n",
       "5     0.722222        positive   \n",
       "\n",
       "                                    cluster_sentences  word_count  \\\n",
       "8   Хорошая лебедка, со своей задачей справляется ...         138   \n",
       "9   Хорошая лебедка, со своей задачей справляется ...         138   \n",
       "2   Пришло с опозданием на два дня позже на ниву в...          83   \n",
       "6   Но в инструкции ни слова про сборку и креплени...          60   \n",
       "3   Расширители хорошие вот только пришлось для фо...          47   \n",
       "10  Один метр троса зажали, смазки не много и та г...          41   \n",
       "11  На вид не плохие, но к сожалению на уаз профи ...          41   \n",
       "4   Монтажный комплект не полный, должна быть ещё ...          22   \n",
       "0   Светят хорошо | Пользоваться невозможно | Но ч...          19   \n",
       "1   Отличная резинка на откатные ворота!!! | Должн...          12   \n",
       "7           Просто крутая лебёдка! | Лебёдка хорошая.           6   \n",
       "5               Здравствуйте! | Зачем вы обманываете?           5   \n",
       "\n",
       "                                          key_thought  \n",
       "8   Нормальный лебёдка, но шумел, разобрался полож...  \n",
       "9   Нормальный лебёдка, но шумел, разобрался полож...  \n",
       "2   Сами расширители арок нормальные, но ставить н...  \n",
       "6   При первой поездки в лес, барабан отломился ко...  \n",
       "3                         На вид огонь 🔥ещё не ставил  \n",
       "10  Один метр троса зажали, смазки не много и та г...  \n",
       "11     Встали как родные устанавливал на петро пикапа  \n",
       "4   Монтажный комплект не полный, должна быть ещё ...  \n",
       "0   Но через месяц сгорел один диод, второй ещё че...  \n",
       "1          Должно хватить длины, пока не установлено!  \n",
       "7                              Просто крутая лебёдка!  \n",
       "5                               Зачем вы обманываете?  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.sort_values(\"word_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_category</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>word_count</th>\n",
       "      <th>key_thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВПМ / Антибукс - антипробуксовочные траки утол...</td>\n",
       "      <td>0.819588</td>\n",
       "      <td>positive</td>\n",
       "      <td>Не вставать сзади, когда машина начинает движе...</td>\n",
       "      <td>1738</td>\n",
       "      <td>2 раза спасали на гололедице, шлифовал на мест...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>positive</td>\n",
       "      <td>Иногда их выбрасывало из-под колес. | Хватало ...</td>\n",
       "      <td>442</td>\n",
       "      <td>Не выручать даже летом, чуток сел в небольшую ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Автотовары/OFFroad</td>\n",
       "      <td>ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>positive</td>\n",
       "      <td>В деле не пробовал | Траки мощные, в деле ещё ...</td>\n",
       "      <td>37</td>\n",
       "      <td>В деле пока не пробовала.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>Пахнет и Точка / Ароматизатор в машину автопар...</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>positive</td>\n",
       "      <td>Ужасная вонючка. | Я обычно не пишу плохие отз...</td>\n",
       "      <td>1120</td>\n",
       "      <td>Во-первых пришел совсем другой аромат, во втор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/Автотовары/Автокосметика и автохимия</td>\n",
       "      <td>ПолиКомПласт / Преобразователь очиститель ржав...</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>positive</td>\n",
       "      <td>Ржавчина леш добавилась. | минус 5 звёзд | Луч...</td>\n",
       "      <td>1370</td>\n",
       "      <td>На унитазе ржавчину убрало на раз два, чем до ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                category  \\\n",
       "0                    /Автотовары/OFFroad   \n",
       "2                    /Автотовары/OFFroad   \n",
       "3                    /Автотовары/OFFroad   \n",
       "4  /Автотовары/Автокосметика и автохимия   \n",
       "6  /Автотовары/Автокосметика и автохимия   \n",
       "\n",
       "                                             product  avg_rating  \\\n",
       "0  ВПМ / Антибукс - антипробуксовочные траки утол...    0.819588   \n",
       "2  ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...    0.842975   \n",
       "3  ВЫРУЧАЙКА / Антибукс Противобуксовочные траки ...    0.842975   \n",
       "4  Пахнет и Точка / Ароматизатор в машину автопар...    0.704545   \n",
       "6  ПолиКомПласт / Преобразователь очиститель ржав...    0.853933   \n",
       "\n",
       "  rating_category                                  cluster_sentences  \\\n",
       "0        positive  Не вставать сзади, когда машина начинает движе...   \n",
       "2        positive  Иногда их выбрасывало из-под колес. | Хватало ...   \n",
       "3        positive  В деле не пробовал | Траки мощные, в деле ещё ...   \n",
       "4        positive  Ужасная вонючка. | Я обычно не пишу плохие отз...   \n",
       "6        positive  Ржавчина леш добавилась. | минус 5 звёзд | Луч...   \n",
       "\n",
       "   word_count                                        key_thought  \n",
       "0        1738  2 раза спасали на гололедице, шлифовал на мест...  \n",
       "2         442  Не выручать даже летом, чуток сел в небольшую ...  \n",
       "3          37                          В деле пока не пробовала.  \n",
       "4        1120  Во-первых пришел совсем другой аромат, во втор...  \n",
       "6        1370  На унитазе ржавчину убрало на раз два, чем до ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Удаление записей с word_count <= 10 и ключевой мыслью менее 3 символов\n",
    "final_result = final_result[((final_result['word_count'] > 10) & (final_result['key_thought'].str.len() > 5))]\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.to_csv(\"./reviews_keywords/feedbackfueltest.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
