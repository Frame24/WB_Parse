{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–§–∞–π–ª '/workspace/wildberries_reviews.csv' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gdown\n",
    "\n",
    "def download_file_if_not_exists(file_url, output_path):\n",
    "    \"\"\"–°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª —Å Google Drive, –µ—Å–ª–∏ –æ–Ω –µ—â—ë –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.\"\"\"\n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–∞\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"–§–∞–π–ª '{output_path}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.\")\n",
    "    else:\n",
    "        print(f\"–§–∞–π–ª '{output_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É...\")\n",
    "        gdown.download(file_url, output_path, quiet=False)\n",
    "        print(f\"–§–∞–π–ª '{output_path}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.\")\n",
    "\n",
    "# –£–∫–∞–∑—ã–≤–∞–µ–º URL –∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É\n",
    "# file_url = 'https://drive.google.com/uc?id=15pofNbomaoUap41Rcn1uNGeiJIqFd2qe'\n",
    "file_url = 'https://drive.google.com/uc?id=1alondqI-2IHo__mYU7KQz4Ip8ytYGHXg'\n",
    "output_file_name = 'wildberries_reviews.csv'  # –£–∫–∞–∂–∏—Ç–µ —Ä–µ–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞, –∫–æ—Ç–æ—Ä–æ–µ —Ö–æ—Ç–∏—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å\n",
    "output_path = os.path.join(os.getcwd(), output_file_name)  # –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É\n",
    "\n",
    "download_file_if_not_exists(file_url, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf.pandas  # –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ cuDF –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏—è –µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "cudf.pandas.install()  # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ cuDF –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –¥–ª—è pandas\n",
    "import pandas as pd  # –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ pandas –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ cuDF\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099c3a6abb8f456b82b79e7697fd6441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4575fb70f543bc84d32aabbb2c839e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3548 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ –æ—Ç –°–±–µ—Ä–±–∞–Ω–∫–∞\n",
    "tokenizer = AutoTokenizer.from_pretrained('sberbank-ai/sbert_large_nlu_ru')\n",
    "model = AutoModel.from_pretrained('sberbank-ai/sbert_large_nlu_ru').to(device)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ SpaCy\n",
    "nlp = spacy.load(\"ru_core_news_lg\")\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ pandas DataFrame\n",
    "df_raw = pd.read_csv(\"wildberries_reviews.csv\", nrows=30000)\n",
    "df = df_raw[-3000:-1]  # –û—Ç–±–æ—Ä 500 –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ pandas DataFrame –≤ Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # –°–Ω–∞—á–∞–ª–∞ –∑–∞–º–µ–Ω—è–µ–º –≤—Å–µ \\n, \\r, \\t –Ω–∞ –ø—Ä–æ–±–µ–ª\n",
    "    text = re.sub(r'[\\n\\r\\t]+', ' ', text)\n",
    "    \n",
    "    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "\n",
    "    # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª –∏ —Ç–æ—á–∫—É (–µ—Å–ª–∏ —Ç–æ—á–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)\n",
    "    text = re.sub(r'(?<!\\.)\\s*\\.\\s*', '. ', text)  # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –ø–æ—Å–ª–µ –∑–∞–º–µ–Ω—ã –µ—Å—Ç—å —Ç–æ—á–∫–∞ –∏ –ø—Ä–æ–±–µ–ª\n",
    "    text = re.sub(r'\\s*\\.\\s*(?!\\.)', ' ', text)  # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–µ—Ä–µ–¥ —Ç–æ—á–∫–æ–π, –µ—Å–ª–∏ —Ç–æ—á–∫–∞ –µ—Å—Ç—å\n",
    "    \n",
    "    # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è —Ç–æ—á–∫–æ–π, —É–±–∏—Ä–∞–µ–º –µ—ë\n",
    "    text = re.sub(r'\\s*\\.$', '', text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n",
    "def split_into_sentences(text):\n",
    "    doc = nlp(clean_text(text))\n",
    "    return [sent.text for sent in doc.sents]\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n",
    "def split_reviews_into_sentences(batch):\n",
    "    batch['sentences'] = [split_into_sentences(text) for text in batch['corrected_text']]\n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(split_reviews_into_sentences, batched=True, batch_size=8)\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º Dataset –æ–±—Ä–∞—Ç–Ω–æ –≤ pandas DataFrame\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "# –í—ã–ø–æ–ª–Ω–∏–º explode –ø–æ —Å—Ç–æ–ª–±—Ü—É —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏\n",
    "df_exploded = df.explode('sentences').reset_index(drop=True)\n",
    "\n",
    "# –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ —Å—Ç–æ–ª–±—Ü—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ—è–≤–∏–ª–∏—Å—å –ø–æ—Å–ª–µ explode\n",
    "df_exploded = df_exploded.drop(columns=[col for col in df_exploded.columns if col.startswith('__index_level_')])\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º DataFrame –æ–±—Ä–∞—Ç–Ω–æ –≤ Hugging Face Dataset\n",
    "dataset_exploded = Dataset.from_pandas(df_exploded)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n",
    "def compute_sentence_embeddings(sentences):\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ explode\n",
    "def compute_embeddings_after_explode(batch):\n",
    "    sentences = batch['sentences']\n",
    "    embeddings = compute_sentence_embeddings(sentences)\n",
    "    batch['sentence_embeddings'] = embeddings\n",
    "    return batch\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "dataset = dataset_exploded.map(compute_embeddings_after_explode, batched=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Organizing clusters for *Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç: 129it [00:00, 833690.63it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.41s/it]\n",
      "Organizing clusters for AutoVirazh / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –¥–≤—É—Ö–ø–æ—Ä—à–Ω–µ–≤–æ–π 85–ª –º–∏–Ω: 4it [00:00, 55007.27it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Recursive clustering: 0it [00:00, ?it/s]\n",
      "Organizing clusters for Clements / –í–∫–ª–∞–¥—ã—à –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π 100–º–∫–º –æ–±–ª–æ–∂–∫–∞: 220it [00:00, 851242.51it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.03it/s]\n",
      "Organizing clusters for Eternal way / –ë–µ—Å–ø—Ä–æ–≤–æ–¥–Ω–æ–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä–Ω—ã–π –Ω–∞—Å–æ—Å - –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä: 42it [00:00, 532207.76it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.65it/s]\n",
      "Organizing clusters for FST Auto / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ö–ª–∞—Å—Å–∏–∫–∞ 2 —à—Ç: 201it [00:00, 733729.42it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:03<00:00,  3.21it/s]\n",
      "Organizing clusters for FST Auto / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –°–ø–æ—Ä—Ç–∏–≤–Ω—ã–π —Å—Ç–∏–ª—å 2 —à—Ç: 231it [00:00, 1002985.74it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:03<00:00,  4.42it/s]\n",
      "Organizing clusters for Grand House / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –∞–Ω—Ç–∏–±–ª–∏–∫: 239it [00:00, 810378.86it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.50it/s]\n",
      "Organizing clusters for Lieblich Hause (Haz) / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –≤–æ–∑–¥—É—à–Ω—ã–π –±–µ—Å–ø—Ä–æ–≤–æ–¥–Ω–æ–π: 180it [00:00, 1403298.74it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  5.62it/s]\n",
      "Organizing clusters for Lieblich Hause / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏—Ñ–∞—Ä—ã: 232it [00:00, 875070.62it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:01<00:00,  3.65it/s]\n",
      "Organizing clusters for LiteRock / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –±–µ—Å–ø—Ä–æ–≤–æ–¥–Ω–æ–π: 28it [00:00, 278956.09it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Recursive clustering: 0it [00:00, ?it/s]\n",
      "Organizing clusters for MAZURA / –ê–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è —Ö–∞–º–µ–ª–µ–æ–Ω: 219it [00:00, 829018.57it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.22it/s]\n",
      "Organizing clusters for OD&STYLE / –û–±–ª–æ–∂–∫–∞ –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤–∫–ª–∞–¥—ã—à: 173it [00:00, 1172236.82it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 10.50it/s]\n",
      "Organizing clusters for RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏—Ñ–∞—Ä—ã: 281it [00:00, 1026654.55it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.33it/s]\n",
      "Organizing clusters for Romarina / –ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω—ã–π: 184it [00:00, 1162277.01it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:05<00:00,  1.19s/it]\n",
      "Organizing clusters for SHADOVtech / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –≤–æ–∑–¥—É—à–Ω—ã–π —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∏–π,–Ω–∞—Å–æ—Å –º–∞—à–∏–Ω: 254it [00:00, 739315.21it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.40s/it]\n",
      "Organizing clusters for StarLine / –ß–µ—Ö–æ–ª —Å–∏–ª–∏–∫–æ–Ω–æ–≤—ã–π –¥–ª—è –±—Ä–µ–ª–æ–∫–∞ –°—Ç–∞—Ä–ª–∞–π–Ω –ê63 –ê93 –ê66 –ê96: 150it [00:00, 1090373.66it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.79it/s]\n",
      "Organizing clusters for Stylish_Shock / –ö–æ–∂–∞–Ω–∞—è –æ–±–ª–æ–∂–∫–∞ –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –≤–∏–∑–∏—Ç–Ω–∏—Ü–µ–π: 210it [00:00, 808076.92it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  6.78it/s]\n",
      "Organizing clusters for SuperVision / –û—á–∫–∏ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, —Ä—ã–±–∞–ª–∫–∏, –∞–Ω—Ç–∏—Ñ–∞—Ä—ã: 202it [00:00, 685476.87it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.81it/s]\n",
      "Organizing clusters for –ú–∏—Å—Å–∏—Å –ê / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫ –∞–Ω—Ç–∏—Ñ–∞—Ä—ã: 56it [00:00, 599186.29it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.82it/s]\n",
      "Organizing clusters for –ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä—Ñ—é–º –ø–æ–¥–≤–µ—Å–Ω–æ–π: 30it [00:00, 332881.27it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12671.61it/s]\n",
      "Organizing clusters for –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –°–æ–ª–Ω—Ü–µ–∑–∞—â–∏—Ç–Ω—ã–µ –≤–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ: 38it [00:00, 547709.80it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12372.58it/s]\n",
      "Organizing clusters for –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥–æ –≤–∏–¥–µ–Ω–∏—è –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª–µ–π: 245it [00:00, 804702.02it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>key_thought</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç</td>\n",
       "      <td>–°–≤–æ–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç, –æ—Å–æ–±–µ–Ω–Ω–æ –∂—ë–ª—Ç—ã–µ –ª–∏–Ω–∑—ã ...</td>\n",
       "      <td>–•–ª–∏–ø–∫–∏–µ –ø–æ—Å–ª–µ –ø—Ä–æ—Ç–∏—Ä–∫–µ –æ–¥–Ω–æ —Å—Ç–µ–∫–ª–æ –≤—ã–≤–æ–ª–µ–ª–æ—Å—å,...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç</td>\n",
       "      <td>–í—Å—ë –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ, —Å–ø–∞—Å–∏–±–æ | –ù–æ—Ä–º–∞–ª—å–Ω–æ | –û—Ç–ª–∏—á–Ω...</td>\n",
       "      <td>–í—Å—ë –æ—Ç–ª–∏—á–Ω–æ</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç</td>\n",
       "      <td>–î–µ—Ç—Å–∫–∏–µ | –ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ | –ù—É –æ—á–µ–Ω—å ...</td>\n",
       "      <td>–ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clements / –í–∫–ª–∞–¥—ã—à –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∑—Ä–∞—á–Ω...</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω—ã–π –≤–∫–ª–∞–¥—ã—à, –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ–º–µ—Å—Ç–∏–ª–∏...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π –≤–∫–ª–∞–¥—ã—à, –ø–ª–æ—Ç–Ω—ã–π, –ø–æ —Ä–∞–∑–º–µ—Ä—É –ø–æ–¥–æ—à—ë–ª</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clements / –í–∫–ª–∞–¥—ã—à –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∑—Ä–∞—á–Ω...</td>\n",
       "      <td>–†–µ–∫–æ–º–µ–Ω–¥—É—é! | –ö–∞—á–µ—Å—Ç–≤–æ —Ö–æ—Ä–æ—à–µ–µ! | –ö–∞—á–µ—Å—Ç–≤–æ —Ö–æ—Ä...</td>\n",
       "      <td>–ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–ª–∏—á–Ω–æ–µ</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>–°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...</td>\n",
       "      <td>–ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å –†–µ–∫–æ–º–µ–Ω–¥—É—é | –ú—É–∂—É –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å ...</td>\n",
       "      <td>–ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å –†–µ–∫–æ–º–µ–Ω–¥—É—é</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>–°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...</td>\n",
       "      <td>–û–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ!!! | –°–ø–∞—Å–∏–±–æ!) | –°–ø–∞—Å–∏–±–æ! | –°...</td>\n",
       "      <td>–°–ø–∞—Å–∏–±–æ!üëç</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>–°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...</td>\n",
       "      <td>–°—É–ø–µ—Ä  . | –°—É–ø–µ—Ä! | –û—Ç–ª–∏—á–Ω–æ! | –û—Ç–ª–∏—á–Ω–æ</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ!</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>–°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...</td>\n",
       "      <td>–û–¢–õ–ò–ß–ù–´–ï | —à–∏–∫–∞—Ä–Ω—ã–µ | –û—á–µ–Ω—å —Ö–æ—Ä–æ—à–∏–π</td>\n",
       "      <td>–û–¢–õ–ò–ß–ù–´–ï</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>–°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...</td>\n",
       "      <td>ü§ò | üëçüëç | üëçüëçüëç</td>\n",
       "      <td>üëçüëçüëç</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               product  \\\n",
       "0    *Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç   \n",
       "1    *Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç   \n",
       "2    *Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç   \n",
       "3    Clements / –í–∫–ª–∞–¥—ã—à –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∑—Ä–∞—á–Ω...   \n",
       "4    Clements / –í–∫–ª–∞–¥—ã—à –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∑—Ä–∞—á–Ω...   \n",
       "..                                                 ...   \n",
       "163  –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...   \n",
       "164  –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...   \n",
       "165  –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...   \n",
       "166  –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...   \n",
       "167  –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...   \n",
       "\n",
       "                                     cluster_sentences  \\\n",
       "0    –°–≤–æ–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç, –æ—Å–æ–±–µ–Ω–Ω–æ –∂—ë–ª—Ç—ã–µ –ª–∏–Ω–∑—ã ...   \n",
       "1    –í—Å—ë –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ, —Å–ø–∞—Å–∏–±–æ | –ù–æ—Ä–º–∞–ª—å–Ω–æ | –û—Ç–ª–∏—á–Ω...   \n",
       "2    –î–µ—Ç—Å–∫–∏–µ | –ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ | –ù—É –æ—á–µ–Ω—å ...   \n",
       "3    –û—á–µ–Ω—å —É–¥–æ–±–Ω—ã–π –≤–∫–ª–∞–¥—ã—à, –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ–º–µ—Å—Ç–∏–ª–∏...   \n",
       "4    –†–µ–∫–æ–º–µ–Ω–¥—É—é! | –ö–∞—á–µ—Å—Ç–≤–æ —Ö–æ—Ä–æ—à–µ–µ! | –ö–∞—á–µ—Å—Ç–≤–æ —Ö–æ—Ä...   \n",
       "..                                                 ...   \n",
       "163  –ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å –†–µ–∫–æ–º–µ–Ω–¥—É—é | –ú—É–∂—É –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å ...   \n",
       "164  –û–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ!!! | –°–ø–∞—Å–∏–±–æ!) | –°–ø–∞—Å–∏–±–æ! | –°...   \n",
       "165             –°—É–ø–µ—Ä  . | –°—É–ø–µ—Ä! | –û—Ç–ª–∏—á–Ω–æ! | –û—Ç–ª–∏—á–Ω–æ   \n",
       "166                –û–¢–õ–ò–ß–ù–´–ï | —à–∏–∫–∞—Ä–Ω—ã–µ | –û—á–µ–Ω—å —Ö–æ—Ä–æ—à–∏–π   \n",
       "167                                       ü§ò | üëçüëç | üëçüëçüëç   \n",
       "\n",
       "                                           key_thought  word_count  \n",
       "0    –•–ª–∏–ø–∫–∏–µ –ø–æ—Å–ª–µ –ø—Ä–æ—Ç–∏—Ä–∫–µ –æ–¥–Ω–æ —Å—Ç–µ–∫–ª–æ –≤—ã–≤–æ–ª–µ–ª–æ—Å—å,...          53  \n",
       "1                                          –í—Å—ë –æ—Ç–ª–∏—á–Ω–æ          10  \n",
       "2                             –ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ           9  \n",
       "3        –û—Ç–ª–∏—á–Ω—ã–π –≤–∫–ª–∞–¥—ã—à, –ø–ª–æ—Ç–Ω—ã–π, –ø–æ —Ä–∞–∑–º–µ—Ä—É –ø–æ–¥–æ—à—ë–ª         152  \n",
       "4                                    –ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–ª–∏—á–Ω–æ–µ          77  \n",
       "..                                                 ...         ...  \n",
       "163                         –ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å –†–µ–∫–æ–º–µ–Ω–¥—É—é          10  \n",
       "164                                          –°–ø–∞—Å–∏–±–æ!üëç           8  \n",
       "165                                           –û—Ç–ª–∏—á–Ω–æ!           8  \n",
       "166                                           –û–¢–õ–ò–ß–ù–´–ï           6  \n",
       "167                                                üëçüëçüëç           5  \n",
       "\n",
       "[168 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (GPU –∏–ª–∏ CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ü–µ–Ω—Ç—Ä–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞ (—Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞)\n",
    "def find_centroid(embeddings):\n",
    "    return np.mean(embeddings, axis=0)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –∫–ª—é—á–µ–≤–æ–π –º—ã—Å–ª–∏ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ\n",
    "def extract_key_thought(cluster_sentences):\n",
    "    sentences = cluster_sentences.split(\" | \")\n",
    "    embeddings = compute_sentence_embeddings(sentences)\n",
    "    \n",
    "    centroid = find_centroid(embeddings)\n",
    "    similarities = cosine_similarity(embeddings, [centroid])\n",
    "    key_sentence_index = np.argmax(similarities)\n",
    "    \n",
    "    return sentences[key_sentence_index]\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Ç–µ—Ä–µ\n",
    "def count_words(cluster_sentences):\n",
    "    words = cluster_sentences.split()\n",
    "    return len(words)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "def compute_sentence_embeddings(sentences):\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "    return embeddings\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∫—Ä—É–ø–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "def recluster_large_cluster(cluster_sentences, eps=0.1, min_samples=2):\n",
    "    sentences = cluster_sentences.split(\" | \")\n",
    "    \n",
    "    embeddings = compute_sentence_embeddings(sentences)\n",
    "    \n",
    "    re_clustering = DBSCAN(eps=eps, min_samples=min_samples, metric=\"cosine\").fit(embeddings)\n",
    "    \n",
    "    re_cluster_dict = {}\n",
    "    for idx, label in enumerate(re_clustering.labels_):\n",
    "        if label == -1:\n",
    "            continue\n",
    "        label_str = str(label)\n",
    "        if label_str not in re_cluster_dict:\n",
    "            re_cluster_dict[label_str] = []\n",
    "        re_cluster_dict[label_str].append(sentences[idx])\n",
    "    \n",
    "    return [\" | \".join(cluster) for cluster in re_cluster_dict.values()]\n",
    "\n",
    "# –†–µ–∫—É—Ä—Å–∏–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∫—Ä—É–ø–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "def recursive_clustering(cluster_sentences, threshold, eps=0.25, min_samples=3, min_eps=0.05):\n",
    "    current_eps = eps\n",
    "    new_clusters = [cluster_sentences]\n",
    "\n",
    "    while True:\n",
    "        next_clusters = []\n",
    "        reclustered_any = False\n",
    "        \n",
    "        for cluster in new_clusters:\n",
    "            if count_words(cluster) > threshold:\n",
    "                while current_eps >= min_eps:\n",
    "                    reclustered = recluster_large_cluster(cluster, eps=current_eps, min_samples=min_samples)\n",
    "                    if len(reclustered) > 1:\n",
    "                        next_clusters.extend(reclustered)\n",
    "                        reclustered_any = True\n",
    "                        break  # –ö–ª–∞—Å—Ç–µ—Ä —É—Å–ø–µ—à–Ω–æ —Ä–∞–∑–¥–µ–ª–µ–Ω, –≤—ã—Ö–æ–¥–∏–º –∏–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ —Ü–∏–∫–ª–∞\n",
    "                    else:\n",
    "                        current_eps *= 0.9  # –£–º–µ–Ω—å—à–∞–µ–º eps –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞\n",
    "                \n",
    "                if len(reclustered) == 1:\n",
    "                    # –ï—Å–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä —Ç–∞–∫ –∏ –Ω–µ –±—ã–ª —Ä–∞–∑–¥–µ–ª–µ–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –æ–±—Ä–∞—Ç–Ω–æ\n",
    "                    next_clusters.append(cluster)\n",
    "            else:\n",
    "                next_clusters.append(cluster)\n",
    "        \n",
    "        new_clusters = next_clusters\n",
    "        \n",
    "        if not reclustered_any:\n",
    "            break\n",
    "    \n",
    "    return new_clusters\n",
    "\n",
    "# –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –ø–æ —Ç–æ–≤–∞—Ä–∞–º\n",
    "final_result = pd.DataFrame()\n",
    "\n",
    "for product_name, group in df_exploded.groupby('product'):\n",
    "    all_sentences = group['sentences'].tolist()\n",
    "\n",
    "    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –±–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ –±–∞—Ç—á–∏\n",
    "    all_embeddings = compute_sentence_embeddings(all_sentences)\n",
    "\n",
    "    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏\n",
    "    clustering = DBSCAN(eps=0.25, min_samples=3, metric=\"cosine\").fit(all_embeddings)\n",
    "\n",
    "    cluster_dict = {}\n",
    "    for idx, label in tqdm(enumerate(clustering.labels_), desc=f\"Organizing clusters for {product_name}\"):\n",
    "        if label == -1:\n",
    "            continue\n",
    "        label_str = str(label)\n",
    "        if label_str not in cluster_dict:\n",
    "            cluster_dict[label_str] = set()\n",
    "        cluster_dict[label_str].add(all_sentences[idx])\n",
    "\n",
    "    clusters = [\" | \".join(sentences) for sentences in cluster_dict.values()]\n",
    "    threshold = np.mean([count_words(cluster) for cluster in clusters]) * 1.5\n",
    "\n",
    "    final_clusters = []\n",
    "    for cluster in tqdm(clusters, desc=\"Recursive clustering\"):\n",
    "        final_clusters.extend(recursive_clustering(cluster, threshold))\n",
    "\n",
    "    df_exploded_sorted = pd.DataFrame({'product': product_name, 'cluster_sentences': final_clusters})\n",
    "    df_exploded_sorted['word_count'] = df_exploded_sorted['cluster_sentences'].apply(count_words)\n",
    "    df_exploded_sorted['key_thought'] = df_exploded_sorted['cluster_sentences'].apply(extract_key_thought)\n",
    "\n",
    "    df_exploded_sorted = df_exploded_sorted.sort_values(by='word_count', ascending=False)\n",
    "\n",
    "    final_result = pd.concat([final_result, df_exploded_sorted], ignore_index=True)\n",
    "\n",
    "# –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "display(final_result[['product', 'cluster_sentences', 'key_thought', 'word_count']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –í—Å—ë –æ—Ç–ª–∏—á–Ω–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–ª–∏—á–Ω–æ–µ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–π, –ø—Ä–æ—á–Ω—ã–π\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –í—Å–µ –æ—Ç–ª–∏—á–Ω–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä!\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –í—Å–µ –æ—Ç–ª–∏—á–Ω–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –í—Å—ë –æ—Ç–ª–∏—á–Ω–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9553651809692383. –ò—Å–∫–ª—é—á–∞–µ–º –ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9553651809692383. –ò—Å–∫–ª—é—á–∞–µ–º –ú—É–∂—É –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å —Å–ø–∞—Å–∏–±–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9777071475982666. –ò—Å–∫–ª—é—á–∞–µ–º –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –°–ø–∞—Å–∏–±–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –í—Å—ë –æ—Ç–ª–∏—á–Ω–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9922985434532166. –ò—Å–∫–ª—é—á–∞–µ–º –ö–ª–∞—Å—Å–Ω—ã–π –∞–ø–ø–∞—Ä–∞—Ç, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9553651809692383. –ò—Å–∫–ª—é—á–∞–µ–º –ú—É–∂—É –æ—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–π –≤–∫–ª–∞–¥—ã—à\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –í—Å–µ –æ—Ç–ª–∏—á–Ω–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9777071475982666. –ò—Å–∫–ª—é—á–∞–µ–º –£–¥–æ–±–Ω–∞—è, —Ö–æ—Ä–æ—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9777071475982666. –ò—Å–∫–ª—é—á–∞–µ–º –•–æ—Ä–æ—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9553651809692383. –ò—Å–∫–ª—é—á–∞–µ–º –ü–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å, —Å–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–µ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9777071475982666. –ò—Å–∫–ª—é—á–∞–µ–º –•–æ—Ä–æ—à–∏–π —Ç–æ–≤–∞—Ä\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä!\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9922985434532166. –ò—Å–∫–ª—é—á–∞–µ–º –ö–ª–∞—Å—Å–Ω–∞—è –≤–µ—â—å!\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9553651809692383. –ò—Å–∫–ª—é—á–∞–µ–º –ú—É–∂—É –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–π —á–µ—Ö–æ–ª\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –í—Å–µ –æ—Ç–ª–∏—á–Ω–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, —Å–æ–≤–µ—Ç—É—é\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 1.0000001192092896. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ñ–∏–≥–µ–Ω–Ω—ã–π —Å–ø–∞—Å–∏–±–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9142447710037231. –ò—Å–∫–ª—é—á–∞–µ–º –ö—Ä–∞—Å–∏–≤—ã–π, –∫–æ–∂–∞–Ω—ã–π, –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å–Ω—ã–π\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9553651809692383. –ò—Å–∫–ª—é—á–∞–µ–º –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è, –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω–∞—è –≤–µ—â—å\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9922985434532166. –ò—Å–∫–ª—é—á–∞–µ–º –û—á–∫–∏ –∫–ª–∞—Å—Å–Ω—ã–µ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9553651809692383. –ò—Å–∫–ª—é—á–∞–µ–º –°—É–ø–µ—Ä, –æ—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9777071475982666. –ò—Å–∫–ª—é—á–∞–µ–º –û—á–µ–Ω—å —Ö–æ—Ä–æ—à–∏–µ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –°–ø–∞—Å–∏–±–æ, –æ—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –í—Å–µ –æ—Ç–ª–∏—á–Ω–æ !\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9553651809692383. –ò—Å–∫–ª—é—á–∞–µ–º –ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å –†–µ–∫–æ–º–µ–Ω–¥—É—é\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>key_thought</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç</td>\n",
       "      <td>–°–≤–æ–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç, –æ—Å–æ–±–µ–Ω–Ω–æ –∂—ë–ª—Ç—ã–µ –ª–∏–Ω–∑—ã ...</td>\n",
       "      <td>–•–ª–∏–ø–∫–∏–µ –ø–æ—Å–ª–µ –ø—Ä–æ—Ç–∏—Ä–∫–µ –æ–¥–Ω–æ —Å—Ç–µ–∫–ª–æ –≤—ã–≤–æ–ª–µ–ª–æ—Å—å,...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç</td>\n",
       "      <td>–î–µ—Ç—Å–∫–∏–µ | –ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ | –ù—É –æ—á–µ–Ω—å ...</td>\n",
       "      <td>–ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Clements / –í–∫–ª–∞–¥—ã—à –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∑—Ä–∞—á–Ω...</td>\n",
       "      <td>–í–º–µ—Å—Ç–∏–ª–∏—Å—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã: –¢–°, —Å—Ç—Ä–∞—Ö–æ–≤—ã–µ, –ø–∞—Å–ø–æ...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π –≤–∫–ª–∞–¥—ã—à, –ø–ª–æ—Ç–Ω—ã–π, –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤–æ—à–ª–∏...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Eternal way / –ë–µ—Å–ø—Ä–æ–≤–æ–¥–Ω–æ–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∞–∫–∫—É–º...</td>\n",
       "      <td>–ó–∞–∫–∞–∑–∞–ª–∞ —Å–µ–±–µ –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä, –º–µ–Ω—è –ø–æ–¥–∫—É–ø–∏–ª –Ω–µ–æ–±—ã—á...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ë—Ä–∞–ª–∞ –≤ –ø–æ–¥–∞—Ä–æ–∫ –º—É–∂—É –°—Ä–∞–∑—É ...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FST Auto / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ö–ª–∞—Å—Å–∏–∫–∞ 2 —à—Ç</td>\n",
       "      <td>–ö–∞–∫ –∏–≥—Ä—É—à–µ—á–Ω—ã–µ, –ª—ë–≥–∫–∏–µ, –Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤...</td>\n",
       "      <td>–°–∫–æ–ª—å–∫–æ —Å—Ç–æ—è—Ç, —Ç–∞–∫ –∏ –≤—ã–≥–ª—è–¥—è—Ç: –¥—ë—à–µ–≤–æ –∏ –ø—Ä–æ—Å—Ç–æ</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FST Auto / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –°–ø–æ—Ä—Ç–∏–≤–Ω—ã–π —Å—Ç–∏–ª—å...</td>\n",
       "      <td>–ö–∞–∫ –∏–≥—Ä—É—à–µ—á–Ω—ã–µ, –ª—ë–≥–∫–∏–µ, –Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤...</td>\n",
       "      <td>–°–∫–æ–ª—å–∫–æ —Å—Ç–æ—è—Ç, —Ç–∞–∫ –∏ –≤—ã–≥–ª—è–¥—è—Ç: –¥—ë—à–µ–≤–æ –∏ –ø—Ä–æ—Å—Ç–æ</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Grand House / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –∞–Ω—Ç–∏–±–ª–∏–∫</td>\n",
       "      <td>–ì–æ–¥–Ω—ã–µ –æ—á–∫–∏, –Ω–æ—á—å—é –∫–∞–∫ –¥–Ω—ë–º –µ–¥–µ—à—å, –¥–Ω—ë–º —Å–æ–ª–Ω—Ü–µ...</td>\n",
       "      <td>–ü–æ–ª –¥–Ω—è —Å–µ–≥–æ–¥–Ω—è –µ—Ö–∞–ª –≤ –∂–µ–ª—Ç—ã—Ö –æ—á–∫–∞—Ö, –≥–ª–∞–∑–∞ –Ω–µ ...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Grand House / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –∞–Ω—Ç–∏–±–ª–∏–∫</td>\n",
       "      <td>–û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ, –º—É–∂—É –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é | –û—á...</td>\n",
       "      <td>–û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ, –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Lieblich Hause (Haz) / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –≤–æ–∑–¥—É—à–Ω—ã–π –±–µ...</td>\n",
       "      <td>–ï—Å—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –º–∞–Ω–æ–º–µ—Ç—Ä, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ –Ω–µ –Ω–∞...</td>\n",
       "      <td>–ù–∞–∫–∞—á–∞–ª 2 –∫–æ–ª–µ—Å–∞ –¥–ª—è –≤–µ–ª–∏–∫–∞ –¥–æ 3 –∞—Ç–º–æ—Å—Ñ–µ—Ä - —Å–ø...</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Lieblich Hause (Haz) / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –≤–æ–∑–¥—É—à–Ω—ã–π –±–µ...</td>\n",
       "      <td>–ö—É–ø–∏–ª –∫–∞—á–∞—Ç—å –≤–∞—Ç—Ä—É—à–∫—É –∏ –¥–ª—è –≤–µ–ª–æ—Å–∏–ø–µ–¥–æ–≤ –†–∞–±–æ—Ç–∞...</td>\n",
       "      <td>–ü–æ–∫—É–ø–∞–ª –¥–ª—è –≤–µ–ª–æ—Å–∏–ø–µ–¥–∞, –æ—Ç–ª–∏—á–Ω–∞—è —à—Ç—É–∫–∞ –ü—Ä–æ–±–æ–≤–∞...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Lieblich Hause / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, ...</td>\n",
       "      <td>–û—á–µ–Ω—å –ø–æ–ª–µ–∑–Ω—ã–µ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –¥–µ—à—ë–≤—É...</td>\n",
       "      <td>–£–¥–æ–±–Ω—ã–µ, –æ–±–ª–µ–≥—á–∞—é—Ç –≤–æ–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ —è—Ä–∫–æ–º —Å–≤–µ—Ç–µ –†–µ...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Lieblich Hause / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, ...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –£–¥–æ–±–Ω—ã–µ –†–µ–∫–æ–º–µ–Ω–¥—É—é | –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –£–¥–æ–±–Ω—ã–µ –†–µ–∫–æ–º–µ–Ω–¥—É—é</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Lieblich Hause / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, ...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, —Å–ø–∞—Å–∏–±–æ —Ö–æ—Ä–æ—à–∏–π | –í—Å–µ —Ö–æ—Ä–æ—à–æ –û—á–∫...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, —Å–ø–∞—Å–∏–±–æ —Ö–æ—Ä–æ—à–∏–π</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>MAZURA / –ê–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è —Ö–∞–º–µ–ª–µ–æ–Ω</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, –º–∞—Ç–µ—Ä–∏–∞–ª –æ—Ç–ª–∏—á–Ω—ã–π –∑–∞ —Å–≤–æ—é –∞–∏–Ω–Ω—É ...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, –ª—ë–≥–∫–∏–µ –∏ —É–¥–æ–±–Ω—ã–µ –í —Ö–æ—Ä–æ—à–µ–º —á–µ—Ö–ª–µ...</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>MAZURA / –ê–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è —Ö–∞–º–µ–ª–µ–æ–Ω</td>\n",
       "      <td>–ñ–∞–ª–µ—é, —á—Ç–æ –Ω–µ –∫—É–ø–∏–ª–∞ –∏—Ö —Ä–∞–Ω—å—à–µ –ó–∞–∫–∞–∑–∞–ª–∞ —Ç–æ–ª—å–∫–æ...</td>\n",
       "      <td>–ñ–∞–ª–µ—é, —á—Ç–æ –Ω–µ –∫—É–ø–∏–ª–∞ –∏—Ö —Ä–∞–Ω—å—à–µ –ó–∞–∫–∞–∑–∞–ª–∞ —Ç–æ–ª—å–∫–æ...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>MAZURA / –ê–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è —Ö–∞–º–µ–ª–µ–æ–Ω</td>\n",
       "      <td>–û—á–∫–∏ —Ö–æ—Ä–æ—à–∏ –í–∏–¥–Ω–æ –≤ –Ω–∏—Ö –Ω–∞ —Ç—Ä–∞—Å—Å–µ —Ö–æ—Ä–æ—à–æ | –û—Ç–ª...</td>\n",
       "      <td>–û—á–∫–∏ —Ö–æ—Ä–æ—à–∏ –í–∏–¥–Ω–æ –≤ –Ω–∏—Ö –Ω–∞ —Ç—Ä–∞—Å—Å–µ —Ö–æ—Ä–æ—à–æ</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...</td>\n",
       "      <td>–û—á–∫–∏ –Ω—Ä–∞–≤—è—Ç—Å—è –ó–∞—Ç–µ–º–Ω—è—é—Ç –≤ —Å–æ–ª–Ω–µ—á–Ω—É—é –ø–æ–≥–æ–¥—É –∏ –æ...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–µ —Å—Ç–∏–ª—å–Ω—ã–µ –æ—á–∫–∏ –∏ —Ö–æ—Ä–æ—à–æ –∑–∞—â–∏—â–∞—é—Ç –æ—Ç —Å–æ...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...</td>\n",
       "      <td>–û—á–∫–∏ —Ü–µ–ª—ã–µ, –Ω–æ—Ä–º –¢–æ–ª—å–∫–æ –æ—Å—Ç–∞–≤–ª—è—é—Ç —Å–ª–µ–¥—ã –Ω–∞ –ø–µ—Ä...</td>\n",
       "      <td>–û—á–∫–∏ –Ω–µ –ø–ª–æ—Ö–∏–µ, –Ω–æ —Ö–ª–∏–ø–∫–∏–µ, –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ —Ü–µ–Ω–µ</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –∑–∞ —Å–≤–æ–∏ –¥–µ–Ω—å–≥–∏, —è –±—ã —Å–∫–∞–∑–∞–ª –æ—Ç–ª–∏—á...</td>\n",
       "      <td>–û—á–∫–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∫–ª–∞—Å—Å–Ω—ã–µ, –∑–∞—è–≤–ª–µ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...</td>\n",
       "      <td>–°—É–ø–µ—Ä –æ—á–∫–∏ –∑–∞ —Ç–∞–∫—É—é —Ü–µ–Ω—É, –∑–∞–∫–∞–∑—ã–≤–∞–ª–∞ –º—É–∂—É, –æ—á–µ...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, –∑–∞–∫–∞–∑–∞–ª–∞ –µ—â—ë, –¥–ª—è —Å—ã–Ω–∞</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –ø–æ–ª—å–∑—É—é—Å—å, –Ω–æ –Ω–µ –≤—Å–µ–≥–¥–∞ | –û—á–∫–∏ –Ω–æ...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –ø–æ–ª—å–∑—É—é—Å—å, –Ω–æ –Ω–µ –≤—Å–µ–≥–¥–∞</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...</td>\n",
       "      <td>–ë–æ–ª—å—à–æ–µ —Å–ø–∞—Å–∏–±–æ –û—á–∫–∏ –æ–≥–æ–Ω—å –¥–∞–∂–µ —Å –æ—á–∫–∞–º–∏ –¥–ª—è –∑...</td>\n",
       "      <td>–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—á–∫–∏ –ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Romarina / –ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω—ã–π</td>\n",
       "      <td>–ù–∞ –≤–µ–ª–∏–∫–∞—Ö –∏—Å–ø—Ä–æ–±–æ–≤–∞–ª –ù–∞–∫–∞—á–∏–≤–∞–µ—Ç –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∫...</td>\n",
       "      <td>–ö–æ–º–ø–∞–∫—Ç–Ω—ã–π, –µ—Å—Ç—å —Å—É–º–æ—á–∫–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è, –ª–µ–≥–∫–æ —É...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Romarina / –ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω—ã–π</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π –Ω–∞—Å–æ—Å –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ—Å—Ç–∞–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç—å...</td>\n",
       "      <td>–ù–∞—Å–æ—Å –æ—Ç–ª–∏—á–Ω—ã–π –û—á–µ–Ω—å –¥–æ–≤–æ–ª–µ–Ω, –±—Ä–∞–ª –¥–ª—è –≤–µ–ª–æ—Å–∏–ø...</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Romarina / –ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω—ã–π</td>\n",
       "      <td>–ù–∞–∫–∞—á–∞–ª –¥–≤–∞ —Ä–∞—Å—à–∏—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –±–∞–∫–∞ –ø–æ 8 –ª–∏—Ç—Ä–æ–≤ —Å ...</td>\n",
       "      <td>–ù–∞–∫–∞—á–∞–ª –∫–æ–ª–µ—Å–∞ —Å–∞–º–æ–∫–∞—Ç—É, –ø–æ–¥–∫–∞—á–∞–ª –ø–µ—Ä–µ–¥–Ω–∏–µ –Ω–∞ ...</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SHADOVtech / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –≤–æ–∑–¥—É—à–Ω—ã...</td>\n",
       "      <td>–ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –¥–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ, –¥–∞...</td>\n",
       "      <td>–ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä —Ö–æ—Ä–æ—à–∏–π, —Å –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–ø—É—â–µ–Ω–Ω–æ–≥–æ –∫–æ–ª...</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>StarLine / –ß–µ—Ö–æ–ª —Å–∏–ª–∏–∫–æ–Ω–æ–≤—ã–π –¥–ª—è –±—Ä–µ–ª–æ–∫–∞ –°—Ç–∞—Ä–ª...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π —á–µ—Ö–æ–ª –•–æ—Ä–æ—à–∞—è —Ü–µ–Ω–∞ –ü–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å –∫–∞—á–µ—Å—Ç...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π —á–µ—Ö–æ–ª –•–æ—Ä–æ—à–∞—è —Ü–µ–Ω–∞ –ü–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å –∫–∞—á–µ—Å—Ç...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>StarLine / –ß–µ—Ö–æ–ª —Å–∏–ª–∏–∫–æ–Ω–æ–≤—ã–π –¥–ª—è –±—Ä–µ–ª–æ–∫–∞ –°—Ç–∞—Ä–ª...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ –ø–æ–¥–æ—à—ë–ª üëç | –†–µ–∫–æ–º–µ–Ω–¥—É—é!üëçüèª | –ü–æ–¥–æ—à–µ–ª –æ—Ç...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ –ø–æ–¥–æ—à–µ–ª –†–µ–∫–æ–º–µ–Ω–¥—É—é</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Stylish_Shock / –ö–æ–∂–∞–Ω–∞—è –æ–±–ª–æ–∂–∫–∞ –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ...</td>\n",
       "      <td>–û—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è —Ç–æ–≤–∞—Ä –û–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤...</td>\n",
       "      <td>–°–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤—Ü—É –∑–∞ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω—É—é –¥–æ—Å—Ç–∞–≤–∫—É, –æ—á–µ–Ω...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Stylish_Shock / –ö–æ–∂–∞–Ω–∞—è –æ–±–ª–æ–∂–∫–∞ –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ...</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–∞—è –∏ –ø–æ–ª–µ–∑–Ω–∞—è –≤–µ—â—å –ü–æ–ª–æ–∂–∏–ª–∞ –≤—Å—ë –¥–æ–∫...</td>\n",
       "      <td>–î–∞–≤–Ω–æ —Ö–æ—Ç–µ–ª–∞ —Ç–∞–∫–æ–π –æ—Ä–≥–∞–Ω–∞–π–∑–µ—Ä –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –í...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>SuperVision / –û—á–∫–∏ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, ...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä –®–∏–∫–∞—Ä–Ω—ã–µ –æ—á–∫–∏ –ö–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –†–µ...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä –®–∏–∫–∞—Ä–Ω—ã–µ –æ—á–∫–∏ –ö–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –†–µ...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>SuperVision / –û—á–∫–∏ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, ...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏, –º—É–∂—É –±—Ä–∞–ª–∞ –≤ –ø–æ–¥–∞—Ä–æ–∫, –æ—Å—Ç–∞–ª—Å—è –¥...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏, –º—É–∂—É –±—Ä–∞–ª–∞ –≤ –ø–æ–¥–∞—Ä–æ–∫, –æ—Å—Ç–∞–ª—Å—è –¥...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>–ú–∏—Å—Å–∏—Å –ê / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–µ –∞–Ω—Ç...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ —É–¥–æ–±–Ω—ã–µ –Ω–µ –º–µ—à–∞—é—Ç –æ–±–∑–æ—Ä—É —Ç–æ —á—Ç–æ –≤...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ —É–¥–æ–±–Ω—ã–µ –Ω–µ –º–µ—à–∞—é—Ç –æ–±–∑–æ—Ä—É —Ç–æ —á—Ç–æ –≤...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>–°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...</td>\n",
       "      <td>–°–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤—Ü—É –û—á–∫–∏ –ø—Ä–∏—à–ª–∏ –≤–æ–≤—Ä–µ–º—è, —Ö–æ—Ä–æ—à–æ —É...</td>\n",
       "      <td>–û—á–∫–∏ –¥–æ—Å—Ç–æ–π–Ω—ã–µ, –¥–æ—Å—Ç–∞–≤–∫–∞ –±—ã—Å—Ç—Ä–∞—è , –∫ –ø–æ–∫—É–ø–∫–µ —Ä...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>–°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...</td>\n",
       "      <td>–û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ, –Ω–µ –±–æ–ª—å—à–∏–µ, –æ—Ç—Ü—É –æ—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª–∏...</td>\n",
       "      <td>–û—á–∫–∏ –∫–ª—ë–≤—ã–µ –ú—É–∂—É –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               product  \\\n",
       "0    *Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç   \n",
       "2    *Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç   \n",
       "6    Clements / –í–∫–ª–∞–¥—ã—à –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∑—Ä–∞—á–Ω...   \n",
       "14   Eternal way / –ë–µ—Å–ø—Ä–æ–≤–æ–¥–Ω–æ–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∞–∫–∫—É–º...   \n",
       "17         FST Auto / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ö–ª–∞—Å—Å–∏–∫–∞ 2 —à—Ç   \n",
       "28   FST Auto / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –°–ø–æ—Ä—Ç–∏–≤–Ω—ã–π —Å—Ç–∏–ª—å...   \n",
       "43            Grand House / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –∞–Ω—Ç–∏–±–ª–∏–∫   \n",
       "44            Grand House / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –∞–Ω—Ç–∏–±–ª–∏–∫   \n",
       "52   Lieblich Hause (Haz) / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –≤–æ–∑–¥—É—à–Ω—ã–π –±–µ...   \n",
       "53   Lieblich Hause (Haz) / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –≤–æ–∑–¥—É—à–Ω—ã–π –±–µ...   \n",
       "66   Lieblich Hause / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, ...   \n",
       "67   Lieblich Hause / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, ...   \n",
       "68   Lieblich Hause / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, ...   \n",
       "72    MAZURA / –ê–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è —Ö–∞–º–µ–ª–µ–æ–Ω   \n",
       "73    MAZURA / –ê–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è —Ö–∞–º–µ–ª–µ–æ–Ω   \n",
       "74    MAZURA / –ê–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è —Ö–∞–º–µ–ª–µ–æ–Ω   \n",
       "89   RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...   \n",
       "90   RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...   \n",
       "91   RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...   \n",
       "94   RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...   \n",
       "97   RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...   \n",
       "98   RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...   \n",
       "104    Romarina / –ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω—ã–π   \n",
       "105    Romarina / –ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω—ã–π   \n",
       "106    Romarina / –ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω—ã–π   \n",
       "114  SHADOVtech / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –≤–æ–∑–¥—É—à–Ω—ã...   \n",
       "119  StarLine / –ß–µ—Ö–æ–ª —Å–∏–ª–∏–∫–æ–Ω–æ–≤—ã–π –¥–ª—è –±—Ä–µ–ª–æ–∫–∞ –°—Ç–∞—Ä–ª...   \n",
       "120  StarLine / –ß–µ—Ö–æ–ª —Å–∏–ª–∏–∫–æ–Ω–æ–≤—ã–π –¥–ª—è –±—Ä–µ–ª–æ–∫–∞ –°—Ç–∞—Ä–ª...   \n",
       "127  Stylish_Shock / –ö–æ–∂–∞–Ω–∞—è –æ–±–ª–æ–∂–∫–∞ –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ...   \n",
       "128  Stylish_Shock / –ö–æ–∂–∞–Ω–∞—è –æ–±–ª–æ–∂–∫–∞ –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ...   \n",
       "145  SuperVision / –û—á–∫–∏ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, ...   \n",
       "147  SuperVision / –û—á–∫–∏ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, ...   \n",
       "153  –ú–∏—Å—Å–∏—Å –ê / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–µ –∞–Ω—Ç...   \n",
       "158  –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...   \n",
       "160  –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...   \n",
       "\n",
       "                                     cluster_sentences  \\\n",
       "0    –°–≤–æ–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç, –æ—Å–æ–±–µ–Ω–Ω–æ –∂—ë–ª—Ç—ã–µ –ª–∏–Ω–∑—ã ...   \n",
       "2    –î–µ—Ç—Å–∫–∏–µ | –ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ | –ù—É –æ—á–µ–Ω—å ...   \n",
       "6    –í–º–µ—Å—Ç–∏–ª–∏—Å—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã: –¢–°, —Å—Ç—Ä–∞—Ö–æ–≤—ã–µ, –ø–∞—Å–ø–æ...   \n",
       "14   –ó–∞–∫–∞–∑–∞–ª–∞ —Å–µ–±–µ –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä, –º–µ–Ω—è –ø–æ–¥–∫—É–ø–∏–ª –Ω–µ–æ–±—ã—á...   \n",
       "17   –ö–∞–∫ –∏–≥—Ä—É—à–µ—á–Ω—ã–µ, –ª—ë–≥–∫–∏–µ, –Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤...   \n",
       "28   –ö–∞–∫ –∏–≥—Ä—É—à–µ—á–Ω—ã–µ, –ª—ë–≥–∫–∏–µ, –Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤...   \n",
       "43   –ì–æ–¥–Ω—ã–µ –æ—á–∫–∏, –Ω–æ—á—å—é –∫–∞–∫ –¥–Ω—ë–º –µ–¥–µ—à—å, –¥–Ω—ë–º —Å–æ–ª–Ω—Ü–µ...   \n",
       "44   –û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ, –º—É–∂—É –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é | –û—á...   \n",
       "52   –ï—Å—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –º–∞–Ω–æ–º–µ—Ç—Ä, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ –Ω–µ –Ω–∞...   \n",
       "53   –ö—É–ø–∏–ª –∫–∞—á–∞—Ç—å –≤–∞—Ç—Ä—É—à–∫—É –∏ –¥–ª—è –≤–µ–ª–æ—Å–∏–ø–µ–¥–æ–≤ –†–∞–±–æ—Ç–∞...   \n",
       "66   –û—á–µ–Ω—å –ø–æ–ª–µ–∑–Ω—ã–µ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –¥–µ—à—ë–≤—É...   \n",
       "67   –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –£–¥–æ–±–Ω—ã–µ –†–µ–∫–æ–º–µ–Ω–¥—É—é | –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏...   \n",
       "68   –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, —Å–ø–∞—Å–∏–±–æ —Ö–æ—Ä–æ—à–∏–π | –í—Å–µ —Ö–æ—Ä–æ—à–æ –û—á–∫...   \n",
       "72   –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, –º–∞—Ç–µ—Ä–∏–∞–ª –æ—Ç–ª–∏—á–Ω—ã–π –∑–∞ —Å–≤–æ—é –∞–∏–Ω–Ω—É ...   \n",
       "73   –ñ–∞–ª–µ—é, —á—Ç–æ –Ω–µ –∫—É–ø–∏–ª–∞ –∏—Ö —Ä–∞–Ω—å—à–µ –ó–∞–∫–∞–∑–∞–ª–∞ —Ç–æ–ª—å–∫–æ...   \n",
       "74   –û—á–∫–∏ —Ö–æ—Ä–æ—à–∏ –í–∏–¥–Ω–æ –≤ –Ω–∏—Ö –Ω–∞ —Ç—Ä–∞—Å—Å–µ —Ö–æ—Ä–æ—à–æ | –û—Ç–ª...   \n",
       "89   –û—á–∫–∏ –Ω—Ä–∞–≤—è—Ç—Å—è –ó–∞—Ç–µ–º–Ω—è—é—Ç –≤ —Å–æ–ª–Ω–µ—á–Ω—É—é –ø–æ–≥–æ–¥—É –∏ –æ...   \n",
       "90   –û—á–∫–∏ —Ü–µ–ª—ã–µ, –Ω–æ—Ä–º –¢–æ–ª—å–∫–æ –æ—Å—Ç–∞–≤–ª—è—é—Ç —Å–ª–µ–¥—ã –Ω–∞ –ø–µ—Ä...   \n",
       "91   –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –∑–∞ —Å–≤–æ–∏ –¥–µ–Ω—å–≥–∏, —è –±—ã —Å–∫–∞–∑–∞–ª –æ—Ç–ª–∏—á...   \n",
       "94   –°—É–ø–µ—Ä –æ—á–∫–∏ –∑–∞ —Ç–∞–∫—É—é —Ü–µ–Ω—É, –∑–∞–∫–∞–∑—ã–≤–∞–ª–∞ –º—É–∂—É, –æ—á–µ...   \n",
       "97   –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –ø–æ–ª—å–∑—É—é—Å—å, –Ω–æ –Ω–µ –≤—Å–µ–≥–¥–∞ | –û—á–∫–∏ –Ω–æ...   \n",
       "98   –ë–æ–ª—å—à–æ–µ —Å–ø–∞—Å–∏–±–æ –û—á–∫–∏ –æ–≥–æ–Ω—å –¥–∞–∂–µ —Å –æ—á–∫–∞–º–∏ –¥–ª—è –∑...   \n",
       "104  –ù–∞ –≤–µ–ª–∏–∫–∞—Ö –∏—Å–ø—Ä–æ–±–æ–≤–∞–ª –ù–∞–∫–∞—á–∏–≤–∞–µ—Ç –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∫...   \n",
       "105  –û—Ç–ª–∏—á–Ω—ã–π –Ω–∞—Å–æ—Å –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ—Å—Ç–∞–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç—å...   \n",
       "106  –ù–∞–∫–∞—á–∞–ª –¥–≤–∞ —Ä–∞—Å—à–∏—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –±–∞–∫–∞ –ø–æ 8 –ª–∏—Ç—Ä–æ–≤ —Å ...   \n",
       "114  –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –¥–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ, –¥–∞...   \n",
       "119  –û—Ç–ª–∏—á–Ω—ã–π —á–µ—Ö–æ–ª –•–æ—Ä–æ—à–∞—è —Ü–µ–Ω–∞ –ü–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å –∫–∞—á–µ—Å—Ç...   \n",
       "120  –û—Ç–ª–∏—á–Ω–æ –ø–æ–¥–æ—à—ë–ª üëç | –†–µ–∫–æ–º–µ–Ω–¥—É—é!üëçüèª | –ü–æ–¥–æ—à–µ–ª –æ—Ç...   \n",
       "127  –û—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è —Ç–æ–≤–∞—Ä –û–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤...   \n",
       "128  –û—á–µ–Ω—å —É–¥–æ–±–Ω–∞—è –∏ –ø–æ–ª–µ–∑–Ω–∞—è –≤–µ—â—å –ü–æ–ª–æ–∂–∏–ª–∞ –≤—Å—ë –¥–æ–∫...   \n",
       "145  –û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä –®–∏–∫–∞—Ä–Ω—ã–µ –æ—á–∫–∏ –ö–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –†–µ...   \n",
       "147  –û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏, –º—É–∂—É –±—Ä–∞–ª–∞ –≤ –ø–æ–¥–∞—Ä–æ–∫, –æ—Å—Ç–∞–ª—Å—è –¥...   \n",
       "153  –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ —É–¥–æ–±–Ω—ã–µ –Ω–µ –º–µ—à–∞—é—Ç –æ–±–∑–æ—Ä—É —Ç–æ —á—Ç–æ –≤...   \n",
       "158  –°–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤—Ü—É –û—á–∫–∏ –ø—Ä–∏—à–ª–∏ –≤–æ–≤—Ä–µ–º—è, —Ö–æ—Ä–æ—à–æ —É...   \n",
       "160  –û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ, –Ω–µ –±–æ–ª—å—à–∏–µ, –æ—Ç—Ü—É –æ—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª–∏...   \n",
       "\n",
       "                                           key_thought  word_count  \n",
       "0    –•–ª–∏–ø–∫–∏–µ –ø–æ—Å–ª–µ –ø—Ä–æ—Ç–∏—Ä–∫–µ –æ–¥–Ω–æ —Å—Ç–µ–∫–ª–æ –≤—ã–≤–æ–ª–µ–ª–æ—Å—å,...          53  \n",
       "2                             –ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ           9  \n",
       "6    –û—Ç–ª–∏—á–Ω—ã–π –≤–∫–ª–∞–¥—ã—à, –ø–ª–æ—Ç–Ω—ã–π, –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤–æ—à–ª–∏...          43  \n",
       "14   –•–æ—Ä–æ—à–∏–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ë—Ä–∞–ª–∞ –≤ –ø–æ–¥–∞—Ä–æ–∫ –º—É–∂—É –°—Ä–∞–∑—É ...          43  \n",
       "17      –°–∫–æ–ª—å–∫–æ —Å—Ç–æ—è—Ç, —Ç–∞–∫ –∏ –≤—ã–≥–ª—è–¥—è—Ç: –¥—ë—à–µ–≤–æ –∏ –ø—Ä–æ—Å—Ç–æ          37  \n",
       "28      –°–∫–æ–ª—å–∫–æ —Å—Ç–æ—è—Ç, —Ç–∞–∫ –∏ –≤—ã–≥–ª—è–¥—è—Ç: –¥—ë—à–µ–≤–æ –∏ –ø—Ä–æ—Å—Ç–æ          37  \n",
       "43   –ü–æ–ª –¥–Ω—è —Å–µ–≥–æ–¥–Ω—è –µ—Ö–∞–ª –≤ –∂–µ–ª—Ç—ã—Ö –æ—á–∫–∞—Ö, –≥–ª–∞–∑–∞ –Ω–µ ...          65  \n",
       "44               –û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ, –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é          33  \n",
       "52   –ù–∞–∫–∞—á–∞–ª 2 –∫–æ–ª–µ—Å–∞ –¥–ª—è –≤–µ–ª–∏–∫–∞ –¥–æ 3 –∞—Ç–º–æ—Å—Ñ–µ—Ä - —Å–ø...         173  \n",
       "53   –ü–æ–∫—É–ø–∞–ª –¥–ª—è –≤–µ–ª–æ—Å–∏–ø–µ–¥–∞, –æ—Ç–ª–∏—á–Ω–∞—è —à—Ç—É–∫–∞ –ü—Ä–æ–±–æ–≤–∞...          85  \n",
       "66   –£–¥–æ–±–Ω—ã–µ, –æ–±–ª–µ–≥—á–∞—é—Ç –≤–æ–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ —è—Ä–∫–æ–º —Å–≤–µ—Ç–µ –†–µ...          33  \n",
       "67                     –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –£–¥–æ–±–Ω—ã–µ –†–µ–∫–æ–º–µ–Ω–¥—É—é          30  \n",
       "68                       –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, —Å–ø–∞—Å–∏–±–æ —Ö–æ—Ä–æ—à–∏–π          20  \n",
       "72   –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, –ª—ë–≥–∫–∏–µ –∏ —É–¥–æ–±–Ω—ã–µ –í —Ö–æ—Ä–æ—à–µ–º —á–µ—Ö–ª–µ...         372  \n",
       "73   –ñ–∞–ª–µ—é, —á—Ç–æ –Ω–µ –∫—É–ø–∏–ª–∞ –∏—Ö —Ä–∞–Ω—å—à–µ –ó–∞–∫–∞–∑–∞–ª–∞ —Ç–æ–ª—å–∫–æ...         110  \n",
       "74            –û—á–∫–∏ —Ö–æ—Ä–æ—à–∏ –í–∏–¥–Ω–æ –≤ –Ω–∏—Ö –Ω–∞ —Ç—Ä–∞—Å—Å–µ —Ö–æ—Ä–æ—à–æ          52  \n",
       "89   –û—Ç–ª–∏—á–Ω—ã–µ —Å—Ç–∏–ª—å–Ω—ã–µ –æ—á–∫–∏ –∏ —Ö–æ—Ä–æ—à–æ –∑–∞—â–∏—â–∞—é—Ç –æ—Ç —Å–æ...         108  \n",
       "90        –û—á–∫–∏ –Ω–µ –ø–ª–æ—Ö–∏–µ, –Ω–æ —Ö–ª–∏–ø–∫–∏–µ, –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ —Ü–µ–Ω–µ          91  \n",
       "91   –û—á–∫–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∫–ª–∞—Å—Å–Ω—ã–µ, –∑–∞—è–≤–ª–µ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç...          85  \n",
       "94                –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, –∑–∞–∫–∞–∑–∞–ª–∞ –µ—â—ë, –¥–ª—è —Å—ã–Ω–∞          47  \n",
       "97                –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –ø–æ–ª—å–∑—É—é—Å—å, –Ω–æ –Ω–µ –≤—Å–µ–≥–¥–∞          35  \n",
       "98                     –°–ø–∞—Å–∏–±–æ –∑–∞ –æ—á–∫–∏ –ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å          20  \n",
       "104  –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π, –µ—Å—Ç—å —Å—É–º–æ—á–∫–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è, –ª–µ–≥–∫–æ —É...         600  \n",
       "105  –ù–∞—Å–æ—Å –æ—Ç–ª–∏—á–Ω—ã–π –û—á–µ–Ω—å –¥–æ–≤–æ–ª–µ–Ω, –±—Ä–∞–ª –¥–ª—è –≤–µ–ª–æ—Å–∏–ø...         188  \n",
       "106  –ù–∞–∫–∞—á–∞–ª –∫–æ–ª–µ—Å–∞ —Å–∞–º–æ–∫–∞—Ç—É, –ø–æ–¥–∫–∞—á–∞–ª –ø–µ—Ä–µ–¥–Ω–∏–µ –Ω–∞ ...         127  \n",
       "114  –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä —Ö–æ—Ä–æ—à–∏–π, —Å –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–ø—É—â–µ–Ω–Ω–æ–≥–æ –∫–æ–ª...         528  \n",
       "119  –û—Ç–ª–∏—á–Ω—ã–π —á–µ—Ö–æ–ª –•–æ—Ä–æ—à–∞—è —Ü–µ–Ω–∞ –ü–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å –∫–∞—á–µ—Å—Ç...         103  \n",
       "120                         –û—Ç–ª–∏—á–Ω–æ –ø–æ–¥–æ—à–µ–ª –†–µ–∫–æ–º–µ–Ω–¥—É—é          49  \n",
       "127  –°–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤—Ü—É –∑–∞ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω—É—é –¥–æ—Å—Ç–∞–≤–∫—É, –æ—á–µ–Ω...          62  \n",
       "128  –î–∞–≤–Ω–æ —Ö–æ—Ç–µ–ª–∞ —Ç–∞–∫–æ–π –æ—Ä–≥–∞–Ω–∞–π–∑–µ—Ä –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –í...          59  \n",
       "145  –û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä –®–∏–∫–∞—Ä–Ω—ã–µ –æ—á–∫–∏ –ö–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –†–µ...          58  \n",
       "147  –û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏, –º—É–∂—É –±—Ä–∞–ª–∞ –≤ –ø–æ–¥–∞—Ä–æ–∫, –æ—Å—Ç–∞–ª—Å—è –¥...          35  \n",
       "153  –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ —É–¥–æ–±–Ω—ã–µ –Ω–µ –º–µ—à–∞—é—Ç –æ–±–∑–æ—Ä—É —Ç–æ —á—Ç–æ –≤...          28  \n",
       "158  –û—á–∫–∏ –¥–æ—Å—Ç–æ–π–Ω—ã–µ, –¥–æ—Å—Ç–∞–≤–∫–∞ –±—ã—Å—Ç—Ä–∞—è , –∫ –ø–æ–∫—É–ø–∫–µ —Ä...          55  \n",
       "160                       –û—á–∫–∏ –∫–ª—ë–≤—ã–µ –ú—É–∂—É –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å          18  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import emoji\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ spaCy –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞\n",
    "nlp = spacy.load(\"ru_core_news_lg\")\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–ª–∏—á–∏—è —ç–º–æ–¥–∑–∏ –≤ —Å—Ç—Ä–æ–∫–µ\n",
    "def contains_emoji(text):\n",
    "    return any(char in emoji.EMOJI_DATA for char in text)\n",
    "\n",
    "# –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–∞—Å–∫–∏\n",
    "common_phrases = [\n",
    "    r'–≤—Å—ë –æ–∫', r'—Å—É–ø–µ—Ä', r'–∫–ª–∞—Å—Å', r'–Ω–æ—Ä–º–∞–ª—å–Ω–æ', r'–Ω–æ—Ä–º', r'–≤—Å—ë –Ω–æ—Ä–º', r'–æ—Ç–ª–∏—á–Ω–æ', r'—Ö–æ—Ä–æ—à–æ', r'–Ω–æ—Ä–º–∞–ª—å–Ω–æ —É–ø–∞–∫–æ–≤–∞–Ω–æ',\n",
    "    r'–±–µ–∑ –ø—Ä–æ–±–ª–µ–º', r'–∫–∞–∫ –≤—Å–µ–≥–¥–∞', r'–Ω–æ—Ä–º'\n",
    "]\n",
    "emotional_phrases = [\n",
    "    r'—Å–ø–∞—Å–∏–±–æ', r'—Ä–µ–∫–æ–º–µ–Ω–¥—É—é', r'—Å–æ–≤–µ—Ç—É—é', r'–ø—Ä–æ–¥–∞–≤–µ—Ü –º–æ–ª–æ–¥–µ—Ü', r'–º–æ–ª–æ–¥–µ—Ü', r'—Ä–µ–∫–æ–º–µ–Ω–¥—É—é –ø—Ä–æ–¥–∞–≤—Ü–∞', r'–±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω', r'–±–ª–∞–≥–æ–¥–∞—Ä—é',\n",
    "    r'—Å–æ–≤–µ—Ç—É—é –∫ –ø–æ–∫—É–ø–∫–µ', r'—Å–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–µ', r'–≤—Å–µ–º —Å–æ–≤–µ—Ç—É—é'\n",
    "]\n",
    "short_phrases = [\n",
    "    r'–ø—Ä–∏—à–µ–ª –±—ã—Å—Ç—Ä–æ', r'—É–∂–µ –±—Ä–∞–ª', r'–ø–æ–º–æ–≥–ª–æ', r'–Ω–µ –ø–æ–º–æ–≥–ª–æ', r'–ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª', r'–æ—Ç–ª–∏—á–Ω–∞—è –≤–µ—â—å', r'–≤—Å—ë –æ–∫–µ–π',\n",
    "    r'–Ω–æ—Ä–º–∞–ª—å–Ω–æ', r'–±—ã—Å—Ç—Ä–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞', r'–ø—Ä–∏—à–µ–ª –≤–æ–≤—Ä–µ–º—è'\n",
    "]\n",
    "item_phrases = [\n",
    "    r'—Ö–æ—Ä–æ—à–∞—è –≤–µ—â—å', r'–∫–ª–∞—Å—Å–Ω–∞—è –≤–µ—â—å', r'–æ—Ç–ª–∏—á–Ω–∞—è –≤–µ—â—å', r'–Ω—É–∂–Ω–∞—è –≤–µ—â—å', r'—É–¥–æ–±–Ω–∞—è –≤–µ—â—å', r'–ø–æ–ª–µ–∑–Ω–∞—è –≤–µ—â—å',\n",
    "    r'–ø—Ä–µ–∫—Ä–∞—Å–Ω–∞—è –≤–µ—â—å', r'–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–∞—è –≤–µ—â—å', r'—Ö–æ—Ä–æ—à–∏–π –ø—Ä–æ–¥—É–∫—Ç', r'–æ—Ç–ª–∏—á–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç', r'–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –≤–µ—â—å'\n",
    "]\n",
    "task_phrases = [\n",
    "    r'—Å –∑–∞–¥–∞—á–µ–π —Å–ø—Ä–∞–≤–∏–ª—Å—è', r'—Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏ —Å–ø—Ä–∞–≤–∏–ª—Å—è', r'–∑–∞–¥–∞—á—É —Å–≤–æ—é –≤—ã–ø–æ–ª–Ω–∏–ª', r'—Å–ø—Ä–∞–≤–∏–ª—Å—è –Ω–∞ –æ—Ç–ª–∏—á–Ω–æ', \n",
    "    r'—Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç', r'—Å –∑–∞–¥–∞—á–µ–π —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è', r'–∑–∞–¥–∞—á—É –≤—ã–ø–æ–ª–Ω–∏–ª', r'—Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –∑–∞–¥–∞—á–µ–π', \n",
    "    r'—Å–æ —Å–≤–æ–∏–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è', r'—Å–ø—Ä–∞–≤–∏–ª—Å—è —Å –∑–∞–¥–∞—á–µ–π'\n",
    "]\n",
    "delivery_phrases = [\n",
    "    r'–∑–∞–∫–∞–∑ –ø—Ä–∏—à–µ–ª —Ü–µ–ª—ã–π –∏ –≤–æ–≤—Ä–µ–º—è', r'–ø—Ä–∏—à–µ–ª –≤–æ–≤—Ä–µ–º—è', r'–ø—Ä–∏—à–µ–ª —Ü–µ–ª—ã–π', r'–¥–æ—Å—Ç–∞–≤–∫–∞ –≤–æ–≤—Ä–µ–º—è', r'–≤—Å–µ –ø—Ä–∏—à–ª–æ —Ü–µ–ª—ã–º', \n",
    "    r'—Ç–æ–≤–∞—Ä –ø—Ä–∏—à–µ–ª —Ü–µ–ª—ã–º', r'–ø—Ä–∏—à–µ–ª –≤ —Å—Ä–æ–∫', r'–¥–æ—Å—Ç–∞–≤–∫–∞ –±—ã—Å—Ç—Ä–∞—è', r'–ø—Ä–∏—à–µ–ª –≤–æ–≤—Ä–µ–º—è –∏ —Ü–µ–ª—ã–º', r'–ø–æ–ª—É—á–∏–ª –∑–∞–∫–∞–∑ –≤–æ–≤—Ä–µ–º—è'\n",
    "]\n",
    "emoji_phrases = [\n",
    "    r'–∏–¥–µ–∞–ª—å–Ω–æ', r'–æ—Ç–ª–∏—á–Ω–æ', r'üëç', r'üëè', r'üòÜ', r'üî•', r'üíØ', r'–∫–ª–∞—Å—Å', r'–∫–ª–∞—Å—Åüëç', r'–≤—Å–µ —Å—É–ø–µ—Äüëç', r'üëçüëçüëç', r'üëçüòä'\n",
    "]\n",
    "negative_condition_phrases = [\n",
    "    r'–ø—Ä–∏—à–ª–æ –≤—Å–µ –ø–æ–±–∏—Ç–æ–µ', r'—É–ø–∞–∫–æ–≤–∫–∞ –ø–æ—Ä–≤–∞–Ω–∞', r'–≤—Å—ë —Å–ª–æ–º–∞–Ω–æ', r'—Ç–æ–≤–∞—Ä —Ç—Ä–µ—Å–Ω—É–ª', r'–ø–æ–ª—É—á–∏–ª —Ç–æ–≤–∞—Ä —Å –¥–µ—Ñ–µ–∫—Ç–æ–º', \n",
    "    r'–ø–æ–≥–Ω—É—Ç–∞—è —É–ø–∞–∫–æ–≤–∫–∞', r'–ø—Ä–∏—à–ª–æ —Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω–æ–µ', r'–≤—Å–µ —Ä–∞–∑–ª–∏—Ç–æ', r'–∫–æ—Ä–æ–±–∫–∞ –ø–æ–º—è—Ç–∞', r'–≤—Å—ë –ø–æ–±–∏–ª–æ—Å—å', \n",
    "    r'—Å–ª–æ–º–∞–Ω–Ω—ã–π —Ç–æ–≤–∞—Ä', r'–≤—Å–µ –ø–æ—Ä–≤–∞–Ω–æ', r'–ø—Ä–∏—à–µ–ª –≤–µ—Å—å –≤ —Ç—Ä–µ—â–∏–Ω–∞—Ö', r'–ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω–∞—è —É–ø–∞–∫–æ–≤–∫–∞', r'—Ç–æ–≤–∞—Ä –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç'\n",
    "]\n",
    "positive_condition_phrases = [\n",
    "    r'–≤—Å—ë –ø—Ä–∏—à–ª–æ —Ü–µ–ª–æ–µ –∏ –Ω–µ–≤—Ä–µ–¥–∏–º–æ–µ', r'–¥–æ—Å—Ç–∞–≤–∫–∞ - –≤–æ!', r'–∫—Ä—É—Ç–∞—è —É–ø–∞–∫–æ–≤–∫–∞', r'—É–ø–∞–∫–æ–≤–∞–Ω–æ –Ω–∞ —Å–æ–≤–µ—Å—Ç—å', \n",
    "    r'–≤—Å–µ –ø—Ä–∏—à–ª–æ –≤ –∏–¥–µ–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏', r'—Ç–æ–≤–∞—Ä –≤ –æ—Ç–ª–∏—á–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏', r'–±–µ–∑ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π', r'—É–ø–∞–∫–æ–≤–∫–∞ —Ü–µ–ª–∞—è', \n",
    "    r'—Ç–æ–≤–∞—Ä –±–µ–∑ –¥–µ—Ñ–µ–∫—Ç–æ–≤', r'–≤—Å–µ –ø—Ä–∏—à–ª–æ –∫–∞–∫ –Ω–∞–¥–æ', r'–ø—Ä–∏—à–µ–ª –≤ –ø–æ–ª–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ', r'–æ—Ç–ª–∏—á–Ω–∞—è —É–ø–∞–∫–æ–≤–∫–∞', \n",
    "    r'–≤—Å–µ –¥–æ—à–ª–æ —Ü–µ–ª—ã–º', r'–¥–æ—Å—Ç–∞–≤–∫–∞ –±–µ–∑ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π', r'–∏–¥–µ–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ'\n",
    "]\n",
    "gratitude_phrases = [\n",
    "    r'—Å–ø–∞—Å–∏–±–æ –∑–∞ —Ç–æ–≤–∞—Ä', r'—Å–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤—Ü—É', r'—Å–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–µ', r'–±–ª–∞–≥–æ–¥–∞—Ä—é –∑–∞ —Ç–æ–≤–∞—Ä', r'–±–æ–ª—å—à–æ–µ —Å–ø–∞—Å–∏–±–æ', \n",
    "    r'–æ—á–µ–Ω—å –±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ –¥–æ—Å—Ç–∞–≤–∫—É', r'–æ–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç–æ–≤–∞—Ä', \n",
    "    r'–ø—Ä–æ–¥–∞–≤—Ü—É –æ–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ—Å—Ç—å', r'—Å–ø–∞—Å–∏–±–æ –≤–∞–º', r'–±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω –∑–∞ —Ç–æ–≤–∞—Ä', \n",
    "    r'—Å–ø–∞—Å–∏–±–æ, –≤—Å—ë —Ö–æ—Ä–æ—à–æ', r'–ø—Ä–æ–¥–∞–≤–µ—Ü –º–æ–ª–æ–¥–µ—Ü', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ —Ö–æ—Ä–æ—à–µ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ'\n",
    "]\n",
    "neutral_quality_phrases = [\n",
    "    r'–≤—Å—ë –æ—Ç–ª–∏—á–Ω–æ', r'–≤—Å—ë —Ö–æ—Ä–æ—à–æ', r'–≤—Å–µ —Å—É–ø–µ—Ä', r'–æ—á–µ–Ω—å –¥–æ–≤–æ–ª–µ–Ω –ø–æ–∫—É–ø–∫–æ–π', r'—Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ', \n",
    "    r'–Ω–∞–¥–µ—é—Å—å –ø—Ä–æ—Å–ª—É–∂–∏—Ç—å –¥–æ–ª–≥–æ', r'–≤—Å—ë —Ü–µ–ª–æ–µ', r'–≤—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ', r'–≤—Å—ë –∫–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏', \n",
    "    r'–≤—Å—ë –∫–∞–∫ –∑–∞—è–≤–ª–µ–Ω–æ', r'–∑–∞ —Å–≤–æ—é —Ü–µ–Ω—É –æ—Ç–ª–∏—á–Ω–æ', r'–∫–∞—á–µ—Å—Ç–≤–æ —Ö–æ—Ä–æ—à–µ–µ', r'–æ—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ', \n",
    "    r'–∫–æ–º–ø–ª–µ–∫—Ç –∫–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏', r'–º–µ–ª–æ—á—å, –∞ –ø—Ä–∏—è—Ç–Ω–æ', r'–º–Ω–µ –≤—Å—ë –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å', r'–¥–æ–±—Ä—ã–π –¥–µ–Ω—å', \n",
    "    r'–≤—Å—ë —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç', r'—Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ, —Å–ø–∞—Å–∏–±–æ', r'–≤—Å—ë —Å—É–ø–µ—Ä üëå'\n",
    "]\n",
    "\n",
    "# –ù–æ–≤—ã–µ –º–∞—Å–∫–∏\n",
    "confirmation_phrases = [\n",
    "    r'–≤—Å—ë —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç', r'–≤—Å—ë –∫–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏', r'–≤—Å—ë –∫–∞–∫ –∑–∞—è–≤–ª–µ–Ω–æ', r'—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—é', r'–≤—Å—ë —Ü–µ–ª–æ–µ', r'–≤—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ', r'–≤—Å—ë –Ω–æ—Ä–º', r'–≤—Å—ë —Ö–æ—Ä–æ—à–æ'\n",
    "]\n",
    "simple_statements_phrases = [\n",
    "    r'—Ö–æ—Ä–æ—à–∞—è –≤–µ—â—å', r'–∫–ª–∞—Å—Å–Ω–∞—è –≤–µ—â—å', r'–æ—Ç–ª–∏—á–Ω–∞—è –≤–µ—â—å', r'—É–¥–æ–±–Ω–æ', r'–Ω–æ—Ä–º–∞–ª—å–Ω–æ', r'—Ä–∞–±–æ—Ç–∞–µ—Ç', r'—Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ', r'—Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ', r'–≤—Å—ë –Ω–æ—Ä–º–∞–ª—å–Ω–æ', r'–≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç'\n",
    "]\n",
    "quality_phrases = [\n",
    "    r'–∫–∞—á–µ—Å—Ç–≤–æ —Ö–æ—Ä–æ—à–µ–µ', r'–æ—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ', r'–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ', r'–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ', r'–≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ', r'–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç–æ–≤–∞—Ä', r'–∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–ª–∏—á–Ω–æ–µ', r'–∫–∞—á–µ—Å—Ç–≤–æ —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ'\n",
    "]\n",
    "functionality_phrases = [\n",
    "    r'—Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ', r'—Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ', r'–≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç', r'—Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç', r'—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π', r'—Ñ—É–Ω–∫—Ü–∏–∏ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è', r'—Å –∑–∞–¥–∞—á–µ–π —Å–ø—Ä–∞–≤–∏–ª—Å—è', r'—Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –∑–∞–¥–∞—á–µ–π', r'—Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç'\n",
    "]\n",
    "price_phrases = [\n",
    "    r'—Ü–µ–Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è', r'—Ü–µ–Ω–∞ –∞–¥–µ–∫–≤–∞—Ç–Ω–∞—è', r'—Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ü–µ–Ω–∞/–∫–∞—á–µ—Å—Ç–≤–æ', r'—Ü–µ–Ω–∞ –æ—Ç–ª–∏—á–Ω–∞—è', r'—Ü–µ–Ω–∞ —Ö–æ—Ä–æ—à–∞—è', r'—Ü–µ–Ω–∞ –ø—Ä–∏–µ–º–ª–µ–º–∞—è', r'—Ü–µ–Ω–∞ –æ–ø—Ä–∞–≤–¥–∞–Ω–∞', r'—Ü–µ–Ω–∞ –Ω–∏–∑–∫–∞—è', r'—Ü–µ–Ω–∞ –≤—ã—Å–æ–∫–∞—è', r'—Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ü–µ–Ω—ã –∏ –∫–∞—á–µ—Å—Ç–≤–∞', r'–∑–∞ —Ç–∞–∫—É—é —Ü–µ–Ω—É', r'–≤–ø–æ–ª–Ω–µ –ø—Ä–∏–µ–º–ª–µ–º–∞—è —Ü–µ–Ω–∞'\n",
    "]\n",
    "durability_phrases = [\n",
    "    r'–Ω–∞–¥–µ—é—Å—å –ø—Ä–æ—Å–ª—É–∂–∏—Ç—å –¥–æ–ª–≥–æ', r'–ø–æ–ª—å–∑—É—é—Å—å –¥–æ–ª–≥–æ', r'–Ω–∞–¥–µ–∂–Ω—ã–π —Ç–æ–≤–∞—Ä', r'–¥–æ–ª–≥–æ–≤–µ—á–Ω—ã–π', r'—Ö–≤–∞—Ç–∏—Ç –Ω–∞–¥–æ–ª–≥–æ', r'–±—É–¥—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–æ–ª–≥–æ', r'–Ω–∞ —Å–µ–∑–æ–Ω —Ö–≤–∞—Ç–∏—Ç', r'–¥–æ–ª–≥–æ –ø–æ–ª—å–∑—É—é—Å—å', r'–ø—Ä–æ–≤–µ—Ä–µ–Ω–æ –≤—Ä–µ–º–µ–Ω–µ–º', r'–≤—ã–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–∞–≥—Ä—É–∑–∫–∏', r'–ø–æ—Å–º–æ—Ç—Ä–∏–º, —Å–∫–æ–ª—å–∫–æ –ø—Ä–æ–¥–µ—Ä–∂–∏—Ç—Å—è'\n",
    "]\n",
    "appearance_phrases = [\n",
    "    r'–≤—ã–≥–ª—è–¥–∏—Ç —Ö–æ—Ä–æ—à–æ', r'—Å–º–æ—Ç—Ä–∏—Ç—Å—è –∫—Ä–∞—Å–∏–≤–æ', r'–≤–Ω–µ—à–Ω–∏–π –≤–∏–¥ –æ—Ç–ª–∏—á–Ω—ã–π', r'—Å—Ç–∏–ª—å–Ω–æ –≤—ã–≥–ª—è–¥–∏—Ç', r'–≤—ã–≥–ª—è–¥–∏—Ç –∫—Ä–∞—Å–∏–≤–æ', r'—Å–º–æ—Ç—Ä–∏—Ç—Å—è –æ—Ç–ª–∏—á–Ω–æ', r'–≤–Ω–µ—à–Ω–µ –ø—Ä–∏—è—Ç–Ω–æ', r'—Å—Ç–∏–ª—å–Ω—ã–π', r'–≤—ã–≥–ª—è–¥–∏—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ'\n",
    "]\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "def compute_sentence_embeddings(sentences):\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–∞—Å–æ–∫ –∏ –∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "gratitude_emb = compute_sentence_embeddings(gratitude_phrases)\n",
    "common_emb = compute_sentence_embeddings(common_phrases)\n",
    "emotional_emb = compute_sentence_embeddings(emotional_phrases)\n",
    "short_emb = compute_sentence_embeddings(short_phrases)\n",
    "item_emb = compute_sentence_embeddings(item_phrases)\n",
    "task_emb = compute_sentence_embeddings(task_phrases)\n",
    "delivery_emb = compute_sentence_embeddings(delivery_phrases)\n",
    "emoji_text_emb = compute_sentence_embeddings(emoji_phrases)\n",
    "negative_condition_emb = compute_sentence_embeddings(negative_condition_phrases)\n",
    "positive_condition_emb = compute_sentence_embeddings(positive_condition_phrases)\n",
    "neutral_quality_emb = compute_sentence_embeddings(neutral_quality_phrases)\n",
    "confirmation_emb = compute_sentence_embeddings(confirmation_phrases)\n",
    "simple_statements_emb = compute_sentence_embeddings(simple_statements_phrases)\n",
    "quality_emb = compute_sentence_embeddings(quality_phrases)\n",
    "functionality_emb = compute_sentence_embeddings(functionality_phrases)\n",
    "price_emb = compute_sentence_embeddings(price_phrases)\n",
    "durability_emb = compute_sentence_embeddings(durability_phrases)\n",
    "appearance_emb = compute_sentence_embeddings(appearance_phrases)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –±–ª–∏–∑–æ—Å—Ç–∏ —Å –∫–∞–∂–¥–æ–π –º–∞—Å–∫–æ–π\n",
    "def is_similar_to_mask(key_thought, mask_emb):\n",
    "    key_emb = compute_sentence_embeddings([key_thought])\n",
    "    return np.max(cosine_similarity(key_emb, mask_emb)) > 0.65  # –ü–æ—Ä–æ–≥ –±–ª–∏–∑–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö –º—ã—Å–ª–µ–π –Ω–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –±–ª–∏–∑–æ—Å—Ç—å –∫ –∫–∞–∂–¥–æ–π –º–∞—Å–∫–µ\n",
    "final_result['is_similar_to_emoji'] = final_result['key_thought'].apply(lambda x: contains_emoji(x) or is_similar_to_mask(x, emoji_text_emb))\n",
    "final_result['is_similar_to_common'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, common_emb))\n",
    "final_result['is_similar_to_emotional'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, emotional_emb))\n",
    "final_result['is_similar_to_short'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, short_emb))\n",
    "final_result['is_similar_to_item'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, item_emb))\n",
    "final_result['is_similar_to_task'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, task_emb))\n",
    "final_result['is_similar_to_delivery'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, delivery_emb))\n",
    "final_result['is_similar_to_negative_condition'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, negative_condition_emb))\n",
    "final_result['is_similar_to_positive_condition'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, positive_condition_emb))\n",
    "final_result['is_similar_to_gratitude'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, gratitude_emb))\n",
    "final_result['is_similar_to_neutral_quality'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, neutral_quality_emb))\n",
    "final_result['is_similar_to_confirmation'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, confirmation_emb))\n",
    "final_result['is_similar_to_simple_statements'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, simple_statements_emb))\n",
    "final_result['is_similar_to_quality'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, quality_emb))\n",
    "final_result['is_similar_to_functionality'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, functionality_emb))\n",
    "final_result['is_similar_to_price'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, price_emb))\n",
    "final_result['is_similar_to_durability'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, durability_emb))\n",
    "final_result['is_similar_to_appearance'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, appearance_emb))\n",
    "\n",
    "# –£–¥–∞–ª–µ–Ω–∏–µ –ø—É—Å—Ç—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "final_result = final_result[final_result['cluster_sentences'].str.strip().astype(bool)]\n",
    "\n",
    "# –°–ª–æ–≤–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "exclusion_words = [\n",
    "    r'–æ—Ç–ª–∏—á–Ω—ã–π', r'—Ö–æ—Ä–æ—à–∏–π', r'—à–∏–∫–∞—Ä–Ω—ã–π', r'–æ—Ñ–∏–≥–µ–Ω–Ω—ã–π', r'–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã–π', r'–ø–æ—Ç—Ä—è—Å–∞—é—â–∏–π', r'–≤–µ–ª–∏–∫–æ–ª–µ–ø–Ω—ã–π', \n",
    "    r'–ø—Ä–µ–∫—Ä–∞—Å–Ω—ã–π', r'–∏–∑—É–º–∏—Ç–µ–ª—å–Ω—ã–π', r'—Ñ–∞–Ω—Ç–∞—Å—Ç–∏—á–µ—Å–∫–∏–π', r'—É–¥–∏–≤–∏—Ç–µ–ª—å–Ω—ã–π', r'–Ω–µ–≤–µ—Ä–æ—è—Ç–Ω—ã–π', r'–∑–∞—á—ë—Ç–Ω—ã–π', r'—Å—É–ø–µ—Ä—Å–∫–∏–π', \n",
    "    r'–∫–ª–∞—Å—Å–Ω—ã–π', r'–∫—Ä—É—Ç–æ–π', r'–ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å', r'–ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å', r'–ª—é–±–ª—é', r'–≤–æ—Å—Ö–∏—â—ë–Ω', \n",
    "    r'–¥–æ–≤–æ–ª–µ–Ω', r'–Ω–∞—Å–ª–∞–∂–¥–∞—é—Å—å', r'–ø–æ—Ä–∞–¥–æ–≤–∞–ª–æ'\n",
    "]\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "\n",
    "# –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤ –∏–∑ —Å–ø–∏—Å–∫–∞ exclusion_words\n",
    "lemmatized_exclusion_words = [lemmatize_text(word) for word in exclusion_words]\n",
    "exclusion_emb = compute_sentence_embeddings(lemmatized_exclusion_words)\n",
    "\n",
    "# –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –±–ª–∏–∑–æ—Å—Ç–∏\n",
    "def is_single_word_or_stop_word(key_thought):\n",
    "    words = re.findall(r'\\w+', key_thought)  # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ —Å–ª–æ–≤–∞\n",
    "    if len(words) == 1:\n",
    "        return True\n",
    "    if len(words) == 2 and words[1] in stop_words:\n",
    "        return True\n",
    "    if len(words) == 2 and re.match(r'[^\\w\\s]', words[1]):  # –ü—É–Ω–∫—Ç—É–∞—Ü–∏—è –∫–∞–∫ –≤—Ç–æ—Ä–æ–µ —Å–ª–æ–≤–æ\n",
    "        return True\n",
    "    if len(words) in [2, 3]:\n",
    "        lemmatized_key_thought = lemmatize_text(key_thought)\n",
    "        lemmatized_words = re.findall(r'\\w+', lemmatized_key_thought)\n",
    "        for word in lemmatized_words:\n",
    "            key_emb = compute_sentence_embeddings([word])\n",
    "            max_similarity = np.max(cosine_similarity(key_emb, exclusion_emb))\n",
    "            if max_similarity > 0.9:  # –ü–æ—Ä–æ–≥ –±–ª–∏–∑–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å\n",
    "                print(f\"–ë–ª–∏–∑–æ—Å—Ç—å - {max_similarity}. –ò—Å–∫–ª—é—á–∞–µ–º {key_thought}\")\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏\n",
    "final_result = final_result[~final_result['key_thought'].apply(is_single_word_or_stop_word)]\n",
    "\n",
    "# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, –≥–¥–µ –≤—Å–µ –º–∞—Å–∫–∏ False\n",
    "mask_false_clusters = (\n",
    "    ~final_result['is_similar_to_emoji'] &\n",
    "    ~final_result['is_similar_to_common'] &\n",
    "    ~final_result['is_similar_to_emotional'] &\n",
    "    ~final_result['is_similar_to_short'] &\n",
    "    ~final_result['is_similar_to_item'] &\n",
    "    ~final_result['is_similar_to_task'] &\n",
    "    ~final_result['is_similar_to_delivery'] &\n",
    "    ~final_result['is_similar_to_negative_condition'] &\n",
    "    ~final_result['is_similar_to_positive_condition'] &\n",
    "    ~final_result['is_similar_to_gratitude'] &\n",
    "    ~final_result['is_similar_to_neutral_quality'] &\n",
    "    ~final_result['is_similar_to_confirmation'] &\n",
    "    ~final_result['is_similar_to_simple_statements'] &\n",
    "    ~final_result['is_similar_to_quality'] &\n",
    "    ~final_result['is_similar_to_functionality'] &\n",
    "    ~final_result['is_similar_to_price'] &\n",
    "    ~final_result['is_similar_to_durability'] &\n",
    "    ~final_result['is_similar_to_appearance']\n",
    ")\n",
    "\n",
    "# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "df_false_clusters = final_result[mask_false_clusters]\n",
    "display(df_false_clusters[['product', 'cluster_sentences', 'key_thought', 'word_count']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_false_clusters[['cluster_sentences', 'key_thought', 'word_count']].to_csv(\"./reviews_keywords/clusters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Summarizing clusters: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62/62 [02:09<00:00,  2.09s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–ê –≤–æ—Ç –≤ —Ç–µ–º–Ω—ã—Ö –µ–∑–¥–∏—Ç—å –ø–æ —Å–ª–µ–ø—è—â–µ–π –æ—Ç —Å–æ–ª–Ω—Ü–∞ –¥–æ...</td>\n",
       "      <td>–í —Ç–µ–º–Ω—ã—Ö –æ—á–∫–∞—Ö —á—É—Ç—å –∫–æ–º—Ñ–æ—Ä—Ç–Ω–µ–µ –µ–∑–¥–∏—Ç—å –ø–æ —Å–ª–µ–ø—è...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–û–¥–Ω–æ —Å—Ç–µ–∫–ª–æ —Å–≤–µ—Ç–ª–æ–µ –¥—Ä—É–≥–æ–µ —á–µ—Ä–Ω–æ–µ –≤–æ–æ–±—â–µ —Ä–∞–∑–Ω—ã...</td>\n",
       "      <td>–û–¥–Ω–æ —Å—Ç–µ–∫–ª–æ —Å–≤–µ—Ç–ª–æ–µ, –¥—Ä—É–≥–æ–µ —á–µ—Ä–Ω–æ–µ...&lt;br&gt;–°—Ç–µ–∫–ª...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>–ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ | –î–µ—Ç—Å–∫–∏–µ | –ù—É –æ—á–µ–Ω—å ...</td>\n",
       "      <td>–ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ &lt;br&gt;&lt;br&gt;–ú–∞–ª—ã—à–∏ –æ—á–µ–Ω—å ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –æ–±–ª–æ–∂–∫–∞! | –ò –ø–æ —Ä–∞–∑–º–µ—Ä—É –∏–¥–µ–∞–ª—å–Ω–æ ...</td>\n",
       "      <td>–ù–µ–º–Ω–æ–≥–æ –Ω–µ –≤–ª–µ–∑ –≤ –æ–±–ª–æ–∂–∫—É, –ø—Ä–∏—à–ª–æ—Å—å –ø–æ–¥—Ä–µ–∑–∞—Ç—å ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç—É—Ä–Ω–∞—è, –ø–æ—ç—Ç–æ–º—É –ª–∞–º...</td>\n",
       "      <td>–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç—É—Ä–Ω–∞—è, –ø–æ—ç—Ç–æ–º—É –ª–∞–º...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>–ü–æ–∫—É–ø–∞–ª–∞ –ø–∞–ø–µ- —Ä—ã–±–∞–∫—É. | –ü–æ–∫—É–ø–∞–ª–∞ –º—É–∂—É. | –ë—Ä–∞–ª...</td>\n",
       "      <td>–ü–æ–∫—É–ø–∞–ª–∞ –ø–∞–ø–µ- —Ä—ã–±–∞–∫—É &lt;br&gt;–ü–æ–∫—É–ø–∞–ª–∞ –º—É–∂—É &lt;br&gt;–ë—ã...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>–û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ –¥–µ–¥—É—à–∫–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å | –§–æ—Ç–æ —Å–æ–æ—Ç–≤–µ...</td>\n",
       "      <td>–û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ, —à–∏—Ä–æ–∫–∏–µ, –º–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å –æ—á–∫–∏. &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>–û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ,—Å–≤–∞–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç –Ω–∞ 5+ .–ú–∏–Ω...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –Ω–µ –º–µ—à–∞—é—Ç –æ–±–∑–æ—Ä—É, –æ–Ω–∏ –∫–∞–∫–∏–µ —Ç–æ —Ä–∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>–û–ì–†–û–ú–ù–ê–Ø –ë–õ–ê–ì–û–î–ê–†–ù–û–°–¢–¨  –ó–ê –û–ß–ö–ò , –ú–£–ñ–£ –û–ß–ï–ù–¨ –ü...</td>\n",
       "      <td>–°–ø–∞—Å–∏–±–æ, –±—Ä–∞–ª–∞ –º—É–∂—É, —Å–∫–∞–∑–∞–ª –æ—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏. –í –¥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>–†–µ–∞–ª—å–Ω–æ —É–±–∏—Ä–∞—é—Ç –±–ª–∏–∫–∏ —Å –æ—Ç—Ä–∞–∂–∞—é—â–∏—Ö –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ...</td>\n",
       "      <td>–†–µ–∞–ª—å–Ω–æ —É–±–∏—Ä–∞—é—Ç –±–ª–∏–∫–∏ —Å –æ—Ç—Ä–∞–∂–∞—é—â–∏—Ö –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     cluster_sentences  \\\n",
       "0    –ê –≤–æ—Ç –≤ —Ç–µ–º–Ω—ã—Ö –µ–∑–¥–∏—Ç—å –ø–æ —Å–ª–µ–ø—è—â–µ–π –æ—Ç —Å–æ–ª–Ω—Ü–∞ –¥–æ...   \n",
       "1    –û–¥–Ω–æ —Å—Ç–µ–∫–ª–æ —Å–≤–µ—Ç–ª–æ–µ –¥—Ä—É–≥–æ–µ —á–µ—Ä–Ω–æ–µ –≤–æ–æ–±—â–µ —Ä–∞–∑–Ω—ã...   \n",
       "7    –ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ | –î–µ—Ç—Å–∫–∏–µ | –ù—É –æ—á–µ–Ω—å ...   \n",
       "10   –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –æ–±–ª–æ–∂–∫–∞! | –ò –ø–æ —Ä–∞–∑–º–µ—Ä—É –∏–¥–µ–∞–ª—å–Ω–æ ...   \n",
       "17   –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç—É—Ä–Ω–∞—è, –ø–æ—ç—Ç–æ–º—É –ª–∞–º...   \n",
       "..                                                 ...   \n",
       "244  –ü–æ–∫—É–ø–∞–ª–∞ –ø–∞–ø–µ- —Ä—ã–±–∞–∫—É. | –ü–æ–∫—É–ø–∞–ª–∞ –º—É–∂—É. | –ë—Ä–∞–ª...   \n",
       "249  –û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ –¥–µ–¥—É—à–∫–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å | –§–æ—Ç–æ —Å–æ–æ—Ç–≤–µ...   \n",
       "250  –û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ,—Å–≤–∞–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç –Ω–∞ 5+ .–ú–∏–Ω...   \n",
       "256  –û–ì–†–û–ú–ù–ê–Ø –ë–õ–ê–ì–û–î–ê–†–ù–û–°–¢–¨  –ó–ê –û–ß–ö–ò , –ú–£–ñ–£ –û–ß–ï–ù–¨ –ü...   \n",
       "263  –†–µ–∞–ª—å–Ω–æ —É–±–∏—Ä–∞—é—Ç –±–ª–∏–∫–∏ —Å –æ—Ç—Ä–∞–∂–∞—é—â–∏—Ö –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ...   \n",
       "\n",
       "                                               summary  \n",
       "0    –í —Ç–µ–º–Ω—ã—Ö –æ—á–∫–∞—Ö —á—É—Ç—å –∫–æ–º—Ñ–æ—Ä—Ç–Ω–µ–µ –µ–∑–¥–∏—Ç—å –ø–æ —Å–ª–µ–ø—è...  \n",
       "1    –û–¥–Ω–æ —Å—Ç–µ–∫–ª–æ —Å–≤–µ—Ç–ª–æ–µ, –¥—Ä—É–≥–æ–µ —á–µ—Ä–Ω–æ–µ...<br>–°—Ç–µ–∫–ª...  \n",
       "7    –ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ <br><br>–ú–∞–ª—ã—à–∏ –æ—á–µ–Ω—å ...  \n",
       "10   –ù–µ–º–Ω–æ–≥–æ –Ω–µ –≤–ª–µ–∑ –≤ –æ–±–ª–æ–∂–∫—É, –ø—Ä–∏—à–ª–æ—Å—å –ø–æ–¥—Ä–µ–∑–∞—Ç—å ...  \n",
       "17   –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç—É—Ä–Ω–∞—è, –ø–æ—ç—Ç–æ–º—É –ª–∞–º...  \n",
       "..                                                 ...  \n",
       "244  –ü–æ–∫—É–ø–∞–ª–∞ –ø–∞–ø–µ- —Ä—ã–±–∞–∫—É <br>–ü–æ–∫—É–ø–∞–ª–∞ –º—É–∂—É <br>–ë—ã...  \n",
       "249  –û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ, —à–∏—Ä–æ–∫–∏–µ, –º–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å –æ—á–∫–∏. <...  \n",
       "250  –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –Ω–µ –º–µ—à–∞—é—Ç –æ–±–∑–æ—Ä—É, –æ–Ω–∏ –∫–∞–∫–∏–µ —Ç–æ —Ä–∞...  \n",
       "256  –°–ø–∞—Å–∏–±–æ, –±—Ä–∞–ª–∞ –º—É–∂—É, —Å–∫–∞–∑–∞–ª –æ—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏. –í –¥...  \n",
       "263  –†–µ–∞–ª—å–Ω–æ —É–±–∏—Ä–∞—é—Ç –±–ª–∏–∫–∏ —Å –æ—Ç—Ä–∞–∂–∞—é—â–∏—Ö –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ...  \n",
       "\n",
       "[62 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (GPU –∏–ª–∏ CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ T5\n",
    "model_name = \"cointegrated/rut5-base-multitask\"  # –ú–æ–¥–µ–ª—å –¥–ª—è —Ä—É—Å—Å–∫–æ–π T5\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞—Å—Ç–∏\n",
    "def chunk_text(text, max_length=100):\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i + max_length]) for i in range(0, len(words), max_length)]\n",
    "    return chunks\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n",
    "def summarize_text(text):\n",
    "    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –ø–µ—Ä–µ–Ω–æ—Å –Ω–∞ GPU\n",
    "    inputs = tokenizer(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    \n",
    "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPU\n",
    "    summary_ids = model.generate(\n",
    "        inputs.input_ids, \n",
    "        max_length=150, \n",
    "        min_length=40, \n",
    "        length_penalty=4,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º penalty –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π\n",
    "        num_beams=16,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ beam –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "        repetition_penalty=3.0,  # –î–æ–±–∞–≤–ª—è–µ–º —à—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    # –ü–µ—Ä–µ–Ω–æ—Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ CPU –∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ —Å —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º\n",
    "def recursive_summarization(text, depth=2):\n",
    "    chunks = chunk_text(text, max_length=100)  # –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞—Å—Ç–∏, –∫–∞–∂–¥–∞—è –¥–æ 100 —Å–ª–æ–≤\n",
    "    summaries = [summarize_text(chunk) for chunk in chunks]\n",
    "    \n",
    "    # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–π –≥–ª—É–±–∏–Ω—ã —Ä–µ–∫—É—Ä—Å–∏–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "    if depth <= 1:\n",
    "        return ' '.join(summaries)\n",
    "    \n",
    "    # –í –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ —Å—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ–º –µ—â–µ —Ä–∞–∑ –Ω–∞ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–æ–π –≥–ª—É–±–∏–Ω–µ\n",
    "    return recursive_summarization(' '.join(summaries), depth - 1)\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –∫ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Ç–µ—Ä—É —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPU\n",
    "df_false_clusters['summary'] = [\n",
    "    recursive_summarization(text, depth=2) for text in tqdm(df_false_clusters['cluster_sentences'], desc=\"Summarizing clusters\")\n",
    "]\n",
    "\n",
    "# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏\n",
    "display(df_false_clusters[['cluster_sentences', 'summary']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'–•–æ—Ä–æ—à–∏–π –≥–µ—Ä–º–µ—Ç–∏–∫, –ø–æ–º–æ–≥. –•–æ—Ä–æ—à–∏–π –≥–µ—Ä–º–µ—Ç–∏–∫, –ø–æ–º–æ–≥. –•–æ—Ä–æ—à–∏–π –≥–µ—Ä–º–µ—Ç–∏–∫, –ø–æ–º–æ–≥. –•–æ—Ä–æ—à–∏–π –≥–µ—Ä–º–µ—Ç–∏–∫, –ø–æ–º–æ–≥. –•–æ—Ä–æ—à–∏–π –≥–µ—Ä–º–µ—Ç–∏–∫, –ø–æ–º–æ–≥.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞\n",
    "model_name = \"cointegrated/rut5-base-multitask\"  # –ú–æ–¥–µ–ª—å T5 –¥–ª—è –º—É–ª—å—Ç–∏—Ç–∞—Å–∫–∏–Ω–≥–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–æ–≤ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞\n",
    "def clean_text(text):\n",
    "    sentences = text.split('<br>')\n",
    "    cleaned_sentences = []\n",
    "    seen = set()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        if sentence not in seen:\n",
    "            cleaned_sentences.append(sentence)\n",
    "            seen.add(sentence)\n",
    "    \n",
    "    return ' '.join(cleaned_sentences)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º T5\n",
    "def correct_text(text):\n",
    "    inputs = tokenizer(\"correct: \" + text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    summary_ids = model.generate(inputs.input_ids, max_length=150, min_length=40, length_penalty=1.0, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞\n",
    "text = '–•–æ—Ä–æ—à–∏–π –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å, —á–∏—Å—Ç–∏–ª –¥—Ä–æ—Å—Å–µ–ª—å —Å—Ç–∞—Ä–æ–π –¢–æ–π–æ—Ç—ã, –æ—Ç–º—ã–≤–∞–µ—Ç –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ, —Å–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤—Ü—É. <br>–û—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ –æ—Ç–º—ã–≤–∞–µ—Ç –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏—è, –Ω–∞–≥–∞—Ä –•–æ—Ä–æ—à–∏–π –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å, –ø—Ä–µ—à—ë–ª —Ö–æ—Ä–æ—à–æ —É–ø–∞–∫–æ–≤–∞–Ω, —Å–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤—Ü—É <br>–•–æ—Ä–æ—à–∏–π –≥–µ—Ä–º–µ—Ç–∏–∫, –ø–æ–º–æ–≥. <br>–•–æ—Ä–æ—à–∏–π –≥–µ—Ä–º–µ—Ç–∏–∫, –ø–æ–º–æ–≥. <br>–û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä —Ä–µ–∫–æ–º–µ–Ω–¥—É—é'\n",
    "\n",
    "# –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –ø–æ–≤—Ç–æ—Ä–æ–≤\n",
    "cleaned_text = clean_text(text)\n",
    "\n",
    "# –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏\n",
    "final_text = correct_text(cleaned_text)\n",
    "final_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded_sorted[\"cluster_sentences\"].to_csv(\"./reviews_keywords/clusters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce69147fe48a4354a19c51e442d277ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'clusters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m key_phrases\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkey_phrases\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_key_phrases_from_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclusters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# –ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ñ—Ä–∞–∑–∞–º\u001b[39;00m\n\u001b[1;32m     54\u001b[0m key_phrases \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey_phrases\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:3161\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3156\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3157\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3158\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3159\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3160\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3161\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3162\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3163\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:3552\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3548\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3549\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3550\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3551\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3552\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3556\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3557\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3561\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:3421\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3420\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3421\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3423\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3424\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3425\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[15], line 50\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m key_phrases\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m batch: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey_phrases\u001b[39m\u001b[38;5;124m\"\u001b[39m: extract_key_phrases_from_clusters(\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclusters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)}, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# –ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ñ—Ä–∞–∑–∞–º\u001b[39;00m\n\u001b[1;32m     54\u001b[0m key_phrases \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey_phrases\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:271\u001b[0m, in \u001b[0;36mLazyDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 271\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys_to_format:\n\u001b[1;32m    273\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'clusters'"
     ]
    }
   ],
   "source": [
    "def filter_tokens(syntax_analysis):\n",
    "    # –û—Ç–∫–ª—é—á–∞–µ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "    filtered_tokens = [\n",
    "        token for token in syntax_analysis \n",
    "        if token[1] not in {\"PUNCT\", \"SPACE\"}  # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –∏ –ø—Ä–æ–±–µ–ª—ã\n",
    "        # –û—Ç–∫–ª—é—á–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –¥–ª–∏–Ω–µ\n",
    "    ]\n",
    "    \n",
    "    return filtered_tokens\n",
    "\n",
    "def extract_key_phrases_from_sentences(doc):\n",
    "    key_phrases = []\n",
    "    \n",
    "    for sent in doc.sents:\n",
    "        syntax_analysis = [(token.text, token.pos_, token.dep_, token.head.text) for token in sent]\n",
    "        filtered_tokens = filter_tokens(syntax_analysis)\n",
    "        phrase = []\n",
    "\n",
    "        for i, token in enumerate(filtered_tokens):\n",
    "            if token[1] in {\"NOUN\", \"VERB\"}:  # –°—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ –∏–ª–∏ –≥–ª–∞–≥–æ–ª\n",
    "                if phrase:\n",
    "                    key_phrases.append(\" \".join(phrase))\n",
    "                    phrase = []\n",
    "                phrase.append(token[0])\n",
    "            elif token[1] in {\"ADJ\", \"ADV\"}:  # –ü—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ, –Ω–∞—Ä–µ—á–∏—è\n",
    "                if phrase:\n",
    "                    phrase.append(token[0])\n",
    "\n",
    "            # –ï—Å–ª–∏ –∫–æ–Ω–µ—Ü —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —á–∞—Å—Ç—å —Ä–µ—á–∏ –Ω–µ —Å–≤—è–∑–∞–Ω–∞ —Å —Ç–µ–∫—É—â–µ–π —Ñ—Ä–∞–∑–æ–π\n",
    "            if i == len(filtered_tokens) - 1 or filtered_tokens[i+1][1] not in {\"ADJ\", \"ADV\", \"ADP\", \"CCONJ\", \"SCONJ\", \"PART\"}:\n",
    "                if phrase:\n",
    "                    key_phrases.append(\" \".join(phrase))\n",
    "                    phrase = []\n",
    "    key_phrases = [phrase for phrase in key_phrases if len(phrase.split()) > 1 and len(phrase.strip()) > 2]\n",
    "\n",
    "    return \" \".join(key_phrases)\n",
    "\n",
    "\n",
    "def extract_key_phrases_from_clusters(clusters):\n",
    "    key_phrases = []\n",
    "    for cluster in clusters:\n",
    "        cluster_key_phrases = []\n",
    "        for sentences in cluster:  # –¢–∞–∫ –∫–∞–∫ cluster —Ç–µ–ø–µ—Ä—å —Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤\n",
    "            doc = nlp(sentences)\n",
    "            cluster_key_phrases.append(extract_key_phrases_from_sentences(doc))\n",
    "        key_phrases.append(\" \".join(cluster_key_phrases))  # –°–æ–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã –∏–∑ –æ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞ –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É\n",
    "    return key_phrases\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "dataset = dataset.map(lambda batch: {\"key_phrases\": extract_key_phrases_from_clusters(batch['clusters'])}, batched=True, batch_size=8)\n",
    "\n",
    "\n",
    "# –ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ñ—Ä–∞–∑–∞–º\n",
    "key_phrases = dataset['key_phrases']\n",
    "phrase_freq = Counter(key_phrases)\n",
    "\n",
    "# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "print(\"–ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑ (–ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –±–ª–∏–∑–æ—Å—Ç–∏):\")\n",
    "print(phrase_freq.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./reviews_keywords/temp_spacy.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
