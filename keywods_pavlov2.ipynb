{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –≠—Ç–∞–ø 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf.pandas  # –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ cuDF –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏—è –µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "cudf.pandas.install()  # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ cuDF –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –¥–ª—è pandas\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–§–∞–π–ª '/workspace/wildberries_reviews.csv' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gdown\n",
    "\n",
    "def download_file_if_not_exists(file_url, output_path):\n",
    "    \"\"\"–°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª —Å Google Drive, –µ—Å–ª–∏ –æ–Ω –µ—â—ë –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.\"\"\"\n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–∞\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"–§–∞–π–ª '{output_path}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.\")\n",
    "    else:\n",
    "        print(f\"–§–∞–π–ª '{output_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É...\")\n",
    "        gdown.download(file_url, output_path, quiet=False)\n",
    "        print(f\"–§–∞–π–ª '{output_path}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.\")\n",
    "\n",
    "# –£–∫–∞–∑—ã–≤–∞–µ–º URL –∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É\n",
    "# file_url = 'https://drive.google.com/uc?id=15pofNbomaoUap41Rcn1uNGeiJIqFd2qe'\n",
    "file_url = 'https://drive.google.com/uc?id=1alondqI-2IHo__mYU7KQz4Ip8ytYGHXg'\n",
    "output_file_name = 'wildberries_reviews.csv'  # –£–∫–∞–∂–∏—Ç–µ —Ä–µ–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞, –∫–æ—Ç–æ—Ä–æ–µ —Ö–æ—Ç–∏—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å\n",
    "output_path = os.path.join(os.getcwd(), output_file_name)  # –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É\n",
    "\n",
    "download_file_if_not_exists(file_url, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corrected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>331634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>–ú–∞–ª–æ –º–µ—Ä–∏—Ç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       corrected_text\n",
       "count          517652\n",
       "unique         331634\n",
       "top        –ú–∞–ª–æ –º–µ—Ä–∏—Ç\n",
       "freq              128"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å CSV —Ñ–∞–π–ª–∞–º–∏\n",
    "folder_path = './reviews_keywords/corrected_reviews'\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# –ß–∏—Ç–∞–µ–º –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ CSV —Ñ–∞–π–ª—ã –≤ –æ–¥–∏–Ω –¥–∞—Ç–∞—Ñ—Ä–µ–π–º\n",
    "df_list = [pd.read_csv(os.path.join(folder_path, file), index_col=\"id\") for file in csv_files]\n",
    "combined_df = pd.concat(df_list, ignore_index=False)\n",
    "\n",
    "combined_df.index = combined_df.index - 1\n",
    "combined_df = pd.concat([pd.read_csv(\"wildberries_reviews.csv\")[[\"corrected_text\"]], combined_df], ignore_index=False)\n",
    "# –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "combined_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corrected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–í—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ, –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169793</th>\n",
       "      <td>–û—á–µ–Ω—å —Å–≤–µ–∂–∞—è –∏ –≤–∫—É—Å–Ω–∞—è. –ù–µ –æ—á–µ–Ω—å —Å–ª–∞–¥–∫–∞—è, –º—è–≥–∫...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169798</th>\n",
       "      <td>–ó–∏–º–æ–π –±—ã–ª–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Ö—É—Ä–º–∞, —Å–µ–π—á–∞—Å –º—É–∂ –ø–æ–ø—Ä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169810</th>\n",
       "      <td>–•—É—Ä–º–∞ –≤–∫—É—Å–Ω–∞—è, —Å–≤–µ–∂–∞—è, –æ—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å. –†–µ–∫–æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169829</th>\n",
       "      <td>–•—É—Ä–º–∞ –ø—Ä–æ—Å—Ç–æ —Å—É–ø–µ—Ä! –°–≤–µ–∂–∞—è, –Ω–∏–∫–∞–∫–æ–≥–æ —Å–∞—Ö–∞—Ä–∞, –∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169876</th>\n",
       "      <td>–°—É–ø–µ—Ä—Å–∫–∏–π –ø—Ä–æ–¥—É–∫—Ç, –æ—Ç–ª–∏—á–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞, —Ö–æ—Ä–æ—à–æ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517652 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            corrected_text\n",
       "0                                         –†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.\n",
       "1        –ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...\n",
       "2        –ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...\n",
       "3        –õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...\n",
       "4        –í—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ, –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑...\n",
       "...                                                    ...\n",
       "2169793  –û—á–µ–Ω—å —Å–≤–µ–∂–∞—è –∏ –≤–∫—É—Å–Ω–∞—è. –ù–µ –æ—á–µ–Ω—å —Å–ª–∞–¥–∫–∞—è, –º—è–≥–∫...\n",
       "2169798  –ó–∏–º–æ–π –±—ã–ª–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Ö—É—Ä–º–∞, —Å–µ–π—á–∞—Å –º—É–∂ –ø–æ–ø—Ä...\n",
       "2169810  –•—É—Ä–º–∞ –≤–∫—É—Å–Ω–∞—è, —Å–≤–µ–∂–∞—è, –æ—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å. –†–µ–∫–æ...\n",
       "2169829  –•—É—Ä–º–∞ –ø—Ä–æ—Å—Ç–æ —Å—É–ø–µ—Ä! –°–≤–µ–∂–∞—è, –Ω–∏–∫–∞–∫–æ–≥–æ —Å–∞—Ö–∞—Ä–∞, –∞...\n",
       "2169876  –°—É–ø–µ—Ä—Å–∫–∏–π –ø—Ä–æ–¥—É–∫—Ç, –æ—Ç–ª–∏—á–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞, —Ö–æ—Ä–æ—à–æ ...\n",
       "\n",
       "[517652 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_full_text</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–í—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ, –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    review_full_text  review_rating  \\\n",
       "0                                   –†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.              5   \n",
       "1  –ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...              5   \n",
       "2  –ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...              5   \n",
       "3  –õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...              5   \n",
       "4  –í—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ, –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑...              5   \n",
       "\n",
       "                                             product             category  \\\n",
       "0  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "1  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "2  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "3  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "4  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.wildberries.ru/catalog/162315454/f...  \n",
       "1  https://www.wildberries.ru/catalog/162315454/f...  \n",
       "2  https://www.wildberries.ru/catalog/162315454/f...  \n",
       "3  https://www.wildberries.ru/catalog/162315454/f...  \n",
       "4  https://www.wildberries.ru/catalog/162315454/f...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_big = pd.read_csv(\"wildberries_reviews.csv.gz\", compression=\"gzip\").drop(\"Unnamed: 0\", axis=1)\n",
    "df_raw_big.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.937733e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.592586e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.036269e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_rating\n",
       "count   2.937733e+06\n",
       "mean    4.592586e+00\n",
       "std     1.036269e+00\n",
       "min     1.000000e+00\n",
       "25%     5.000000e+00\n",
       "50%     5.000000e+00\n",
       "75%     5.000000e+00\n",
       "max     5.000000e+00"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = combined_df.merge(df_raw_big, left_index=True, right_index=True, how='right')\n",
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['corrected_text'] = result['corrected_text'].fillna(result['review_full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_full_text</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>product</th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "      <th>corrected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>–†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>–ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>–ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>–õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–í—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ, –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑...</td>\n",
       "      <td>5</td>\n",
       "      <td>Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...</td>\n",
       "      <td>/–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad</td>\n",
       "      <td>https://www.wildberries.ru/catalog/162315454/f...</td>\n",
       "      <td>–í—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ, –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    review_full_text  review_rating  \\\n",
       "0                                   –†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.              5   \n",
       "1  –ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...              5   \n",
       "2  –ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...              5   \n",
       "3  –õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...              5   \n",
       "4  –í—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ, –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑...              5   \n",
       "\n",
       "                                             product             category  \\\n",
       "0  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "1  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "2  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "3  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "4  Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 13...  /–ê–≤—Ç–æ—Ç–æ–≤–∞—Ä—ã/OFFroad   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "1  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "2  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "3  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "4  https://www.wildberries.ru/catalog/162315454/f...   \n",
       "\n",
       "                                      corrected_text  \n",
       "0                                   –†–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ.  \n",
       "1  –ü—Ä–∏—à–ª–æ –±—ã—Å—Ç—Ä–æ, –≤—Å–µ —Ü–µ–ª–æ–µ –Ω–∞ –≤–∏–¥. –ó–∞–≤—Ç—Ä–∞ –±—É–¥—É –∏...  \n",
       "2  –ö—É–ø–∏–ª –Ω–∞ –∫–≤–∞–¥—Ä –¥–ª—è –ø–æ–¥–Ω—è—Ç–∏—è –æ—Ç–≤–∞–ª–∞, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ ...  \n",
       "3  –õ–µ–±—ë–¥–∫–∞ —Ö–æ—Ä–æ—à–∞—è. –ù–æ –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏ —Å–ª–æ–≤–∞ –ø—Ä–æ ...  \n",
       "4  –í—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ, –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ 5 –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç–æ–ª–±—Ü–µ 'product'\n",
    "result_limited = result.groupby('product').head(10).reset_index(drop=True)[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3526cde97ddd4182952ba84a71b57a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75913fe94dc443f394de41bb32c9cefa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1389 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ –æ—Ç –°–±–µ—Ä–±–∞–Ω–∫–∞\n",
    "tokenizer = AutoTokenizer.from_pretrained('sberbank-ai/sbert_large_nlu_ru')\n",
    "model = AutoModel.from_pretrained('sberbank-ai/sbert_large_nlu_ru').to(device)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ SpaCy\n",
    "nlp = spacy.load(\"ru_core_news_lg\")\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ pandas DataFrame\n",
    "df_raw = pd.read_csv(\"wildberries_reviews.csv\", nrows=30000)\n",
    "# df = df_raw[-500:-1]  # –û—Ç–±–æ—Ä 500 –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "df = result_limited\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ pandas DataFrame –≤ Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # –°–Ω–∞—á–∞–ª–∞ –∑–∞–º–µ–Ω—è–µ–º –≤—Å–µ \\n, \\r, \\t –Ω–∞ –ø—Ä–æ–±–µ–ª\n",
    "    text = re.sub(r'[\\n\\r\\t]+', ' ', text)\n",
    "    \n",
    "    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "\n",
    "    # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª –∏ —Ç–æ—á–∫—É (–µ—Å–ª–∏ —Ç–æ—á–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)\n",
    "    text = re.sub(r'(?<!\\.)\\s*\\.\\s*', '. ', text)  # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –ø–æ—Å–ª–µ –∑–∞–º–µ–Ω—ã –µ—Å—Ç—å —Ç–æ—á–∫–∞ –∏ –ø—Ä–æ–±–µ–ª\n",
    "    text = re.sub(r'\\s*\\.\\s*(?!\\.)', ' ', text)  # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–µ—Ä–µ–¥ —Ç–æ—á–∫–æ–π, –µ—Å–ª–∏ —Ç–æ—á–∫–∞ –µ—Å—Ç—å\n",
    "    \n",
    "    # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è —Ç–æ—á–∫–æ–π, —É–±–∏—Ä–∞–µ–º –µ—ë\n",
    "    text = re.sub(r'\\s*\\.$', '', text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n",
    "def split_into_sentences(text):\n",
    "    doc = nlp(clean_text(text))\n",
    "    return [sent.text for sent in doc.sents]\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –æ—Ç–∑—ã–≤–æ–≤ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n",
    "def split_reviews_into_sentences(batch):\n",
    "    batch['sentences'] = [split_into_sentences(text) for text in batch['corrected_text']]\n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(split_reviews_into_sentences, batched=True, batch_size=8)\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º Dataset –æ–±—Ä–∞—Ç–Ω–æ –≤ pandas DataFrame\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "# –í—ã–ø–æ–ª–Ω–∏–º explode –ø–æ —Å—Ç–æ–ª–±—Ü—É —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏\n",
    "df_exploded = df.explode('sentences').reset_index(drop=True)\n",
    "\n",
    "# –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ —Å—Ç–æ–ª–±—Ü—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ—è–≤–∏–ª–∏—Å—å –ø–æ—Å–ª–µ explode\n",
    "df_exploded = df_exploded.drop(columns=[col for col in df_exploded.columns if col.startswith('__index_level_')])\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º DataFrame –æ–±—Ä–∞—Ç–Ω–æ –≤ Hugging Face Dataset\n",
    "dataset_exploded = Dataset.from_pandas(df_exploded)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n",
    "def compute_sentence_embeddings(sentences):\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ explode\n",
    "def compute_embeddings_after_explode(batch):\n",
    "    sentences = batch['sentences']\n",
    "    embeddings = compute_sentence_embeddings(sentences)\n",
    "    batch['sentence_embeddings'] = embeddings\n",
    "    return batch\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "dataset = dataset_exploded.map(compute_embeddings_after_explode, batched=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 310/310 [00:00<00:00, 565.52it/s]\n",
      "–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–¥—É–∫—Ç–æ–≤: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 107/107 [00:29<00:00,  3.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3TON / –û—á–∏—Å—Ç–∏—Ç–µ–ª—å –∫–∞—Ä–±—é—Ä–∞—Ç–æ—Ä–∞ –∏ –¥—Ä–æ—Å—Å–µ–ª—å–Ω–æ–π –∑–∞...</td>\n",
       "      <td>–ö—Ä—ã—à–∫–∞ –Ω–∞ –æ—á–∏—Å—Ç–∏—Ç–µ–ª–µ —Ä–∞—Å–∫–æ–ª–æ—Ç–∞ –∏ –¥–µ—Ä–∂–∏—Ç—Å—è —Ç–æ–ª—å...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3TON / –û—á–∏—Å—Ç–∏—Ç–µ–ª—å –∫–∞—Ä–±—é—Ä–∞—Ç–æ—Ä–∞ –∏ –¥—Ä–æ—Å—Å–µ–ª—å–Ω–æ–π –∑–∞...</td>\n",
       "      <td>–û–∫</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3TON / –û—á–∏—Å—Ç–∏—Ç–µ–ª—å –∫–∞—Ä–±—é—Ä–∞—Ç–æ—Ä–∞ –∏ –¥—Ä–æ—Å—Å–µ–ª—å–Ω–æ–π –∑–∞...</td>\n",
       "      <td>–ü—Ä–∏—à–ª–æ –≤–æ–≤—Ä–µ–º—è, –æ—Ç–ª–∏—á–Ω–æ —É–ø–∞–∫–æ–≤–∞–Ω–Ω—ã–º –ú—É–∂ —Å–∫–∞–∑–∞–ª...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3TON / –û—á–∏—Å—Ç–∏—Ç–µ–ª—å –∫–∞—Ä–±—é—Ä–∞—Ç–æ—Ä–∞ –∏ –¥—Ä–æ—Å—Å–µ–ª—å–Ω–æ–π –∑–∞...</td>\n",
       "      <td>–¢–æ–≤–∞—Ä –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–ª–∏ –ó–∞ –≤—Å–∫—Ä—ã—Ç—É—é —É–ø–∞–∫–æ–≤–∫—É —Å...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3TON / –û—á–∏—Å—Ç–∏—Ç–µ–ª—å –∫–∞—Ä–±—é—Ä–∞—Ç–æ—Ä–∞ –∏ –¥—Ä–æ—Å—Å–µ–ª—å–Ω–æ–π –∑–∞...</td>\n",
       "      <td>–£–ø–∞–∫–æ–≤–∞–Ω–æ –≤ –∫–æ—Ä–æ–±–∫—É –≤—Å–µ —Ü–µ–ª–æ–µ –ø—Ä–∏–µ—Ö–∞–ª–æ, –æ—Ç–ª–∏—á–Ω...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>–§—Ä–µ–≥–∞—Ç –õ–∏—Ñ—Ç –ü–æ–¥–≤–µ—Å–∫–∞ / –õ–∏—Ñ—Ç –∫–æ–º–ø–ª–µ–∫—Ç —Ä–µ—Å—Å–æ—Ä—ã –ö...</td>\n",
       "      <td>–í—Å–µ –æ—Ç–ª–∏—á–Ω–æ, –ø–æ–¥–æ—à–ª–∏ –±–µ–∑ –ø—Ä–æ–±–ª–µ–º!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>–§—Ä–µ–≥–∞—Ç –õ–∏—Ñ—Ç –ü–æ–¥–≤–µ—Å–∫–∞ / –õ–∏—Ñ—Ç –∫–æ–º–ø–ª–µ–∫—Ç —Ä–µ—Å—Å–æ—Ä—ã –ö...</td>\n",
       "      <td>–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—é!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>–§—Ä–µ–≥–∞—Ç –õ–∏—Ñ—Ç –ü–æ–¥–≤–µ—Å–∫–∞ / –õ–∏—Ñ—Ç –∫–æ–º–ø–ª–µ–∫—Ç —Ä–µ—Å—Å–æ—Ä—ã –ö...</td>\n",
       "      <td>–ü—Ä–∏—à–ª–∏ –∫–∞—á–µ—Å—Ç–≤–æ üî•–ø–æ–∫–∞ –µ—â—ë –Ω–µ —Å—Ç–∞–≤–∏–ª</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>–§—Ä–µ–≥–∞—Ç –õ–∏—Ñ—Ç –ü–æ–¥–≤–µ—Å–∫–∞ / –õ–∏—Ñ—Ç –∫–æ–º–ø–ª–µ–∫—Ç —Ä–µ—Å—Å–æ—Ä—ã –ö...</td>\n",
       "      <td>–í—Å–µ –≤—Å—Ç–∞–ª–æ –±–µ–∑ –ø—Ä–æ–±–ª–µ–º, —É–∞–∑ –ø–æ–¥–Ω—è–ª—Å—è –Ω–∞ 3 —Å–º –ö...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>–§—Ä–µ–≥–∞—Ç –õ–∏—Ñ—Ç –ü–æ–¥–≤–µ—Å–∫–∞ / –õ–∏—Ñ—Ç –∫–æ–º–ø–ª–µ–∫—Ç —Ä–µ—Å—Å–æ—Ä—ã –ö...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1389 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                product  \\\n",
       "0     3TON / –û—á–∏—Å—Ç–∏—Ç–µ–ª—å –∫–∞—Ä–±—é—Ä–∞—Ç–æ—Ä–∞ –∏ –¥—Ä–æ—Å—Å–µ–ª—å–Ω–æ–π –∑–∞...   \n",
       "1     3TON / –û—á–∏—Å—Ç–∏—Ç–µ–ª—å –∫–∞—Ä–±—é—Ä–∞—Ç–æ—Ä–∞ –∏ –¥—Ä–æ—Å—Å–µ–ª—å–Ω–æ–π –∑–∞...   \n",
       "2     3TON / –û—á–∏—Å—Ç–∏—Ç–µ–ª—å –∫–∞—Ä–±—é—Ä–∞—Ç–æ—Ä–∞ –∏ –¥—Ä–æ—Å—Å–µ–ª—å–Ω–æ–π –∑–∞...   \n",
       "3     3TON / –û—á–∏—Å—Ç–∏—Ç–µ–ª—å –∫–∞—Ä–±—é—Ä–∞—Ç–æ—Ä–∞ –∏ –¥—Ä–æ—Å—Å–µ–ª—å–Ω–æ–π –∑–∞...   \n",
       "4     3TON / –û—á–∏—Å—Ç–∏—Ç–µ–ª—å –∫–∞—Ä–±—é—Ä–∞—Ç–æ—Ä–∞ –∏ –¥—Ä–æ—Å—Å–µ–ª—å–Ω–æ–π –∑–∞...   \n",
       "...                                                 ...   \n",
       "1384  –§—Ä–µ–≥–∞—Ç –õ–∏—Ñ—Ç –ü–æ–¥–≤–µ—Å–∫–∞ / –õ–∏—Ñ—Ç –∫–æ–º–ø–ª–µ–∫—Ç —Ä–µ—Å—Å–æ—Ä—ã –ö...   \n",
       "1385  –§—Ä–µ–≥–∞—Ç –õ–∏—Ñ—Ç –ü–æ–¥–≤–µ—Å–∫–∞ / –õ–∏—Ñ—Ç –∫–æ–º–ø–ª–µ–∫—Ç —Ä–µ—Å—Å–æ—Ä—ã –ö...   \n",
       "1386  –§—Ä–µ–≥–∞—Ç –õ–∏—Ñ—Ç –ü–æ–¥–≤–µ—Å–∫–∞ / –õ–∏—Ñ—Ç –∫–æ–º–ø–ª–µ–∫—Ç —Ä–µ—Å—Å–æ—Ä—ã –ö...   \n",
       "1387  –§—Ä–µ–≥–∞—Ç –õ–∏—Ñ—Ç –ü–æ–¥–≤–µ—Å–∫–∞ / –õ–∏—Ñ—Ç –∫–æ–º–ø–ª–µ–∫—Ç —Ä–µ—Å—Å–æ—Ä—ã –ö...   \n",
       "1388  –§—Ä–µ–≥–∞—Ç –õ–∏—Ñ—Ç –ü–æ–¥–≤–µ—Å–∫–∞ / –õ–∏—Ñ—Ç –∫–æ–º–ø–ª–µ–∫—Ç —Ä–µ—Å—Å–æ—Ä—ã –ö...   \n",
       "\n",
       "                                               sentence  label  \n",
       "0     –ö—Ä—ã—à–∫–∞ –Ω–∞ –æ—á–∏—Å—Ç–∏—Ç–µ–ª–µ —Ä–∞—Å–∫–æ–ª–æ—Ç–∞ –∏ –¥–µ—Ä–∂–∏—Ç—Å—è —Ç–æ–ª—å...      1  \n",
       "1                                                    –û–∫      0  \n",
       "2     –ü—Ä–∏—à–ª–æ –≤–æ–≤—Ä–µ–º—è, –æ—Ç–ª–∏—á–Ω–æ —É–ø–∞–∫–æ–≤–∞–Ω–Ω—ã–º –ú—É–∂ —Å–∫–∞–∑–∞–ª...      0  \n",
       "3     –¢–æ–≤–∞—Ä –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–ª–∏ –ó–∞ –≤—Å–∫—Ä—ã—Ç—É—é —É–ø–∞–∫–æ–≤–∫—É —Å...      0  \n",
       "4     –£–ø–∞–∫–æ–≤–∞–Ω–æ –≤ –∫–æ—Ä–æ–±–∫—É –≤—Å–µ —Ü–µ–ª–æ–µ –ø—Ä–∏–µ—Ö–∞–ª–æ, –æ—Ç–ª–∏—á–Ω...      0  \n",
       "...                                                 ...    ...  \n",
       "1384                  –í—Å–µ –æ—Ç–ª–∏—á–Ω–æ, –ø–æ–¥–æ—à–ª–∏ –±–µ–∑ –ø—Ä–æ–±–ª–µ–º!      0  \n",
       "1385                            –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—é!      0  \n",
       "1386                –ü—Ä–∏—à–ª–∏ –∫–∞—á–µ—Å—Ç–≤–æ üî•–ø–æ–∫–∞ –µ—â—ë –Ω–µ —Å—Ç–∞–≤–∏–ª      1  \n",
       "1387  –í—Å–µ –≤—Å—Ç–∞–ª–æ –±–µ–∑ –ø—Ä–æ–±–ª–µ–º, —É–∞–∑ –ø–æ–¥–Ω—è–ª—Å—è –Ω–∞ 3 —Å–º –ö...      0  \n",
       "1388                                   –•–æ—Ä–æ—à–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞      1  \n",
       "\n",
       "[1389 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ –≤ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–µ Hugging Face\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (GPU –∏–ª–∏ CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ –æ—Ç –°–±–µ—Ä–±–∞–Ω–∫–∞\n",
    "tokenizer = AutoTokenizer.from_pretrained('sberbank-ai/sbert_large_nlu_ru')\n",
    "model = AutoModel.from_pretrained('sberbank-ai/sbert_large_nlu_ru').to(device)\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "logging.basicConfig(filename='./reviews_keywords/clustering.log', \n",
    "                    level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ spaCy –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞\n",
    "nlp = spacy.load(\"ru_core_news_lg\")\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º spaCy\n",
    "def lemmatize_sentences(sentences):\n",
    "    lemmatized_sentences = []\n",
    "    for doc in tqdm(nlp.pipe(sentences, batch_size=32, n_process=-1), total=len(sentences), desc=\"–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è\"):\n",
    "        lemmatized_sentences.append(\" \".join([token.lemma_ for token in doc]))\n",
    "    return lemmatized_sentences\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π\n",
    "def compute_sentence_embeddings(sentences):\n",
    "    if not sentences:\n",
    "        return np.array([])  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤, –µ—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø—É—Å—Ç\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–∏–≤—è–∑–∫–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∫ –º–∞—Å–∫–∞–º —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –º–µ—Ç–∫–∞–º–∏\n",
    "def assign_to_masks(sentences, mask_embeddings, mask_names, threshold=0.65):\n",
    "    labeled_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_emb = compute_sentence_embeddings([sentence])\n",
    "        similarities = [np.max(cosine_similarity(sentence_emb, mask_emb)) for mask_emb in mask_embeddings]\n",
    "        max_similarity = np.max(similarities)\n",
    "        best_mask_index = np.argmax(similarities)\n",
    "\n",
    "        if max_similarity > threshold:\n",
    "            mask_name = mask_names[best_mask_index]\n",
    "            logging.info(f\"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ '{sentence}' –ø—Ä–∏–≤—è–∑–∞–Ω–æ –∫ –º–∞—Å–∫–µ '{mask_name}' —Å –ø–æ—Ö–æ–∂–µ—Å—Ç—å—é {max_similarity:.2f}\")\n",
    "            labeled_sentences.append((sentence, 0))  # –ü—Ä–∏–≤—è–∑–∞–Ω–æ –∫ –º–∞—Å–∫–µ, –º–µ—Ç–∫–∞ 0\n",
    "        else:\n",
    "            logging.info(f\"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ '{sentence}' –Ω–µ –ø—Ä–∏–≤—è–∑–∞–Ω–æ –Ω–∏ –∫ –æ–¥–Ω–æ–π –º–∞—Å–∫–µ\")\n",
    "            labeled_sentences.append((sentence, 1))  # –ù–µ –ø—Ä–∏–≤—è–∑–∞–Ω–æ –∫ –º–∞—Å–∫–µ, –º–µ—Ç–∫–∞ 1\n",
    "\n",
    "    return labeled_sentences\n",
    "\n",
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö —Ñ—Ä–∞–∑\n",
    "def classify_short_sentences(sentences, mask_words, min_words=2, max_words=4):\n",
    "    short_sentences = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        if min_words <= len(words) <= max_words:\n",
    "            match_count = sum(1 for word in words if word in mask_words)\n",
    "            if match_count > 0:\n",
    "                short_sentences.append(sentence)\n",
    "        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —É—Å–ª–æ–≤–∏–µ –¥–ª—è —Ñ—Ä–∞–∑ —Ç–∏–ø–∞ \"–û—á–∫–∏ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å\"\n",
    "        if \"–ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å\" in sentence or \"–Ω–µ–ø–ª–æ—Ö–∏–µ\" in sentence or \"–æ—Ç–ª–∏—á–Ω—ã–µ\" in sentence:\n",
    "            short_sentences.append(sentence)\n",
    "    \n",
    "    return short_sentences\n",
    "\n",
    "# –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ –∏ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º\n",
    "def process_reviews(df_exploded, mask_embeddings, mask_names, mask_words, threshold=0.6, eps=0.25, min_samples=3):\n",
    "    final_result = pd.DataFrame()\n",
    "\n",
    "    # tqdm –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º\n",
    "    for product_name, group in tqdm(df_exploded.groupby('product'), desc=\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–¥—É–∫—Ç–æ–≤\"):\n",
    "        all_sentences = group['sentences'].tolist()\n",
    "\n",
    "        # –ü—Ä–æ–ø—É—Å–∫, –µ—Å–ª–∏ –Ω–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
    "        if not all_sentences:\n",
    "            logging.info(f\"–ü—Ä–æ–ø—É—Å–∫ –ø—Ä–æ–¥—É–∫—Ç–∞ {product_name}, —Ç–∞–∫ –∫–∞–∫ –Ω–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.\")\n",
    "            continue\n",
    "\n",
    "        # –ü—Ä–∏–≤—è–∑–∫–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∫ –º–∞—Å–∫–∞–º –∏ –ø—Ä–∏—Å–≤–æ–µ–Ω–∏–µ –º–µ—Ç–æ–∫\n",
    "        labeled_sentences = assign_to_masks(all_sentences, mask_embeddings, mask_names, threshold)\n",
    "\n",
    "        # –û—Ç–¥–µ–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –º–µ—Ç–æ–∫ –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
    "        sentences, labels = zip(*labeled_sentences)\n",
    "\n",
    "        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö —Ñ—Ä–∞–∑\n",
    "        short_sentences = classify_short_sentences(sentences, mask_words)\n",
    "        short_labeled_sentences = [(sentence, 2) for sentence in short_sentences]\n",
    "\n",
    "        # –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ (—á—Ç–æ–±—ã –æ–Ω–∏ –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–ª–∏—Å—å)\n",
    "        filtered_sentences_labels = [(s, l) for s, l in zip(sentences, labels) if s not in short_sentences]\n",
    "\n",
    "        # Check if filtered_sentences_labels is empty before unpacking\n",
    "        if filtered_sentences_labels:\n",
    "            sentences, labels = zip(*filtered_sentences_labels)\n",
    "        else:\n",
    "            sentences, labels = [], []\n",
    "\n",
    "        # Adding short labeled sentences to the DataFrame\n",
    "        df_labels = pd.DataFrame({\n",
    "            'product': product_name,\n",
    "            'sentence': list(sentences) + [s for s, l in short_labeled_sentences],\n",
    "            'label': list(labels) + [l for s, l in short_labeled_sentences]\n",
    "        })\n",
    "\n",
    "        final_result = pd.concat([final_result, df_labels], ignore_index=True)\n",
    "\n",
    "    return final_result\n",
    "\n",
    "\n",
    "# –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –º–∞—Å–æ–∫\n",
    "def prepare_mask_embeddings(mask_phrases):\n",
    "    lemmatized_masks = lemmatize_sentences(mask_phrases)\n",
    "    return compute_sentence_embeddings(lemmatized_masks)\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö —Å–ª–æ–≤ –∏–∑ –º–∞—Å–æ–∫\n",
    "def create_mask_words(mask_phrases):\n",
    "    all_words = []\n",
    "    for phrase in mask_phrases:\n",
    "        all_words.extend(phrase.split())\n",
    "    lemmatized_words = lemmatize_sentences(all_words)\n",
    "    return set(lemmatized_words)\n",
    "\n",
    "\n",
    "quality_phrases = [\n",
    "    r'–ø—Ä–µ–∫—Ä–∞—Å–Ω–∞—è –≤–µ—â—å', r'–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–∞—è –≤–µ—â—å', \n",
    "    r'–≤—Å–µ –ø—Ä–∏—à–ª–æ –≤ –∏–¥–µ–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏', r'—Ç–æ–≤–∞—Ä –≤ –æ—Ç–ª–∏—á–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏', \n",
    "    r'–±–µ–∑ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π', r'—É–ø–∞–∫–æ–≤–∫–∞ —Ü–µ–ª–∞—è', r'—Ç–æ–≤–∞—Ä –±–µ–∑ –¥–µ—Ñ–µ–∫—Ç–æ–≤', \n",
    "    r'–≤—Å–µ –¥–æ—à–ª–æ —Ü–µ–ª—ã–º', r'–¥–æ—Å—Ç–∞–≤–∫–∞ –±–µ–∑ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π', r'–∏–¥–µ–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ',\n",
    "    r'–æ—á–µ–Ω—å –¥–æ–≤–æ–ª–µ–Ω', r'–æ—á–µ–Ω—å –¥–æ–≤–æ–ª—å–Ω–∞', r'—Ç–æ–≤–∞—Ä –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è', r'–∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å'\n",
    "]\n",
    "\n",
    "\n",
    "functionality_phrases = [\n",
    "    r'—Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ', r'—Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ', r'–≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç', r'—Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç', r'—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π', \n",
    "    r'—Ñ—É–Ω–∫—Ü–∏–∏ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è', r'—Å –∑–∞–¥–∞—á–µ–π —Å–ø—Ä–∞–≤–∏–ª—Å—è', r'—Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –∑–∞–¥–∞—á–µ–π', r'–∑–∞–¥–∞—á—É —Å–≤–æ—é –≤—ã–ø–æ–ª–Ω–∏–ª', \n",
    "    r'—Å–ø—Ä–∞–≤–∏–ª—Å—è –Ω–∞ –æ—Ç–ª–∏—á–Ω–æ', r'—Å–æ —Å–≤–æ–∏–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è', r'–∑–∞–¥–∞—á—É –≤—ã–ø–æ–ª–Ω–∏–ª',\n",
    "    r'–¥–æ–≤–æ–ª–µ–Ω —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é', r'–¥–æ–≤–æ–ª—å–Ω–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é', r'—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è'\n",
    "]\n",
    "\n",
    "gratitude_phrases = [\n",
    "    r'—Å–ø–∞—Å–∏–±–æ', r'—Ä–µ–∫–æ–º–µ–Ω–¥—É—é', r'—Å–æ–≤–µ—Ç—É—é', r'–ø—Ä–æ–¥–∞–≤–µ—Ü –º–æ–ª–æ–¥–µ—Ü', r'–±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω', r'–±–ª–∞–≥–æ–¥–∞—Ä—é', \n",
    "    r'—Å–æ–≤–µ—Ç—É—é –∫ –ø–æ–∫—É–ø–∫–µ', r'—Å–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–µ', r'–≤—Å–µ–º —Å–æ–≤–µ—Ç—É—é', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ —Ç–æ–≤–∞—Ä', \n",
    "    r'—Å–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤—Ü—É', r'–±–ª–∞–≥–æ–¥–∞—Ä—é –∑–∞ —Ç–æ–≤–∞—Ä', r'–±–æ–ª—å—à–æ–µ —Å–ø–∞—Å–∏–±–æ', r'–æ—á–µ–Ω—å –±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω', \n",
    "    r'—Å–ø–∞—Å–∏–±–æ –∑–∞ –¥–æ—Å—Ç–∞–≤–∫—É', r'–æ–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç–æ–≤–∞—Ä', \n",
    "    r'–ø—Ä–æ–¥–∞–≤—Ü—É –æ–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ—Å—Ç—å', r'—Å–ø–∞—Å–∏–±–æ –≤–∞–º', \n",
    "    r'–±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω –∑–∞ —Ç–æ–≤–∞—Ä', r'—Å–ø–∞—Å–∏–±–æ, –≤—Å—ë —Ö–æ—Ä–æ—à–æ', r'–ø—Ä–æ–¥–∞–≤–µ—Ü –º–æ–ª–æ–¥–µ—Ü', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ —Ö–æ—Ä–æ—à–µ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ',\n",
    "    r'–¥–æ–≤–æ–ª–µ–Ω —Å–µ—Ä–≤–∏—Å–æ–º', r'–¥–æ–≤–æ–ª—å–Ω–∞ —Å–µ—Ä–≤–∏—Å–æ–º'\n",
    "]\n",
    "\n",
    "delivery_phrases = [\n",
    "    r'–ø—Ä–∏—à–µ–ª –±—ã—Å—Ç—Ä–æ', r'–±—ã—Å—Ç—Ä–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞', r'–ø—Ä–∏—à–µ–ª –≤–æ–≤—Ä–µ–º—è', r'–∑–∞–∫–∞–∑ –ø—Ä–∏—à–µ–ª —Ü–µ–ª—ã–π –∏ –≤–æ–≤—Ä–µ–º—è', \n",
    "    r'–ø—Ä–∏—à–µ–ª —Ü–µ–ª—ã–π', r'–¥–æ—Å—Ç–∞–≤–∫–∞ –≤–æ–≤—Ä–µ–º—è', r'–≤—Å–µ –ø—Ä–∏—à–ª–æ —Ü–µ–ª—ã–º', r'—Ç–æ–≤–∞—Ä –ø—Ä–∏—à–µ–ª —Ü–µ–ª—ã–º', r'–ø—Ä–∏—à–µ–ª –≤ —Å—Ä–æ–∫',\n",
    "    r'–ø—Ä–∏—à–µ–ª –≤–æ–≤—Ä–µ–º—è –∏ —Ü–µ–ª—ã–º', r'–ø–æ–ª—É—á–∏–ª –∑–∞–∫–∞–∑ –≤–æ–≤—Ä–µ–º—è', r'–¥–æ—Å—Ç–∞–≤–∫–∞ - –≤–æ!', r'–≤—Å–µ –ø—Ä–∏—à–ª–æ –∫–∞–∫ –Ω–∞–¥–æ', \n",
    "    r'–ø—Ä–∏—à–µ–ª –≤ –ø–æ–ª–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ', r'–æ—Ç–ª–∏—á–Ω–∞—è —É–ø–∞–∫–æ–≤–∫–∞', r'–≤—Å–µ –¥–æ—à–ª–æ —Ü–µ–ª—ã–º', r'—É–ø–∞–∫–æ–≤–∞–Ω–æ –Ω–∞ —Å–æ–≤–µ—Å—Ç—å', \n",
    "    r'–∫—Ä—É—Ç–∞—è —É–ø–∞–∫–æ–≤–∫–∞', r'–¥–æ–≤–æ–ª–µ–Ω –¥–æ—Å—Ç–∞–≤–∫–æ–π', r'–¥–æ–≤–æ–ª—å–Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–æ–π'\n",
    "]\n",
    "\n",
    "confirmation_phrases = [\n",
    "    r'–≤—Å—ë —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç', r'–≤—Å—ë –∫–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏', r'–≤—Å—ë –∫–∞–∫ –∑–∞—è–≤–ª–µ–Ω–æ', r'—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—é', \n",
    "    r'–≤—Å—ë —Ü–µ–ª–æ–µ', r'–≤—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ', r'–≤—Å—ë –Ω–æ—Ä–º', r'–≤—Å—ë —Ö–æ—Ä–æ—à–æ', r'–∫–∞–∫ –≤—Å–µ–≥–¥–∞', r'–±–µ–∑ –ø—Ä–æ–±–ª–µ–º', \n",
    "    r'–Ω–æ—Ä–º–∞–ª—å–Ω–æ —É–ø–∞–∫–æ–≤–∞–Ω–æ', r'–Ω–æ—Ä–º–∞–ª—å–Ω–æ', r'–≤—Å—ë –Ω–æ—Ä–º', r'–ø–æ–ª–Ω–æ—Å—Ç—å—é –¥–æ–≤–æ–ª–µ–Ω', r'–ø–æ–ª–Ω–æ—Å—Ç—å—é –¥–æ–≤–æ–ª—å–Ω–∞', \n",
    "    r'–≤—Å—ë –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å'\n",
    "]\n",
    "\n",
    "simple_statements_phrases = [\n",
    "    r'—Ö–æ—Ä–æ—à–∞—è –≤–µ—â—å', r'–∫–ª–∞—Å—Å–Ω–∞—è –≤–µ—â—å', r'–æ—Ç–ª–∏—á–Ω–∞—è –≤–µ—â—å', r'—É–¥–æ–±–Ω–æ', r'–Ω–æ—Ä–º–∞–ª—å–Ω–æ', r'—Ä–∞–±–æ—Ç–∞–µ—Ç', \n",
    "    r'—Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ', r'—Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ', r'–≤—Å—ë –Ω–æ—Ä–º–∞–ª—å–Ω–æ', r'–≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç', r'–≤—Å—ë –æ–∫', \n",
    "    r'–≤—Å—ë –æ–∫–µ–π', r'—Å—É–ø–µ—Ä', r'–∫–ª–∞—Å—Å', r'–Ω–æ—Ä–º', r'–æ—Ç–ª–∏—á–Ω–æ', r'—Ö–æ—Ä–æ—à–æ', r'–∏–¥–µ–∞–ª—å–Ω–æ', r'üëç', r'üëè', \n",
    "    r'üòÜ', r'üî•', r'üíØ', r'–∫–ª–∞—Å—Å', r'–≤—Å–µ —Å—É–ø–µ—Ä', r'üòä', r'–¥–æ–≤–æ–ª–µ–Ω', r'–¥–æ–≤–æ–ª—å–Ω–∞', \n",
    "    r'–ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å', \"üòä\", \"üëç\", \"üòç\", \"üòÇ\", \"üõçÔ∏è\", \"üíØ\", \"üòÜ\", \"üòÅ\", \"üëè\", \"üî•\",\n",
    "    \"ü•∞\", \"üòé\", \"ü§©\", \"‚ù§Ô∏è\", \"ü§î\", \"üôå\", \"üòú\", \"üòâ\", \"ü§ó\", \"üòÖ\",\n",
    "    \"üëÄ\", \"ü§∑\", \"üòã\", \"üíñ\", \"üåü\", \"üòá\", \"üòò\", \"üéâ\", \"üí™\", \"üí•\",\n",
    "    \"üëå\", \"üòÑ\", \"üëã\", \"üòè\", \"üôè\", \"ü§ù\", \"‚ú®\", \"ü§ì\", \"üå∏\", \"üòå\",\n",
    "    \"ü•≥\", \"üéÅ\", \"üòë\", \"üò≥\", \"üôà\", \"üò§\", \"üëë\", \"üò¢\", \"ü§§\", \"ü§û\"\n",
    "]\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–∞—Å–æ–∫ –∏ –∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "mask_names = [\n",
    "    \"quality_phrases\",\n",
    "    \"functionality_phrases\",\n",
    "    \"gratitude_phrases\",\n",
    "    \"delivery_phrases\",\n",
    "    \"confirmation_phrases\",\n",
    "    \"simple_statements_phrases\"\n",
    "]\n",
    "\n",
    "mask_embeddings = [\n",
    "    compute_sentence_embeddings(gratitude_phrases),\n",
    "    compute_sentence_embeddings(delivery_phrases),\n",
    "    compute_sentence_embeddings(confirmation_phrases),\n",
    "    compute_sentence_embeddings(simple_statements_phrases),\n",
    "    compute_sentence_embeddings(quality_phrases),\n",
    "    compute_sentence_embeddings(functionality_phrases),\n",
    "]\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤ –∏–∑ –º–∞—Å–æ–∫\n",
    "mask_words = create_mask_words(\n",
    "    gratitude_phrases + delivery_phrases + confirmation_phrases + simple_statements_phrases + quality_phrases + functionality_phrases\n",
    ")\n",
    "\n",
    "# –í—ã–∑–æ–≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –º–∞—Å–æ–∫ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º\n",
    "final_result = process_reviews(df_exploded, mask_embeddings, mask_names, mask_words)\n",
    "\n",
    "# –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "display(final_result[['product', 'sentence', 'label']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12095"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# import spacy\n",
    "# from tqdm import tqdm\n",
    "# import logging\n",
    "\n",
    "# # –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ –≤ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–µ Hugging Face\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (GPU –∏–ª–∏ CPU)\n",
    "# device = torch.device(\"cpu\")  # Ensure everything runs on CPU\n",
    "\n",
    "# # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ –æ—Ç –°–±–µ—Ä–±–∞–Ω–∫–∞\n",
    "# tokenizer = AutoTokenizer.from_pretrained('sberbank-ai/sbert_large_nlu_ru')\n",
    "# model = AutoModel.from_pretrained('sberbank-ai/sbert_large_nlu_ru').to(device)\n",
    "\n",
    "# # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "# logging.basicConfig(filename='./reviews_keywords/clustering.log', \n",
    "#                     level=logging.INFO, \n",
    "#                     format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ spaCy –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞\n",
    "# nlp = spacy.load(\"ru_core_news_lg\")\n",
    "\n",
    "# # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
    "# nltk.download('stopwords')\n",
    "# stop_words = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ü–µ–Ω—Ç—Ä–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞ (—Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞)\n",
    "# def find_centroid(embeddings):\n",
    "#     return np.mean(embeddings, axis=0)\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "# def compute_sentence_embeddings(sentences):\n",
    "#     inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#         # –ü–æ–ª—É—á–∞–µ–º —Å–∫—Ä—ã—Ç—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è\n",
    "#         hidden_states = outputs.hidden_states[-1]\n",
    "#     embeddings = hidden_states.mean(dim=1).cpu().numpy()\n",
    "#     return embeddings\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –∫–ª—é—á–µ–≤–æ–π –º—ã—Å–ª–∏ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ\n",
    "# def extract_key_thought(cluster_sentences):\n",
    "#     sentences = cluster_sentences.split(\" | \")\n",
    "    \n",
    "#     embeddings = compute_sentence_embeddings(sentences)\n",
    "    \n",
    "#     centroid = find_centroid(embeddings)\n",
    "#     similarities = cosine_similarity(embeddings, [centroid])\n",
    "#     key_sentence_index = np.argmax(similarities)\n",
    "    \n",
    "#     return sentences[key_sentence_index]\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Ç–µ—Ä–µ\n",
    "# def count_words(cluster_sentences):\n",
    "#     words = cluster_sentences.split()\n",
    "#     return len(words)\n",
    "\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∫—Ä—É–ø–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "# def recluster_large_cluster(cluster_sentences, eps=0.1, min_samples=2):\n",
    "#     sentences = cluster_sentences.split(\" | \")\n",
    "    \n",
    "#     embeddings = compute_sentence_embeddings(sentences)\n",
    "    \n",
    "#     re_clustering = DBSCAN(eps=eps, min_samples=min_samples, metric=\"cosine\").fit(embeddings)\n",
    "    \n",
    "#     re_cluster_dict = {}\n",
    "#     for idx, label in enumerate(re_clustering.labels_):\n",
    "#         if label == -1:\n",
    "#             continue\n",
    "#         label_str = str(label)\n",
    "#         if label_str not in re_cluster_dict:\n",
    "#             re_cluster_dict[label_str] = []\n",
    "#         re_cluster_dict[label_str].append(sentences[idx])\n",
    "    \n",
    "#     return [\" | \".join(cluster) for cluster in re_cluster_dict.values()]\n",
    "\n",
    "# # –†–µ–∫—É—Ä—Å–∏–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∫—Ä—É–ø–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "# def recursive_clustering(cluster_sentences, threshold, eps=0.25, min_samples=3, min_eps=0.05):\n",
    "#     current_eps = eps\n",
    "#     new_clusters = [cluster_sentences]\n",
    "\n",
    "#     while True:\n",
    "#         next_clusters = []\n",
    "#         reclustered_any = False\n",
    "        \n",
    "#         for cluster in new_clusters:\n",
    "#             if count_words(cluster) > threshold:\n",
    "#                 while current_eps >= min_eps:\n",
    "#                     reclustered = recluster_large_cluster(cluster, eps=current_eps, min_samples=min_samples)\n",
    "#                     if len(reclustered) > 1:\n",
    "#                         next_clusters.extend(reclustered)\n",
    "#                         reclustered_any = True\n",
    "#                         break  # –ö–ª–∞—Å—Ç–µ—Ä —É—Å–ø–µ—à–Ω–æ —Ä–∞–∑–¥–µ–ª–µ–Ω, –≤—ã—Ö–æ–¥–∏–º –∏–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ —Ü–∏–∫–ª–∞\n",
    "#                     else:\n",
    "#                         current_eps -= 0.02  # –£–º–µ–Ω—å—à–∞–µ–º eps –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞\n",
    "                \n",
    "#                 if len(reclustered) == 1:\n",
    "#                     # –ï—Å–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä —Ç–∞–∫ –∏ –Ω–µ –±—ã–ª —Ä–∞–∑–¥–µ–ª–µ–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –æ–±—Ä–∞—Ç–Ω–æ\n",
    "#                     next_clusters.append(cluster)\n",
    "#             else:\n",
    "#                 next_clusters.append(cluster)\n",
    "        \n",
    "#         new_clusters = next_clusters\n",
    "        \n",
    "#         if not reclustered_any:\n",
    "#             break\n",
    "    \n",
    "#     return new_clusters\n",
    "\n",
    "# # –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –ø–æ —Ç–æ–≤–∞—Ä–∞–º\n",
    "# df_clusters = pd.DataFrame()\n",
    "# label_col = \"label\"\n",
    "# sentence_col = \"sentence\"\n",
    "# for label in final_result[label_col].unique():  # Added tqdm here\n",
    "#     print(label)\n",
    "#     label_df = final_result[final_result[label_col] == label]\n",
    "#     all_sentences = label_df[sentence_col].tolist()\n",
    "#     print(all_sentences)\n",
    "#     # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –±–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ –±–∞—Ç—á–∏\n",
    "#     all_embeddings = compute_sentence_embeddings(all_sentences)\n",
    "#     print(all_embeddings)\n",
    "\n",
    "#     # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏\n",
    "#     clustering = DBSCAN(eps=0.25, min_samples=3, metric=\"cosine\").fit(all_embeddings)\n",
    "#     print(clustering)\n",
    "\n",
    "#     cluster_dict = {}\n",
    "#     for idx, label in tqdm(enumerate(clustering.labels_), desc=f\"Organizing clusters for {label}\"):\n",
    "#         if label == -1:\n",
    "#             continue\n",
    "#         label_str = str(label)\n",
    "#         if label_str not in cluster_dict:\n",
    "#             cluster_dict[label_str] = set()\n",
    "#         cluster_dict[label_str].add(all_sentences[idx])\n",
    "\n",
    "#     clusters = [\" | \".join(sentences) for sentences in cluster_dict.values()]\n",
    "#     threshold = np.min([np.mean([count_words(cluster) for cluster in clusters]) * 1.5  ,  450])\n",
    "\n",
    "#     final_clusters = []\n",
    "#     for cluster in tqdm(clusters, desc=\"Recursive clustering\"):\n",
    "#         final_clusters.extend(recursive_clustering(cluster, threshold))\n",
    "\n",
    "#     df_exploded_sorted = pd.DataFrame({'cluster_sentences': final_clusters})\n",
    "#     df_exploded_sorted['word_count'] = df_exploded_sorted['cluster_sentences'].apply(count_words)\n",
    "#     df_exploded_sorted['key_thought'] = df_exploded_sorted['cluster_sentences'].apply(extract_key_thought)\n",
    "\n",
    "#     df_exploded_sorted = df_exploded_sorted.sort_values(by='word_count', ascending=False)\n",
    "\n",
    "#     df_clusters = pd.concat([df_clusters, df_exploded_sorted], ignore_index=True)\n",
    "\n",
    "# # –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "# display(df_clusters[['cluster_sentences', 'key_thought', 'word_count']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –≠—Ç–∞–ø 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf.pandas  # –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ cuDF –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏—è –µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "cudf.pandas.install()  # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ cuDF –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –¥–ª—è pandas\n",
    "import pandas as pd  # –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ pandas –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ cuDF\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_result = pd.read_csv(\"./reviews_keywords/cluster_result.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>key_thought</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['–û—á –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å!', '–î–æ–±—Ä–æ—Ç–Ω–∞—è –∫—Ä—ã—à–∫–∞, —Ä—É—á–∫–∞ –¥...</td>\n",
       "      <td>–°—Ç–∏–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω,–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω –ü—Ä–∏—à—ë–ª —Ö–æ...</td>\n",
       "      <td>179535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['–î–æ—Å—Ç–∞–≤–∫–∞ –±—ã—Å—Ç—Ä–∞—è, –ø–æ–∫–∞ –µ—â—ë –Ω–∏—á–µ–≥–æ –Ω–µ –∫–ª–µ–∏–ª, ...</td>\n",
       "      <td>–î–æ—Å—Ç–∞–≤–∫–∞ –±—ã—Å—Ç—Ä–∞—è, –ø–æ–∫–∞ –µ—â—ë –Ω–∏—á–µ–≥–æ –Ω–µ –∫–ª–µ–∏–ª, –¥—É...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>['–∞–±—Å–æ–ª—é—Ç–Ω–æ', '–∞–±—Å–æ–ª—é—Ç–Ω–æ', '–≤–ø–æ–ª–Ω–µ', '–±–æ–ª–µ–µ —á–µ–º']</td>\n",
       "      <td>–∞–±—Å–æ–ª—é—Ç–Ω–æ</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>['–û—á–µ–Ω—å –ø—Ä–∏—è—Ç–Ω–æüòú', '–û—á–µ–Ω—å –∫—Ä–∞—Å–∏–≤—ã–µüëçüèª', '–û—á–µ–Ω—å ...</td>\n",
       "      <td>–û—á–µ–Ω—å –ø—Ä–∏—è—Ç–Ω–æüòú</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>['–¢–æ —á—Ç–æ –∏—Å–∫–∞–ª–∞, —Å–ø–∫—Å–∏—å–æ –ø—Ä–æ–¥–∞–≤—Ü—É!', '–¢–æ —á—Ç–æ –∏...</td>\n",
       "      <td>–¢–æ —á—Ç–æ –∏—Å–∫–∞–ª–∞, —Å–ø–∫—Å–∏—å–æ –ø—Ä–æ–¥–∞–≤—Ü—É!</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>['–ü—Ä–∏—à–ª–æ—Å—å –≤—ã–∫—É–ø–∞—Ç—å –∏ —Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å!', '–ü—Ä–∏—à–ª–æ...</td>\n",
       "      <td>–ü—Ä–∏—à–ª–æ—Å—å –≤—ã–∫—É–ø–∞—Ç—å –∏ —Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å!</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>['–•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –±–µ–∑ —Å–≤–∞—Ä–∫–∏', '–•–æ—Ä–æ—à–∏–π —Ä–µ–∑...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –±–µ–∑ —Å–≤–∞—Ä–∫–∏</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>['–Ø—Ä–∫–∏–π, –æ—á–µ–Ω—å –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Å–¥–µ–ª–∞–Ωüëçüèª', '–Ø—Ä–∫–∏–π, –æ—á...</td>\n",
       "      <td>–Ø—Ä–∫–∏–π, –æ—á–µ–Ω—å –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Å–¥–µ–ª–∞–Ωüëçüèª</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>['–ü—Ä–∏—à—ë–ª —Å –º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∏–º–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏', '–ü—Ä–∏—à...</td>\n",
       "      <td>–ü—Ä–∏—à—ë–ª —Å –º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∏–º–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>['–ë—É–∫–≤—ã —Å—É–ø–µ—Ä –ú–Ω–æ–≥–æ –∑–∞–ø–∞—Å–Ω—ã—Ö', '–ë—É–∫–≤—ã —Å—É–ø–µ—Ä –ú–Ω...</td>\n",
       "      <td>–ë—É–∫–≤—ã —Å—É–ø–µ—Ä –ú–Ω–æ–≥–æ –∑–∞–ø–∞—Å–Ω—ã—Ö</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>673 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  cluster_id                                  cluster_sentences  \\\n",
       "0        0           0  ['–û—á –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å!', '–î–æ–±—Ä–æ—Ç–Ω–∞—è –∫—Ä—ã—à–∫–∞, —Ä—É—á–∫–∞ –¥...   \n",
       "1        0           1  ['–î–æ—Å—Ç–∞–≤–∫–∞ –±—ã—Å—Ç—Ä–∞—è, –ø–æ–∫–∞ –µ—â—ë –Ω–∏—á–µ–≥–æ –Ω–µ –∫–ª–µ–∏–ª, ...   \n",
       "2        0           2  ['–∞–±—Å–æ–ª—é—Ç–Ω–æ', '–∞–±—Å–æ–ª—é—Ç–Ω–æ', '–≤–ø–æ–ª–Ω–µ', '–±–æ–ª–µ–µ —á–µ–º']   \n",
       "3        0           3  ['–û—á–µ–Ω—å –ø—Ä–∏—è—Ç–Ω–æüòú', '–û—á–µ–Ω—å –∫—Ä–∞—Å–∏–≤—ã–µüëçüèª', '–û—á–µ–Ω—å ...   \n",
       "4        0           4  ['–¢–æ —á—Ç–æ –∏—Å–∫–∞–ª–∞, —Å–ø–∫—Å–∏—å–æ –ø—Ä–æ–¥–∞–≤—Ü—É!', '–¢–æ —á—Ç–æ –∏...   \n",
       "..     ...         ...                                                ...   \n",
       "668      2          64  ['–ü—Ä–∏—à–ª–æ—Å—å –≤—ã–∫—É–ø–∞—Ç—å –∏ —Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å!', '–ü—Ä–∏—à–ª–æ...   \n",
       "669      2          65  ['–•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –±–µ–∑ —Å–≤–∞—Ä–∫–∏', '–•–æ—Ä–æ—à–∏–π —Ä–µ–∑...   \n",
       "670      2          68  ['–Ø—Ä–∫–∏–π, –æ—á–µ–Ω—å –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Å–¥–µ–ª–∞–Ωüëçüèª', '–Ø—Ä–∫–∏–π, –æ—á...   \n",
       "671      2          69  ['–ü—Ä–∏—à—ë–ª —Å –º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∏–º–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏', '–ü—Ä–∏—à...   \n",
       "672      2          70  ['–ë—É–∫–≤—ã —Å—É–ø–µ—Ä –ú–Ω–æ–≥–æ –∑–∞–ø–∞—Å–Ω—ã—Ö', '–ë—É–∫–≤—ã —Å—É–ø–µ—Ä –ú–Ω...   \n",
       "\n",
       "                                           key_thought  word_count  \n",
       "0    –°—Ç–∏–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω,–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω –ü—Ä–∏—à—ë–ª —Ö–æ...      179535  \n",
       "1    –î–æ—Å—Ç–∞–≤–∫–∞ –±—ã—Å—Ç—Ä–∞—è, –ø–æ–∫–∞ –µ—â—ë –Ω–∏—á–µ–≥–æ –Ω–µ –∫–ª–µ–∏–ª, –¥—É...          44  \n",
       "2                                            –∞–±—Å–æ–ª—é—Ç–Ω–æ           5  \n",
       "3                                       –û—á–µ–Ω—å –ø—Ä–∏—è—Ç–Ω–æüòú          21  \n",
       "4                     –¢–æ —á—Ç–æ –∏—Å–∫–∞–ª–∞, —Å–ø–∫—Å–∏—å–æ –ø—Ä–æ–¥–∞–≤—Ü—É!          15  \n",
       "..                                                 ...         ...  \n",
       "668                 –ü—Ä–∏—à–ª–æ—Å—å –≤—ã–∫—É–ø–∞—Ç—å –∏ —Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å!          20  \n",
       "669                      –•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –±–µ–∑ —Å–≤–∞—Ä–∫–∏          12  \n",
       "670                    –Ø—Ä–∫–∏–π, –æ—á–µ–Ω—å –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Å–¥–µ–ª–∞–Ωüëçüèª          16  \n",
       "671               –ü—Ä–∏—à—ë–ª —Å –º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∏–º–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏          16  \n",
       "672                         –ë—É–∫–≤—ã —Å—É–ø–µ—Ä –ú–Ω–æ–≥–æ –∑–∞–ø–∞—Å–Ω—ã—Ö          12  \n",
       "\n",
       "[673 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>key_thought</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[–û—á –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å!, –î–æ–±—Ä–æ—Ç–Ω–∞—è –∫—Ä—ã—à–∫–∞, —Ä—É—á–∫–∞ –¥–æ–±–∞...</td>\n",
       "      <td>–°—Ç–∏–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω,–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω –ü—Ä–∏—à—ë–ª —Ö–æ...</td>\n",
       "      <td>179535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[–î–æ—Å—Ç–∞–≤–∫–∞ –±—ã—Å—Ç—Ä–∞—è, –ø–æ–∫–∞ –µ—â—ë –Ω–∏—á–µ–≥–æ –Ω–µ –∫–ª–µ–∏–ª, –¥...</td>\n",
       "      <td>–î–æ—Å—Ç–∞–≤–∫–∞ –±—ã—Å—Ç—Ä–∞—è, –ø–æ–∫–∞ –µ—â—ë –Ω–∏—á–µ–≥–æ –Ω–µ –∫–ª–µ–∏–ª, –¥—É...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[–∞–±—Å–æ–ª—é—Ç–Ω–æ, –∞–±—Å–æ–ª—é—Ç–Ω–æ, –≤–ø–æ–ª–Ω–µ, –±–æ–ª–µ–µ —á–µ–º]</td>\n",
       "      <td>–∞–±—Å–æ–ª—é—Ç–Ω–æ</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[–û—á–µ–Ω—å –ø—Ä–∏—è—Ç–Ω–æüòú, –û—á–µ–Ω—å –∫—Ä–∞—Å–∏–≤—ã–µüëçüèª, –û—á–µ–Ω—å —Ö–æ—Ä–æ—à...</td>\n",
       "      <td>–û—á–µ–Ω—å –ø—Ä–∏—è—Ç–Ω–æüòú</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[–¢–æ —á—Ç–æ –∏—Å–∫–∞–ª–∞, —Å–ø–∫—Å–∏—å–æ –ø—Ä–æ–¥–∞–≤—Ü—É!, –¢–æ —á—Ç–æ –∏—Å–∫–∞...</td>\n",
       "      <td>–¢–æ —á—Ç–æ –∏—Å–∫–∞–ª–∞, —Å–ø–∫—Å–∏—å–æ –ø—Ä–æ–¥–∞–≤—Ü—É!</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>[–ü—Ä–∏—à–ª–æ—Å—å –≤—ã–∫—É–ø–∞—Ç—å –∏ —Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å!, –ü—Ä–∏—à–ª–æ—Å—å ...</td>\n",
       "      <td>–ü—Ä–∏—à–ª–æ—Å—å –≤—ã–∫—É–ø–∞—Ç—å –∏ —Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å!</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>[–•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –±–µ–∑ —Å–≤–∞—Ä–∫–∏, –•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –±–µ–∑ —Å–≤–∞—Ä–∫–∏</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>[–Ø—Ä–∫–∏–π, –æ—á–µ–Ω—å –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Å–¥–µ–ª–∞–Ωüëçüèª, –Ø—Ä–∫–∏–π, –æ—á–µ–Ω—å...</td>\n",
       "      <td>–Ø—Ä–∫–∏–π, –æ—á–µ–Ω—å –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Å–¥–µ–ª–∞–Ωüëçüèª</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>[–ü—Ä–∏—à—ë–ª —Å –º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∏–º–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏, –ü—Ä–∏—à—ë–ª ...</td>\n",
       "      <td>–ü—Ä–∏—à—ë–ª —Å –º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∏–º–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>[–ë—É–∫–≤—ã —Å—É–ø–µ—Ä –ú–Ω–æ–≥–æ –∑–∞–ø–∞—Å–Ω—ã—Ö, –ë—É–∫–≤—ã —Å—É–ø–µ—Ä –ú–Ω–æ–≥–æ...</td>\n",
       "      <td>–ë—É–∫–≤—ã —Å—É–ø–µ—Ä –ú–Ω–æ–≥–æ –∑–∞–ø–∞—Å–Ω—ã—Ö</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>673 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  cluster_id                                  cluster_sentences  \\\n",
       "0        0           0  [–û—á –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å!, –î–æ–±—Ä–æ—Ç–Ω–∞—è –∫—Ä—ã—à–∫–∞, —Ä—É—á–∫–∞ –¥–æ–±–∞...   \n",
       "1        0           1  [–î–æ—Å—Ç–∞–≤–∫–∞ –±—ã—Å—Ç—Ä–∞—è, –ø–æ–∫–∞ –µ—â—ë –Ω–∏—á–µ–≥–æ –Ω–µ –∫–ª–µ–∏–ª, –¥...   \n",
       "2        0           2          [–∞–±—Å–æ–ª—é—Ç–Ω–æ, –∞–±—Å–æ–ª—é—Ç–Ω–æ, –≤–ø–æ–ª–Ω–µ, –±–æ–ª–µ–µ —á–µ–º]   \n",
       "3        0           3  [–û—á–µ–Ω—å –ø—Ä–∏—è—Ç–Ω–æüòú, –û—á–µ–Ω—å –∫—Ä–∞—Å–∏–≤—ã–µüëçüèª, –û—á–µ–Ω—å —Ö–æ—Ä–æ—à...   \n",
       "4        0           4  [–¢–æ —á—Ç–æ –∏—Å–∫–∞–ª–∞, —Å–ø–∫—Å–∏—å–æ –ø—Ä–æ–¥–∞–≤—Ü—É!, –¢–æ —á—Ç–æ –∏—Å–∫–∞...   \n",
       "..     ...         ...                                                ...   \n",
       "668      2          64  [–ü—Ä–∏—à–ª–æ—Å—å –≤—ã–∫—É–ø–∞—Ç—å –∏ —Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å!, –ü—Ä–∏—à–ª–æ—Å—å ...   \n",
       "669      2          65  [–•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –±–µ–∑ —Å–≤–∞—Ä–∫–∏, –•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å...   \n",
       "670      2          68  [–Ø—Ä–∫–∏–π, –æ—á–µ–Ω—å –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Å–¥–µ–ª–∞–Ωüëçüèª, –Ø—Ä–∫–∏–π, –æ—á–µ–Ω—å...   \n",
       "671      2          69  [–ü—Ä–∏—à—ë–ª —Å –º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∏–º–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏, –ü—Ä–∏—à—ë–ª ...   \n",
       "672      2          70  [–ë—É–∫–≤—ã —Å—É–ø–µ—Ä –ú–Ω–æ–≥–æ –∑–∞–ø–∞—Å–Ω—ã—Ö, –ë—É–∫–≤—ã —Å—É–ø–µ—Ä –ú–Ω–æ–≥–æ...   \n",
       "\n",
       "                                           key_thought  word_count  \n",
       "0    –°—Ç–∏–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω,–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω –ü—Ä–∏—à—ë–ª —Ö–æ...      179535  \n",
       "1    –î–æ—Å—Ç–∞–≤–∫–∞ –±—ã—Å—Ç—Ä–∞—è, –ø–æ–∫–∞ –µ—â—ë –Ω–∏—á–µ–≥–æ –Ω–µ –∫–ª–µ–∏–ª, –¥—É...          44  \n",
       "2                                            –∞–±—Å–æ–ª—é—Ç–Ω–æ           5  \n",
       "3                                       –û—á–µ–Ω—å –ø—Ä–∏—è—Ç–Ω–æüòú          21  \n",
       "4                     –¢–æ —á—Ç–æ –∏—Å–∫–∞–ª–∞, —Å–ø–∫—Å–∏—å–æ –ø—Ä–æ–¥–∞–≤—Ü—É!          15  \n",
       "..                                                 ...         ...  \n",
       "668                 –ü—Ä–∏—à–ª–æ—Å—å –≤—ã–∫—É–ø–∞—Ç—å –∏ —Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å!          20  \n",
       "669                      –•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –±–µ–∑ —Å–≤–∞—Ä–∫–∏          12  \n",
       "670                    –Ø—Ä–∫–∏–π, –æ—á–µ–Ω—å –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Å–¥–µ–ª–∞–Ωüëçüèª          16  \n",
       "671               –ü—Ä–∏—à—ë–ª —Å –º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∏–º–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏          16  \n",
       "672                         –ë—É–∫–≤—ã —Å—É–ø–µ—Ä –ú–Ω–æ–≥–æ –∑–∞–ø–∞—Å–Ω—ã—Ö          12  \n",
       "\n",
       "[673 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_list_from_string(s):\n",
    "    # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å–ø–∏—Å–∫–∞ –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫–∏\n",
    "    matches = re.findall(r'\\[\\'(.*?)\\'\\]', s)\n",
    "    \n",
    "    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ, —Ä–∞–∑–¥–µ–ª—è–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ –∑–∞–ø—è—Ç–æ–π –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫\n",
    "    if matches:\n",
    "        return [item.strip() for item in matches[0].split(\"', '\")]\n",
    "    return s\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∫–æ –≤—Å–µ–π –∫–æ–ª–æ–Ω–∫–µ\n",
    "clustered_result['cluster_sentences'] = clustered_result['cluster_sentences'].apply(lambda x: extract_list_from_string(str(x)))\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "clustered_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_result.loc[clustered_result.label == 2, \"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>key_thought</th>\n",
       "      <th>word_count</th>\n",
       "      <th>total_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[–û—á –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å!, –î–æ–±—Ä–æ—Ç–Ω–∞—è –∫—Ä—ã—à–∫–∞, —Ä—É—á–∫–∞ –¥–æ–±–∞...</td>\n",
       "      <td>0</td>\n",
       "      <td>–°—Ç–∏–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω,–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω –ü—Ä–∏—à—ë–ª —Ö–æ...</td>\n",
       "      <td>208571</td>\n",
       "      <td>24236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[–£–¥–æ–±–Ω–∞—è —Ä—É—á–∫–∞, –ø–ª–æ—Ç–Ω—ã–π –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª - ...</td>\n",
       "      <td>0</td>\n",
       "      <td>–û–ª–∏–º–ø–∏–π–∫–∞ –æ—Ç–ª–∏—á–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –≤–Ω–∞—á–∞–ª–µ –∫—É–ø–∏–ª–∞ —Å—ã...</td>\n",
       "      <td>796358</td>\n",
       "      <td>33113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                  cluster_sentences  cluster_id  \\\n",
       "0      0  [–û—á –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å!, –î–æ–±—Ä–æ—Ç–Ω–∞—è –∫—Ä—ã—à–∫–∞, —Ä—É—á–∫–∞ –¥–æ–±–∞...           0   \n",
       "1      1  [–£–¥–æ–±–Ω–∞—è —Ä—É—á–∫–∞, –ø–ª–æ—Ç–Ω—ã–π –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª - ...           0   \n",
       "\n",
       "                                         key_thought  word_count  \\\n",
       "0  –°—Ç–∏–ª—å–Ω—ã–π –¥–∏–∑–∞–π–Ω,–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω –ü—Ä–∏—à—ë–ª —Ö–æ...      208571   \n",
       "1  –û–ª–∏–º–ø–∏–π–∫–∞ –æ—Ç–ª–∏—á–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –≤–Ω–∞—á–∞–ª–µ –∫—É–ø–∏–ª–∞ —Å—ã...      796358   \n",
       "\n",
       "   total_sentences  \n",
       "0            24236  \n",
       "1            33113  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –º–µ—Ç–∫–µ `label` –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–∞—Å—Å–∏–≤–æ–≤ —Ç–µ–∫—Å—Ç–æ–≤\n",
    "grouped_result = clustered_result.groupby('label').agg({\n",
    "    'cluster_sentences': lambda x: sum(x, []),  # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–ø–∏—Å–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤\n",
    "    'cluster_id': 'first',  # –ú–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å –ª—é–±–æ–π cluster_id, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ –±–æ–ª—å—à–µ –Ω–µ –±—É–¥—É—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏\n",
    "    'key_thought': 'first',  # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—É—é –∫–ª—é—á–µ–≤—É—é –º—ã—Å–ª—å\n",
    "    'word_count': 'sum'  # –°—É–º–º–∏—Ä—É–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤\n",
    "}).reset_index()\n",
    "# –ü–æ–¥—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫ –≤ –º–∞—Å—Å–∏–≤–µ —Ç–µ–∫—Å—Ç–æ–≤\n",
    "grouped_result['total_sentences'] = grouped_result['cluster_sentences'].apply(len)\n",
    "grouped_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cluster_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>–û—á –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>–î–æ–±—Ä–æ—Ç–Ω–∞—è –∫—Ä—ã—à–∫–∞, —Ä—É—á–∫–∞ –¥–æ–±–∞–≤–ª—è–µ—Ç —É–¥–æ–±—Å—Ç–≤–æ - –Ω...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–π –ø–∞—è–ª—å–Ω–∏–∫ –ö–∞—á–µ—Å—Ç–≤–æ –∑–∞ —Ç–∞–∫–∏–µ –¥–µ–Ω—å–≥–∏ –ª—É—á—à...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π –ø–∞—è–ª—å–Ω–∏–∫, —à–Ω—É—Ä –Ω–µ –∫–æ—Ä–æ—Ç–∫–∏–π, —Ä–∞–±–æ—Ç–∞–µ—Ç ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>–†–µ–∫–æ–º–µ–Ω–¥—É—é</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>–•–æ—Ä–æ—à–∞—è –æ—Ç–∫—Ä—ã—Ç–∫–∞, –Ω–æ –ø–æ–¥—Å—Ç–∞–≤–∫–∏ —Ö—Ä—É–ø–∫–∏–µ, –æ–¥–Ω–∞ —Å...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>–û—á–µ–Ω—å –∂–∞–ª—å —á—Ç–æ –≤—Ç–æ—Ä–∞—è —Ñ–æ—Ä–º–∞ –ø—Ä–∏—à–ª–∞ –±–æ–ª—å—à–µ —Ä–∞–∑–º...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>–û—á–µ–Ω—å –∂–∞–ª—å —á—Ç–æ –≤—Ç–æ—Ä–∞—è —Ñ–æ—Ä–º–∞ –ø—Ä–∏—à–ª–∞ –±–æ–ª—å—à–µ —Ä–∞–∑–º...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>–í–æ—Ç —Ç–∞–∫–∏–µ –∫–∏—Ä–ø–∏—á–∏–∫–∏ —É –Ω–∞—Å –ø–æ–ª—É—á–∏–ª–∏—Å—å</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>–ñ–∞–ª–∫–æ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö –¥–µ–Ω–µ–≥, –∑–∞–∫–∞–∑—ã–≤–∞–ª 2 —à—Ç –ù–µ –ø–æ–∫—É...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45792 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                  cluster_sentences\n",
       "0       0                                    –û—á –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å!\n",
       "0       0  –î–æ–±—Ä–æ—Ç–Ω–∞—è –∫—Ä—ã—à–∫–∞, —Ä—É—á–∫–∞ –¥–æ–±–∞–≤–ª—è–µ—Ç —É–¥–æ–±—Å—Ç–≤–æ - –Ω...\n",
       "0       0  –•–æ—Ä–æ—à–∏–π –ø–∞—è–ª—å–Ω–∏–∫ –ö–∞—á–µ—Å—Ç–≤–æ –∑–∞ —Ç–∞–∫–∏–µ –¥–µ–Ω—å–≥–∏ –ª—É—á—à...\n",
       "0       0  –û—Ç–ª–∏—á–Ω—ã–π –ø–∞—è–ª—å–Ω–∏–∫, —à–Ω—É—Ä –Ω–µ –∫–æ—Ä–æ—Ç–∫–∏–π, —Ä–∞–±–æ—Ç–∞–µ—Ç ...\n",
       "0       0                                         –†–µ–∫–æ–º–µ–Ω–¥—É—é\n",
       "..    ...                                                ...\n",
       "1       1  –•–æ—Ä–æ—à–∞—è –æ—Ç–∫—Ä—ã—Ç–∫–∞, –Ω–æ –ø–æ–¥—Å—Ç–∞–≤–∫–∏ —Ö—Ä—É–ø–∫–∏–µ, –æ–¥–Ω–∞ —Å...\n",
       "1       1  –û—á–µ–Ω—å –∂–∞–ª—å —á—Ç–æ –≤—Ç–æ—Ä–∞—è —Ñ–æ—Ä–º–∞ –ø—Ä–∏—à–ª–∞ –±–æ–ª—å—à–µ —Ä–∞–∑–º...\n",
       "1       1  –û—á–µ–Ω—å –∂–∞–ª—å —á—Ç–æ –≤—Ç–æ—Ä–∞—è —Ñ–æ—Ä–º–∞ –ø—Ä–∏—à–ª–∞ –±–æ–ª—å—à–µ —Ä–∞–∑–º...\n",
       "1       1               –í–æ—Ç —Ç–∞–∫–∏–µ –∫–∏—Ä–ø–∏—á–∏–∫–∏ —É –Ω–∞—Å –ø–æ–ª—É—á–∏–ª–∏—Å—å\n",
       "1       1  –ñ–∞–ª–∫–æ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö –¥–µ–Ω–µ–≥, –∑–∞–∫–∞–∑—ã–≤–∞–ª 2 —à—Ç –ù–µ –ø–æ–∫—É...\n",
       "\n",
       "[45792 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_result_exploded = grouped_result.explode('cluster_sentences')[['label', 'cluster_sentences']].drop_duplicates()\n",
    "grouped_result_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import logging\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "train_df, val_df = train_test_split(grouped_result_exploded, test_size=0.1, random_state=42, stratify=grouped_result_exploded['label'])\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "train_texts = train_df['cluster_sentences'].tolist()\n",
    "train_labels = train_df['label'].tolist()\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "val_texts = val_df['cluster_sentences'].tolist()\n",
    "val_labels = val_df['label'].tolist()\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏\n",
    "tokenizer = BertTokenizerFast.from_pretrained('sberbank-ai/sbert_large_nlu_ru')\n",
    "model = BertForSequenceClassification.from_pretrained('sberbank-ai/sbert_large_nlu_ru', num_labels=2).to('cuda')\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)  # –û—Å—Ç–∞–≤–ª—è–µ–º –º–µ—Ç–∫–∏ –Ω–∞ CPU\n",
    "        }\n",
    "\n",
    "def compute_metrics(eval_pred, threshold=0.4):  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ä–æ–≥ –Ω–∏–∂–µ 0.5\n",
    "    logits, labels = eval_pred\n",
    "    predictions = (logits[:, 1] > threshold).astype(int)  # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n",
    "train_dataset = CustomDataset(train_texts, train_labels, tokenizer, max_len=128)\n",
    "val_dataset = CustomDataset(val_texts, val_labels, tokenizer, max_len=128)\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ DataLoader-–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./reviews_keywords/results',\n",
    "    num_train_epochs=2,  # –£–º–µ–Ω—å—à–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ø–æ—Ö\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=200,  # –£–º–µ–Ω—å—à–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —à–∞–≥–æ–≤ –ø—Ä–æ–≥—Ä–µ–≤–∞\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./reviews_keywords/logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",  # –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ\n",
    "    eval_steps=120,  # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞–∂–¥—ã–µ 10 —à–∞–≥–æ–≤\n",
    "    fp16=True,  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ 16-–±–∏—Ç–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏\n",
    "    gradient_accumulation_steps=2,  # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —à–∞–≥–∞ –∞–∫–∫—É–º—É–ª—è—Ü–∏–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤\n",
    ")\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "logging.basicConfig(filename='./reviews_keywords/clustering.log', \n",
    "                    level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–±—ç–∫–∞ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "class LogCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            logging.info(f\"Log at step {state.global_step}: {logs}\")\n",
    "\n",
    "# Trainer API –æ—Ç Hugging Face\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,  # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏\n",
    "    callbacks=[LogCallback()]  # –í–∫–ª—é—á–µ–Ω–∏–µ –∫–æ–ª–ª–±—ç–∫–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    ")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π\n",
    "trainer.train()\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "model.save_pretrained('./reviews_keywords/fine_tuned_model_10')\n",
    "tokenizer.save_pretrained('./reviews_keywords/fine_tuned_model_10')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∏ –≤—Å—è–∫–∏–µ —Ç–µ—Å—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è AG TECH / –ê–Ω—Ç–∏—Å–∫–æ—Ç—á —Å–ø—Ä–µ–π —É–¥–∞–ª–∏—Ç–µ–ª—å –Ω–∞–∫–ª–µ–µ–∫ –∏ —Å–∫–æ—Ç—á–∞ 210–º–ª: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.51it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è Autobrand_AED / –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è led —Ñ–∞—Ä–∞ 30w —Å –°–¢–ì, –±–ª–∏–∂–Ω–∏–π, –¥–∞–ª—å–Ω–∏–π, 1 —à—Ç: 0it [00:00, ?it/s]                                                                            | 1/30 [00:07<03:27,  7.16s/it]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è CHAMELEON / –ê–≤—Ç–æ—à–∞–º–ø—É–Ω—å –¥–ª—è –±–µ—Å–∫–æ–Ω—Ç–∞–∫—Ç–Ω–æ–π –º–æ–π–∫–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è 5 –ª: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.00it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è Detail / Iron –û—á–∏—Å—Ç–∏—Ç–µ–ª—å –¥–∏—Å–∫–æ–≤, –∫—É–∑–æ–≤–∞ –æ—Ç –º–µ—Ç–∞–ª–ª–∏—á–µ—Å–∫–∏—Ö –≤–∫—Ä–∞–ø–ª–µ–Ω–∏–π: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 11.54it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è Detail / –•–∏–º—á–∏—Å—Ç–∫–∞ —Å–∞–ª–æ–Ω–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—è, –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å –∫–æ–∂–∏ TX Textile 1 –ª: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 37.27it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è Fox Chemie / –ú–Ω–æ–≥–æ—Ü–µ–ª–µ–≤–∞—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å–º–∞–∑–∫–∞ FX-40 (wd-40): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 41.21it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è GRASS / –ê–≤—Ç–æ—à–∞–º–ø—É–Ω—å –¥–ª—è –±–µ—Å–∫–æ–Ω—Ç–∞–∫—Ç–Ω–æ–π –º–æ–π–∫–∏, Active Foam Pink, 1 –ª: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.41it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è GRASS / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å —Ä–∂–∞–≤—á–∏–Ω—ã –∞–Ω—Ç–∏—Ä–∂–∞–≤—á–∏–Ω–∞ \"Rust remover\" 600 –º–ª: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 36.36it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è GRASS / –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å —Ä–∂–∞–≤—á–∏–Ω—ã –∞–Ω—Ç–∏—Ä–∂–∞–≤—á–∏–Ω–∞, Rust remover Zinc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 10.71it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è GRASS / –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–µ–Ω–Ω—ã–π –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å Multipurpose Foam 750 –º–ª: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 13.56it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è Hangkai / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è –≤–ª–∞–≥–æ–∑–∞—â–∏—Ç–Ω–∞—è 6000 lbs —Å—Ç–∞–ª—å–Ω–æ–π —Ç—Ä–æ—Å: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 21.71it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è LAVR / –ì–µ—Ä–º–µ—Ç–∏–∫ —Ä–∞–¥–∏–∞—Ç–æ—Ä–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—è: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 35.23it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è LAVR / –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä —É—Ç–µ—á–µ–∫ —Å–∏—Å—Ç–µ–º—ã –æ—Ö–ª–∞–∂–¥–µ–Ω–∏—è –∞–≤—Ç–æ: 0it [00:00, ?it/s]‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                | 12/30 [00:47<00:58,  3.24s/it]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è LAVR / –ö–æ–Ω–¥–∏—Ü–∏–æ–Ω–µ—Ä –∫–æ–∂–∏ –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—â–∏–π, 255 –º–ª: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 30.00it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è LAVR / –ü—Ä–æ–ø–∏—Ç–∫–∞ –¥–ª—è –≤–æ–∑–¥—É—à–Ω–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞ –º–æ—Ç–æ—Ü–∏–∫–ª–∞ 400–º–ª: 0it [00:00, ?it/s]‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                                     | 14/30 [00:49<00:38,  2.39s/it]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è MOTORin / –†–∞—Å—à–∏—Ä–∏—Ç–µ–ª–∏ –∞—Ä–æ–∫ 60 –≠–∫: 0it [00:00, ?it/s]‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                | 15/30 [00:51<00:31,  2.09s/it]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è MOTORin / –†–∞—Å—à–∏—Ä–∏—Ç–µ–ª—å –∫–æ–ª—ë—Å–Ω—ã—Ö –∞—Ä–æ–∫ 40 –º–º: 0it [00:00, ?it/s]‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                          | 16/30 [00:51<00:21,  1.52s/it]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è MOTORin / —Ä–∞—Å—à–∏—Ä–∏—Ç–µ–ª–∏ –∞—Ä–æ–∫: 0it [00:00, ?it/s]‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                     | 17/30 [00:51<00:15,  1.21s/it]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3000lb 1361–∫–≥ 13,5–º: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 51.53it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 3500lb 1588–∫–≥ 15–º: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 17.38it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è Shtapler / –õ–µ–±–µ–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∞—è 12v 4500lb 2041–∫–≥ 15–º: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 17.31it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è Vixem / –õ–µ–±–µ–¥–∫–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–∞—è 12 v 4000 1814 –∫–≥ –∫–µ–≤–ª–∞—Ä–æ–≤—ã–π —Ç—Ä–æ—Å: 0it [00:00, ?it/s]‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                | 21/30 [00:54<00:07,  1.17it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –í–ü–ú / –ê–Ω—Ç–∏–±—É–∫—Å - –∞–Ω—Ç–∏–ø—Ä–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ —É—Ç–æ–ª—â–µ–Ω–Ω—ã–µ (2 —à—Ç): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 30.28it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –í–´–†–£–ß–ê–ô–ö–ê / –ê–Ω—Ç–∏–±—É–∫—Å –ü—Ä–æ—Ç–∏–≤–æ–±—É–∫—Å–æ–≤–æ—á–Ω—ã–µ —Ç—Ä–∞–∫–∏ –¥–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 27.06it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –ü–ö –õ–ò–ú / –ë—Ä–∞—Å–ª–µ—Ç—ã —Ü–µ–ø–∏ –ø—Ä–æ—Ç–∏–≤–æ—Å–∫–æ–ª—å–∂–µ–Ω–∏—è: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 15.38it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –ü–ö –õ–ò–ú / –¶–µ–ø–∏ –ø—Ä–æ—Ç–∏–≤–æ—Å–∫–æ–ª—å–∂–µ–Ω–∏—è –¥–ª—è –ª–µ–≥–∫–æ–≤—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 14.84it/s]\n",
      "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä—Ñ—é–º –ø–æ–¥–≤–µ—Å–Ω–æ–π: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.39it/s]\n",
      "–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–¥—É–∫—Ç–æ–≤:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 28/30 [01:50<00:07,  3.94s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 199\u001b[0m\n\u001b[1;32m    189\u001b[0m mask_embeddings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    190\u001b[0m     compute_sentence_embeddings(gratitude_phrases),\n\u001b[1;32m    191\u001b[0m     compute_sentence_embeddings(delivery_phrases),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    195\u001b[0m     compute_sentence_embeddings(functionality_phrases),\n\u001b[1;32m    196\u001b[0m ]\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# –í—ã–∑–æ–≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –º–∞—Å–æ–∫ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m final_result \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_reviews\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_exploded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç\u001b[39;00m\n\u001b[1;32m    202\u001b[0m display(final_result[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_sentences\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey_thought\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword_count\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "Cell \u001b[0;32mIn[22], line 99\u001b[0m, in \u001b[0;36mprocess_reviews\u001b[0;34m(df_exploded, mask_embeddings, mask_names, threshold, eps, min_samples)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m remaining_clusters \u001b[38;5;241m=\u001b[39m \u001b[43mcluster_remaining_sentences\u001b[49m\u001b[43m(\u001b[49m\u001b[43munassigned_sentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å tqdm –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cluster_id, sentences \u001b[38;5;129;01min\u001b[39;00m tqdm(remaining_clusters\u001b[38;5;241m.\u001b[39mitems(), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproduct_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n",
      "Cell \u001b[0;32mIn[22], line 64\u001b[0m, in \u001b[0;36mcluster_remaining_sentences\u001b[0;34m(sentences, eps, min_samples)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcluster_remaining_sentences\u001b[39m(sentences, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m---> 64\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_sentence_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     clustering \u001b[38;5;241m=\u001b[39m DBSCAN(eps\u001b[38;5;241m=\u001b[39meps, min_samples\u001b[38;5;241m=\u001b[39mmin_samples, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(embeddings)\n\u001b[1;32m     67\u001b[0m     clusters \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[22], line 39\u001b[0m, in \u001b[0;36mcompute_sentence_embeddings\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     38\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# import spacy\n",
    "# from tqdm import tqdm\n",
    "# import logging\n",
    "\n",
    "# # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (GPU –∏–ª–∏ CPU)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ –æ—Ç –°–±–µ—Ä–±–∞–Ω–∫–∞\n",
    "# tokenizer = AutoTokenizer.from_pretrained('sberbank-ai/sbert_large_nlu_ru')\n",
    "# model = AutoModel.from_pretrained('sberbank-ai/sbert_large_nlu_ru').to(device)\n",
    "\n",
    "# # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "# logging.basicConfig(filename='./reviews_keywords/clustering.log', \n",
    "#                     level=logging.INFO, \n",
    "#                     format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ spaCy –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞\n",
    "# nlp = spacy.load(\"ru_core_news_lg\")\n",
    "\n",
    "# # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
    "# nltk.download('stopwords')\n",
    "# stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π\n",
    "# def compute_sentence_embeddings(sentences):\n",
    "#     if not sentences:\n",
    "#         return np.array([])  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤, –µ—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø—É—Å—Ç\n",
    "#     inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#     return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–∏–≤—è–∑–∫–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∫ –º–∞—Å–∫–∞–º —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º\n",
    "# def assign_to_masks(sentences, mask_embeddings, mask_names, threshold=0.65):\n",
    "#     assigned_sentences = []\n",
    "#     unassigned_sentences = []\n",
    "\n",
    "#     for sentence in sentences:\n",
    "#         sentence_emb = compute_sentence_embeddings([sentence])\n",
    "#         similarities = [np.max(cosine_similarity(sentence_emb, mask_emb)) for mask_emb in mask_embeddings]\n",
    "#         max_similarity = np.max(similarities)\n",
    "#         best_mask_index = np.argmax(similarities)\n",
    "\n",
    "#         if max_similarity > threshold:\n",
    "#             assigned_sentences.append(sentence)\n",
    "#             mask_name = mask_names[best_mask_index]\n",
    "#             logging.info(f\"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ '{sentence}' –ø—Ä–∏–≤—è–∑–∞–Ω–æ –∫ –º–∞—Å–∫–µ '{mask_name}' —Å –ø–æ—Ö–æ–∂–µ—Å—Ç—å—é {max_similarity:.2f}\")\n",
    "#         else:\n",
    "#             unassigned_sentences.append(sentence)\n",
    "#             logging.info(f\"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ '{sentence}' –Ω–µ –ø—Ä–∏–≤—è–∑–∞–Ω–æ –Ω–∏ –∫ –æ–¥–Ω–æ–π –º–∞—Å–∫–µ\")\n",
    "\n",
    "#     return assigned_sentences, unassigned_sentences\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
    "# def cluster_remaining_sentences(sentences, eps=0.25, min_samples=3):\n",
    "#     embeddings = compute_sentence_embeddings(sentences)\n",
    "#     clustering = DBSCAN(eps=eps, min_samples=min_samples, metric=\"cosine\").fit(embeddings)\n",
    "    \n",
    "#     clusters = {}\n",
    "#     for idx, label in enumerate(clustering.labels_):\n",
    "#         if label == -1:\n",
    "#             continue\n",
    "#         if label not in clusters:\n",
    "#             clusters[label] = []\n",
    "#         clusters[label].append(sentences[idx])\n",
    "    \n",
    "#     return clusters\n",
    "\n",
    "# # –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ –∏ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º\n",
    "# def process_reviews(df_exploded, mask_embeddings, mask_names, threshold=0.6, eps=0.25, min_samples=3):\n",
    "#     final_result = pd.DataFrame()\n",
    "\n",
    "#     # tqdm –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º\n",
    "#     for product_name, group in tqdm(df_exploded.groupby('product'), desc=\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–¥—É–∫—Ç–æ–≤\"):\n",
    "#         all_sentences = group['sentences'].tolist()\n",
    "\n",
    "#         # –ü—Ä–æ–ø—É—Å–∫, –µ—Å–ª–∏ –Ω–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
    "#         if not all_sentences:\n",
    "#             logging.info(f\"–ü—Ä–æ–ø—É—Å–∫ –ø—Ä–æ–¥—É–∫—Ç–∞ {product_name}, —Ç–∞–∫ –∫–∞–∫ –Ω–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.\")\n",
    "#             continue\n",
    "\n",
    "#         # –ü—Ä–∏–≤—è–∑–∫–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∫ –º–∞—Å–∫–∞–º\n",
    "#         assigned_sentences, unassigned_sentences = assign_to_masks(all_sentences, mask_embeddings, mask_names, threshold)\n",
    "\n",
    "#         # –ü—Ä–æ–ø—É—Å–∫, –µ—Å–ª–∏ –Ω–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏\n",
    "#         if not unassigned_sentences:\n",
    "#             logging.info(f\"–ü—Ä–æ–ø—É—Å–∫ –ø—Ä–æ–¥—É–∫—Ç–∞ {product_name}, —Ç–∞–∫ –∫–∞–∫ –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –±—ã–ª–∏ –ø—Ä–∏–≤—è–∑–∞–Ω—ã –∫ –º–∞—Å–∫–∞–º.\")\n",
    "#             continue\n",
    "\n",
    "#         # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
    "#         remaining_clusters = cluster_remaining_sentences(unassigned_sentences, eps, min_samples)\n",
    "\n",
    "#         # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å tqdm –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º\n",
    "#         for cluster_id, sentences in tqdm(remaining_clusters.items(), desc=f\"–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è {product_name}\"):\n",
    "#             if not sentences:  # –ü—Ä–æ–ø—É—Å–∫ –ø—É—Å—Ç—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "#                 continue\n",
    "#             cluster_text = \" | \".join(sentences)\n",
    "#             key_thought = extract_key_thought(cluster_text)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–Ω–µ–µ –æ–ø–∏—Å–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é\n",
    "\n",
    "#             df_cluster = pd.DataFrame({\n",
    "#                 'product': product_name,\n",
    "#                 'cluster_id': cluster_id,\n",
    "#                 'cluster_sentences': [cluster_text],\n",
    "#                 'key_thought': [key_thought],\n",
    "#                 'word_count': [count_words(cluster_text)]\n",
    "#             })\n",
    "\n",
    "#             final_result = pd.concat([final_result, df_cluster], ignore_index=True)\n",
    "\n",
    "#     return final_result\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –∫–ª—é—á–µ–≤–æ–π –º—ã—Å–ª–∏ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ\n",
    "# def extract_key_thought(cluster_sentences):\n",
    "#     sentences = cluster_sentences.split(\" | \")\n",
    "#     embeddings = compute_sentence_embeddings(sentences)\n",
    "    \n",
    "#     centroid = find_centroid(embeddings)\n",
    "#     similarities = cosine_similarity(embeddings, [centroid])\n",
    "#     key_sentence_index = np.argmax(similarities)\n",
    "    \n",
    "#     return sentences[key_sentence_index]\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ü–µ–Ω—Ç—Ä–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞ (—Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞)\n",
    "# def find_centroid(embeddings):\n",
    "#     return np.mean(embeddings, axis=0)\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Ç–µ—Ä–µ\n",
    "# def count_words(cluster_sentences):\n",
    "#     words = cluster_sentences.split()\n",
    "#     return len(words)\n",
    "\n",
    "# quality_phrases = [\n",
    "#     r'–ø—Ä–µ–∫—Ä–∞—Å–Ω–∞—è –≤–µ—â—å', r'–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–∞—è –≤–µ—â—å', \n",
    "#     r'–≤—Å–µ –ø—Ä–∏—à–ª–æ –≤ –∏–¥–µ–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏', r'—Ç–æ–≤–∞—Ä –≤ –æ—Ç–ª–∏—á–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏', \n",
    "#     r'–±–µ–∑ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π', r'—É–ø–∞–∫–æ–≤–∫–∞ —Ü–µ–ª–∞—è', r'—Ç–æ–≤–∞—Ä –±–µ–∑ –¥–µ—Ñ–µ–∫—Ç–æ–≤', \n",
    "#     r'–≤—Å–µ –¥–æ—à–ª–æ —Ü–µ–ª—ã–º', r'–¥–æ—Å—Ç–∞–≤–∫–∞ –±–µ–∑ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π', r'–∏–¥–µ–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ'\n",
    "# ]\n",
    "\n",
    "# functionality_phrases = [\n",
    "#     r'—Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ', r'—Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ', r'–≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç', r'—Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç', r'—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π', \n",
    "#     r'—Ñ—É–Ω–∫—Ü–∏–∏ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è', r'—Å –∑–∞–¥–∞—á–µ–π —Å–ø—Ä–∞–≤–∏–ª—Å—è', r'—Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –∑–∞–¥–∞—á–µ–π', r'–∑–∞–¥–∞—á—É —Å–≤–æ—é –≤—ã–ø–æ–ª–Ω–∏–ª', \n",
    "#     r'—Å–ø—Ä–∞–≤–∏–ª—Å—è –Ω–∞ –æ—Ç–ª–∏—á–Ω–æ', r'—Å–æ —Å–≤–æ–∏–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è', r'–∑–∞–¥–∞—á—É –≤—ã–ø–æ–ª–Ω–∏–ª'\n",
    "# ]\n",
    "# gratitude_phrases = [\n",
    "#     r'—Å–ø–∞—Å–∏–±–æ', r'—Ä–µ–∫–æ–º–µ–Ω–¥—É—é', r'—Å–æ–≤–µ—Ç—É—é', r'–ø—Ä–æ–¥–∞–≤–µ—Ü –º–æ–ª–æ–¥–µ—Ü', r'–±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω', r'–±–ª–∞–≥–æ–¥–∞—Ä—é', r'—Å–æ–≤–µ—Ç—É—é –∫ –ø–æ–∫—É–ø–∫–µ',\n",
    "#     r'—Å–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–µ', r'–≤—Å–µ–º —Å–æ–≤–µ—Ç—É—é', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ —Ç–æ–≤–∞—Ä', r'—Å–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤—Ü—É', r'–±–ª–∞–≥–æ–¥–∞—Ä—é –∑–∞ —Ç–æ–≤–∞—Ä', \n",
    "#     r'–±–æ–ª—å—à–æ–µ —Å–ø–∞—Å–∏–±–æ', r'–æ—á–µ–Ω—å –±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ –¥–æ—Å—Ç–∞–≤–∫—É', r'–æ–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç–æ–≤–∞—Ä', \n",
    "#     r'–ø—Ä–æ–¥–∞–≤—Ü—É –æ–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ—Å—Ç—å', r'—Å–ø–∞—Å–∏–±–æ –≤–∞–º', r'–±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω –∑–∞ —Ç–æ–≤–∞—Ä', \n",
    "#     r'—Å–ø–∞—Å–∏–±–æ, –≤—Å—ë —Ö–æ—Ä–æ—à–æ', r'–ø—Ä–æ–¥–∞–≤–µ—Ü –º–æ–ª–æ–¥–µ—Ü', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ —Ö–æ—Ä–æ—à–µ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ'\n",
    "# ]\n",
    "# delivery_phrases = [\n",
    "#     r'–ø—Ä–∏—à–µ–ª –±—ã—Å—Ç—Ä–æ', r'–±—ã—Å—Ç—Ä–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞', r'–ø—Ä–∏—à–µ–ª –≤–æ–≤—Ä–µ–º—è', r'–∑–∞–∫–∞–∑ –ø—Ä–∏—à–µ–ª —Ü–µ–ª—ã–π –∏ –≤–æ–≤—Ä–µ–º—è', \n",
    "#     r'–ø—Ä–∏—à–µ–ª —Ü–µ–ª—ã–π', r'–¥–æ—Å—Ç–∞–≤–∫–∞ –≤–æ–≤—Ä–µ–º—è', r'–≤—Å–µ –ø—Ä–∏—à–ª–æ —Ü–µ–ª—ã–º', r'—Ç–æ–≤–∞—Ä –ø—Ä–∏—à–µ–ª —Ü–µ–ª—ã–º', r'–ø—Ä–∏—à–µ–ª –≤ —Å—Ä–æ–∫',\n",
    "#     r'–ø—Ä–∏—à–µ–ª –≤–æ–≤—Ä–µ–º—è –∏ —Ü–µ–ª—ã–º', r'–ø–æ–ª—É—á–∏–ª –∑–∞–∫–∞–∑ –≤–æ–≤—Ä–µ–º—è', r'–¥–æ—Å—Ç–∞–≤–∫–∞ - –≤–æ!', r'–≤—Å–µ –ø—Ä–∏—à–ª–æ –∫–∞–∫ –Ω–∞–¥–æ', \n",
    "#     r'–ø—Ä–∏—à–µ–ª –≤ –ø–æ–ª–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ', r'–æ—Ç–ª–∏—á–Ω–∞—è —É–ø–∞–∫–æ–≤–∫–∞', r'–≤—Å–µ –¥–æ—à–ª–æ —Ü–µ–ª—ã–º', r'—É–ø–∞–∫–æ–≤–∞–Ω–æ –Ω–∞ —Å–æ–≤–µ—Å—Ç—å', \n",
    "#     r'–∫—Ä—É—Ç–∞—è —É–ø–∞–∫–æ–≤–∫–∞'\n",
    "# ]\n",
    "# confirmation_phrases = [\n",
    "#     r'–≤—Å—ë —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç', r'–≤—Å—ë –∫–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏', r'–≤—Å—ë –∫–∞–∫ –∑–∞—è–≤–ª–µ–Ω–æ', r'—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—é', \n",
    "#     r'–≤—Å—ë —Ü–µ–ª–æ–µ', r'–≤—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ', r'–≤—Å—ë –Ω–æ—Ä–º', r'–≤—Å—ë —Ö–æ—Ä–æ—à–æ', r'–∫–∞–∫ –≤—Å–µ–≥–¥–∞', r'–±–µ–∑ –ø—Ä–æ–±–ª–µ–º', \n",
    "#     r'–Ω–æ—Ä–º–∞–ª—å–Ω–æ —É–ø–∞–∫–æ–≤–∞–Ω–æ', r'–Ω–æ—Ä–º–∞–ª—å–Ω–æ', r'–≤—Å—ë –Ω–æ—Ä–º'\n",
    "# ]\n",
    "# simple_statements_phrases = [\n",
    "#     r'—Ö–æ—Ä–æ—à–∞—è –≤–µ—â—å', r'–∫–ª–∞—Å—Å–Ω–∞—è –≤–µ—â—å', r'–æ—Ç–ª–∏—á–Ω–∞—è –≤–µ—â—å', r'—É–¥–æ–±–Ω–æ', r'–Ω–æ—Ä–º–∞–ª—å–Ω–æ', r'—Ä–∞–±–æ—Ç–∞–µ—Ç', \n",
    "#     r'—Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ', r'—Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ', r'–≤—Å—ë –Ω–æ—Ä–º–∞–ª—å–Ω–æ', r'–≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç', r'–≤—Å—ë –æ–∫', \n",
    "#     r'–≤—Å—ë –æ–∫–µ–π', r'—Å—É–ø–µ—Ä', r'–∫–ª–∞—Å—Å', r'–Ω–æ—Ä–º', r'–æ—Ç–ª–∏—á–Ω–æ', r'—Ö–æ—Ä–æ—à–æ', r'–∏–¥–µ–∞–ª—å–Ω–æ', r'üëç', r'üëè', \n",
    "#     r'üòÜ', r'üî•', r'üíØ', r'–∫–ª–∞—Å—Åüëç', r'–≤—Å–µ —Å—É–ø–µ—Äüëç', r'üëçüëçüëç', r'üëçüòä'\n",
    "# ]\n",
    "\n",
    "\n",
    "# # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–∞—Å–æ–∫ –∏ –∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "# mask_names = [\n",
    "#     \"quality_phrases\",\n",
    "#     \"functionality_phrases\",\n",
    "#     \"gratitude_phrases\",\n",
    "#     \"delivery_phrases\",\n",
    "#     \"confirmation_phrases\",\n",
    "#     \"simple_statements_phrases\"\n",
    "# ]\n",
    "\n",
    "# mask_embeddings = [\n",
    "#     compute_sentence_embeddings(gratitude_phrases),\n",
    "#     compute_sentence_embeddings(delivery_phrases),\n",
    "#     compute_sentence_embeddings(confirmation_phrases),\n",
    "#     compute_sentence_embeddings(simple_statements_phrases),\n",
    "#     compute_sentence_embeddings(quality_phrases),\n",
    "#     compute_sentence_embeddings(functionality_phrases),\n",
    "# ]\n",
    "\n",
    "# # –í—ã–∑–æ–≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –º–∞—Å–æ–∫ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º\n",
    "# final_result = process_reviews(df_exploded, mask_embeddings, mask_names)\n",
    "\n",
    "# # –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "# display(final_result[['product', 'cluster_id', 'cluster_sentences', 'key_thought', 'word_count']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Organizing clusters for *Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç: 129it [00:00, 833690.63it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.41s/it]\n",
      "Organizing clusters for AutoVirazh / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –¥–≤—É—Ö–ø–æ—Ä—à–Ω–µ–≤–æ–π 85–ª –º–∏–Ω: 4it [00:00, 55007.27it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Recursive clustering: 0it [00:00, ?it/s]\n",
      "Organizing clusters for Clements / –í–∫–ª–∞–¥—ã—à –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π 100–º–∫–º –æ–±–ª–æ–∂–∫–∞: 220it [00:00, 851242.51it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.03it/s]\n",
      "Organizing clusters for Eternal way / –ë–µ—Å–ø—Ä–æ–≤–æ–¥–Ω–æ–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä–Ω—ã–π –Ω–∞—Å–æ—Å - –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä: 42it [00:00, 532207.76it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.65it/s]\n",
      "Organizing clusters for FST Auto / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ö–ª–∞—Å—Å–∏–∫–∞ 2 —à—Ç: 201it [00:00, 733729.42it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:03<00:00,  3.21it/s]\n",
      "Organizing clusters for FST Auto / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –°–ø–æ—Ä—Ç–∏–≤–Ω—ã–π —Å—Ç–∏–ª—å 2 —à—Ç: 231it [00:00, 1002985.74it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:03<00:00,  4.42it/s]\n",
      "Organizing clusters for Grand House / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –∞–Ω—Ç–∏–±–ª–∏–∫: 239it [00:00, 810378.86it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.50it/s]\n",
      "Organizing clusters for Lieblich Hause (Haz) / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –≤–æ–∑–¥—É—à–Ω—ã–π –±–µ—Å–ø—Ä–æ–≤–æ–¥–Ω–æ–π: 180it [00:00, 1403298.74it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  5.62it/s]\n",
      "Organizing clusters for Lieblich Hause / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏—Ñ–∞—Ä—ã: 232it [00:00, 875070.62it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:01<00:00,  3.65it/s]\n",
      "Organizing clusters for LiteRock / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –±–µ—Å–ø—Ä–æ–≤–æ–¥–Ω–æ–π: 28it [00:00, 278956.09it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Recursive clustering: 0it [00:00, ?it/s]\n",
      "Organizing clusters for MAZURA / –ê–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è —Ö–∞–º–µ–ª–µ–æ–Ω: 219it [00:00, 829018.57it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.22it/s]\n",
      "Organizing clusters for OD&STYLE / –û–±–ª–æ–∂–∫–∞ –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤–∫–ª–∞–¥—ã—à: 173it [00:00, 1172236.82it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 10.50it/s]\n",
      "Organizing clusters for RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏—Ñ–∞—Ä—ã: 281it [00:00, 1026654.55it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.33it/s]\n",
      "Organizing clusters for Romarina / –ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω—ã–π: 184it [00:00, 1162277.01it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:05<00:00,  1.19s/it]\n",
      "Organizing clusters for SHADOVtech / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –≤–æ–∑–¥—É—à–Ω—ã–π —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∏–π,–Ω–∞—Å–æ—Å –º–∞—à–∏–Ω: 254it [00:00, 739315.21it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.40s/it]\n",
      "Organizing clusters for StarLine / –ß–µ—Ö–æ–ª —Å–∏–ª–∏–∫–æ–Ω–æ–≤—ã–π –¥–ª—è –±—Ä–µ–ª–æ–∫–∞ –°—Ç–∞—Ä–ª–∞–π–Ω –ê63 –ê93 –ê66 –ê96: 150it [00:00, 1090373.66it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.79it/s]\n",
      "Organizing clusters for Stylish_Shock / –ö–æ–∂–∞–Ω–∞—è –æ–±–ª–æ–∂–∫–∞ –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –≤–∏–∑–∏—Ç–Ω–∏—Ü–µ–π: 210it [00:00, 808076.92it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00,  6.78it/s]\n",
      "Organizing clusters for SuperVision / –û—á–∫–∏ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, —Ä—ã–±–∞–ª–∫–∏, –∞–Ω—Ç–∏—Ñ–∞—Ä—ã: 202it [00:00, 685476.87it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.81it/s]\n",
      "Organizing clusters for –ú–∏—Å—Å–∏—Å –ê / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫ –∞–Ω—Ç–∏—Ñ–∞—Ä—ã: 56it [00:00, 599186.29it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.82it/s]\n",
      "Organizing clusters for –ü–∞—Ö–Ω–µ—Ç –∏ –¢–æ—á–∫–∞ / –ê—Ä–æ–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –≤ –º–∞—à–∏–Ω—É –∞–≤—Ç–æ–ø–∞—Ä—Ñ—é–º –ø–æ–¥–≤–µ—Å–Ω–æ–π: 30it [00:00, 332881.27it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12671.61it/s]\n",
      "Organizing clusters for –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –°–æ–ª–Ω—Ü–µ–∑–∞—â–∏—Ç–Ω—ã–µ –≤–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ: 38it [00:00, 547709.80it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12372.58it/s]\n",
      "Organizing clusters for –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥–æ –≤–∏–¥–µ–Ω–∏—è –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª–µ–π: 245it [00:00, 804702.02it/s]\n",
      "Recursive clustering: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02<00:00,  3.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>key_thought</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç</td>\n",
       "      <td>–°–≤–æ–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç, –æ—Å–æ–±–µ–Ω–Ω–æ –∂—ë–ª—Ç—ã–µ –ª–∏–Ω–∑—ã ...</td>\n",
       "      <td>–•–ª–∏–ø–∫–∏–µ –ø–æ—Å–ª–µ –ø—Ä–æ—Ç–∏—Ä–∫–µ –æ–¥–Ω–æ —Å—Ç–µ–∫–ª–æ –≤—ã–≤–æ–ª–µ–ª–æ—Å—å,...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç</td>\n",
       "      <td>–í—Å—ë –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ, —Å–ø–∞—Å–∏–±–æ | –ù–æ—Ä–º–∞–ª—å–Ω–æ | –û—Ç–ª–∏—á–Ω...</td>\n",
       "      <td>–í—Å—ë –æ—Ç–ª–∏—á–Ω–æ</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç</td>\n",
       "      <td>–î–µ—Ç—Å–∫–∏–µ | –ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ | –ù—É –æ—á–µ–Ω—å ...</td>\n",
       "      <td>–ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clements / –í–∫–ª–∞–¥—ã—à –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∑—Ä–∞—á–Ω...</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω—ã–π –≤–∫–ª–∞–¥—ã—à, –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ–º–µ—Å—Ç–∏–ª–∏...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π –≤–∫–ª–∞–¥—ã—à, –ø–ª–æ—Ç–Ω—ã–π, –ø–æ —Ä–∞–∑–º–µ—Ä—É –ø–æ–¥–æ—à—ë–ª</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clements / –í–∫–ª–∞–¥—ã—à –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∑—Ä–∞—á–Ω...</td>\n",
       "      <td>–†–µ–∫–æ–º–µ–Ω–¥—É—é! | –ö–∞—á–µ—Å—Ç–≤–æ —Ö–æ—Ä–æ—à–µ–µ! | –ö–∞—á–µ—Å—Ç–≤–æ —Ö–æ—Ä...</td>\n",
       "      <td>–ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–ª–∏—á–Ω–æ–µ</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>–°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...</td>\n",
       "      <td>–ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å –†–µ–∫–æ–º–µ–Ω–¥—É—é | –ú—É–∂—É –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å ...</td>\n",
       "      <td>–ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å –†–µ–∫–æ–º–µ–Ω–¥—É—é</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>–°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...</td>\n",
       "      <td>–û–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ!!! | –°–ø–∞—Å–∏–±–æ!) | –°–ø–∞—Å–∏–±–æ! | –°...</td>\n",
       "      <td>–°–ø–∞—Å–∏–±–æ!üëç</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>–°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...</td>\n",
       "      <td>–°—É–ø–µ—Ä  . | –°—É–ø–µ—Ä! | –û—Ç–ª–∏—á–Ω–æ! | –û—Ç–ª–∏—á–Ω–æ</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ!</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>–°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...</td>\n",
       "      <td>–û–¢–õ–ò–ß–ù–´–ï | —à–∏–∫–∞—Ä–Ω—ã–µ | –û—á–µ–Ω—å —Ö–æ—Ä–æ—à–∏–π</td>\n",
       "      <td>–û–¢–õ–ò–ß–ù–´–ï</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>–°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...</td>\n",
       "      <td>ü§ò | üëçüëç | üëçüëçüëç</td>\n",
       "      <td>üëçüëçüëç</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               product  \\\n",
       "0    *Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç   \n",
       "1    *Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç   \n",
       "2    *Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç   \n",
       "3    Clements / –í–∫–ª–∞–¥—ã—à –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∑—Ä–∞—á–Ω...   \n",
       "4    Clements / –í–∫–ª–∞–¥—ã—à –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∑—Ä–∞—á–Ω...   \n",
       "..                                                 ...   \n",
       "163  –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...   \n",
       "164  –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...   \n",
       "165  –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...   \n",
       "166  –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...   \n",
       "167  –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...   \n",
       "\n",
       "                                     cluster_sentences  \\\n",
       "0    –°–≤–æ–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç, –æ—Å–æ–±–µ–Ω–Ω–æ –∂—ë–ª—Ç—ã–µ –ª–∏–Ω–∑—ã ...   \n",
       "1    –í—Å—ë –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ, —Å–ø–∞—Å–∏–±–æ | –ù–æ—Ä–º–∞–ª—å–Ω–æ | –û—Ç–ª–∏—á–Ω...   \n",
       "2    –î–µ—Ç—Å–∫–∏–µ | –ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ | –ù—É –æ—á–µ–Ω—å ...   \n",
       "3    –û—á–µ–Ω—å —É–¥–æ–±–Ω—ã–π –≤–∫–ª–∞–¥—ã—à, –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ–º–µ—Å—Ç–∏–ª–∏...   \n",
       "4    –†–µ–∫–æ–º–µ–Ω–¥—É—é! | –ö–∞—á–µ—Å—Ç–≤–æ —Ö–æ—Ä–æ—à–µ–µ! | –ö–∞—á–µ—Å—Ç–≤–æ —Ö–æ—Ä...   \n",
       "..                                                 ...   \n",
       "163  –ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å –†–µ–∫–æ–º–µ–Ω–¥—É—é | –ú—É–∂—É –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å ...   \n",
       "164  –û–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ!!! | –°–ø–∞—Å–∏–±–æ!) | –°–ø–∞—Å–∏–±–æ! | –°...   \n",
       "165             –°—É–ø–µ—Ä  . | –°—É–ø–µ—Ä! | –û—Ç–ª–∏—á–Ω–æ! | –û—Ç–ª–∏—á–Ω–æ   \n",
       "166                –û–¢–õ–ò–ß–ù–´–ï | —à–∏–∫–∞—Ä–Ω—ã–µ | –û—á–µ–Ω—å —Ö–æ—Ä–æ—à–∏–π   \n",
       "167                                       ü§ò | üëçüëç | üëçüëçüëç   \n",
       "\n",
       "                                           key_thought  word_count  \n",
       "0    –•–ª–∏–ø–∫–∏–µ –ø–æ—Å–ª–µ –ø—Ä–æ—Ç–∏—Ä–∫–µ –æ–¥–Ω–æ —Å—Ç–µ–∫–ª–æ –≤—ã–≤–æ–ª–µ–ª–æ—Å—å,...          53  \n",
       "1                                          –í—Å—ë –æ—Ç–ª–∏—á–Ω–æ          10  \n",
       "2                             –ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ           9  \n",
       "3        –û—Ç–ª–∏—á–Ω—ã–π –≤–∫–ª–∞–¥—ã—à, –ø–ª–æ—Ç–Ω—ã–π, –ø–æ —Ä–∞–∑–º–µ—Ä—É –ø–æ–¥–æ—à—ë–ª         152  \n",
       "4                                    –ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–ª–∏—á–Ω–æ–µ          77  \n",
       "..                                                 ...         ...  \n",
       "163                         –ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å –†–µ–∫–æ–º–µ–Ω–¥—É—é          10  \n",
       "164                                          –°–ø–∞—Å–∏–±–æ!üëç           8  \n",
       "165                                           –û—Ç–ª–∏—á–Ω–æ!           8  \n",
       "166                                           –û–¢–õ–ò–ß–ù–´–ï           6  \n",
       "167                                                üëçüëçüëç           5  \n",
       "\n",
       "[168 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (GPU –∏–ª–∏ CPU)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ü–µ–Ω—Ç—Ä–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞ (—Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞)\n",
    "# def find_centroid(embeddings):\n",
    "#     return np.mean(embeddings, axis=0)\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –∫–ª—é—á–µ–≤–æ–π –º—ã—Å–ª–∏ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ\n",
    "# def extract_key_thought(cluster_sentences):\n",
    "#     sentences = cluster_sentences.split(\" | \")\n",
    "#     embeddings = compute_sentence_embeddings(sentences)\n",
    "    \n",
    "#     centroid = find_centroid(embeddings)\n",
    "#     similarities = cosine_similarity(embeddings, [centroid])\n",
    "#     key_sentence_index = np.argmax(similarities)\n",
    "    \n",
    "#     return sentences[key_sentence_index]\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Ç–µ—Ä–µ\n",
    "# def count_words(cluster_sentences):\n",
    "#     words = cluster_sentences.split()\n",
    "#     return len(words)\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "# def compute_sentence_embeddings(sentences):\n",
    "#     inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#     embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "#     return embeddings\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∫—Ä—É–ø–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "# def recluster_large_cluster(cluster_sentences, eps=0.1, min_samples=2):\n",
    "#     sentences = cluster_sentences.split(\" | \")\n",
    "    \n",
    "#     embeddings = compute_sentence_embeddings(sentences)\n",
    "    \n",
    "#     re_clustering = DBSCAN(eps=eps, min_samples=min_samples, metric=\"cosine\").fit(embeddings)\n",
    "    \n",
    "#     re_cluster_dict = {}\n",
    "#     for idx, label in enumerate(re_clustering.labels_):\n",
    "#         if label == -1:\n",
    "#             continue\n",
    "#         label_str = str(label)\n",
    "#         if label_str not in re_cluster_dict:\n",
    "#             re_cluster_dict[label_str] = []\n",
    "#         re_cluster_dict[label_str].append(sentences[idx])\n",
    "    \n",
    "#     return [\" | \".join(cluster) for cluster in re_cluster_dict.values()]\n",
    "\n",
    "# # –†–µ–∫—É—Ä—Å–∏–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –∫—Ä—É–ø–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "# def recursive_clustering(cluster_sentences, threshold, eps=0.25, min_samples=3, min_eps=0.05):\n",
    "#     current_eps = eps\n",
    "#     new_clusters = [cluster_sentences]\n",
    "\n",
    "#     while True:\n",
    "#         next_clusters = []\n",
    "#         reclustered_any = False\n",
    "        \n",
    "#         for cluster in new_clusters:\n",
    "#             if count_words(cluster) > threshold:\n",
    "#                 while current_eps >= min_eps:\n",
    "#                     reclustered = recluster_large_cluster(cluster, eps=current_eps, min_samples=min_samples)\n",
    "#                     if len(reclustered) > 1:\n",
    "#                         next_clusters.extend(reclustered)\n",
    "#                         reclustered_any = True\n",
    "#                         break  # –ö–ª–∞—Å—Ç–µ—Ä —É—Å–ø–µ—à–Ω–æ —Ä–∞–∑–¥–µ–ª–µ–Ω, –≤—ã—Ö–æ–¥–∏–º –∏–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ —Ü–∏–∫–ª–∞\n",
    "#                     else:\n",
    "#                         current_eps *= 0.9  # –£–º–µ–Ω—å—à–∞–µ–º eps –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞\n",
    "                \n",
    "#                 if len(reclustered) == 1:\n",
    "#                     # –ï—Å–ª–∏ –∫–ª–∞—Å—Ç–µ—Ä —Ç–∞–∫ –∏ –Ω–µ –±—ã–ª —Ä–∞–∑–¥–µ–ª–µ–Ω, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –æ–±—Ä–∞—Ç–Ω–æ\n",
    "#                     next_clusters.append(cluster)\n",
    "#             else:\n",
    "#                 next_clusters.append(cluster)\n",
    "        \n",
    "#         new_clusters = next_clusters\n",
    "        \n",
    "#         if not reclustered_any:\n",
    "#             break\n",
    "    \n",
    "#     return new_clusters\n",
    "\n",
    "# # –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –ø–æ —Ç–æ–≤–∞—Ä–∞–º\n",
    "# final_result = pd.DataFrame()\n",
    "\n",
    "# for product_name, group in df_exploded.groupby('product'):\n",
    "#     all_sentences = group['sentences'].tolist()\n",
    "\n",
    "#     # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –±–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ –±–∞—Ç—á–∏\n",
    "#     all_embeddings = compute_sentence_embeddings(all_sentences)\n",
    "\n",
    "#     # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏\n",
    "#     clustering = DBSCAN(eps=0.25, min_samples=3, metric=\"cosine\").fit(all_embeddings)\n",
    "\n",
    "#     cluster_dict = {}\n",
    "#     for idx, label in tqdm(enumerate(clustering.labels_), desc=f\"Organizing clusters for {product_name}\"):\n",
    "#         if label == -1:\n",
    "#             continue\n",
    "#         label_str = str(label)\n",
    "#         if label_str not in cluster_dict:\n",
    "#             cluster_dict[label_str] = set()\n",
    "#         cluster_dict[label_str].add(all_sentences[idx])\n",
    "\n",
    "#     clusters = [\" | \".join(sentences) for sentences in cluster_dict.values()]\n",
    "#     threshold = np.mean([count_words(cluster) for cluster in clusters]) * 1.5\n",
    "\n",
    "#     final_clusters = []\n",
    "#     for cluster in tqdm(clusters, desc=\"Recursive clustering\"):\n",
    "#         final_clusters.extend(recursive_clustering(cluster, threshold))\n",
    "\n",
    "#     df_exploded_sorted = pd.DataFrame({'product': product_name, 'cluster_sentences': final_clusters})\n",
    "#     df_exploded_sorted['word_count'] = df_exploded_sorted['cluster_sentences'].apply(count_words)\n",
    "#     df_exploded_sorted['key_thought'] = df_exploded_sorted['cluster_sentences'].apply(extract_key_thought)\n",
    "\n",
    "#     df_exploded_sorted = df_exploded_sorted.sort_values(by='word_count', ascending=False)\n",
    "\n",
    "#     final_result = pd.concat([final_result, df_exploded_sorted], ignore_index=True)\n",
    "\n",
    "# # –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "# display(final_result[['product', 'cluster_sentences', 'key_thought', 'word_count']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –í—Å—ë –æ—Ç–ª–∏—á–Ω–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–ª–∏—á–Ω–æ–µ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–π, –ø—Ä–æ—á–Ω—ã–π\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –í—Å–µ –æ—Ç–ª–∏—á–Ω–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä!\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –í—Å–µ –æ—Ç–ª–∏—á–Ω–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –í—Å—ë –æ—Ç–ª–∏—á–Ω–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9553651809692383. –ò—Å–∫–ª—é—á–∞–µ–º –ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9553651809692383. –ò—Å–∫–ª—é—á–∞–µ–º –ú—É–∂—É –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å —Å–ø–∞—Å–∏–±–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9777071475982666. –ò—Å–∫–ª—é—á–∞–µ–º –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –°–ø–∞—Å–∏–±–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –í—Å—ë –æ—Ç–ª–∏—á–Ω–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9922985434532166. –ò—Å–∫–ª—é—á–∞–µ–º –ö–ª–∞—Å—Å–Ω—ã–π –∞–ø–ø–∞—Ä–∞—Ç, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9553651809692383. –ò—Å–∫–ª—é—á–∞–µ–º –ú—É–∂—É –æ—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–π –≤–∫–ª–∞–¥—ã—à\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –í—Å–µ –æ—Ç–ª–∏—á–Ω–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9777071475982666. –ò—Å–∫–ª—é—á–∞–µ–º –£–¥–æ–±–Ω–∞—è, —Ö–æ—Ä–æ—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9777071475982666. –ò—Å–∫–ª—é—á–∞–µ–º –•–æ—Ä–æ—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9553651809692383. –ò—Å–∫–ª—é—á–∞–µ–º –ü–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å, —Å–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–µ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9777071475982666. –ò—Å–∫–ª—é—á–∞–µ–º –•–æ—Ä–æ—à–∏–π —Ç–æ–≤–∞—Ä\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä!\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9922985434532166. –ò—Å–∫–ª—é—á–∞–µ–º –ö–ª–∞—Å—Å–Ω–∞—è –≤–µ—â—å!\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9553651809692383. –ò—Å–∫–ª—é—á–∞–µ–º –ú—É–∂—É –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–π —á–µ—Ö–æ–ª\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –í—Å–µ –æ—Ç–ª–∏—á–Ω–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, —Å–æ–≤–µ—Ç—É—é\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 1.0000001192092896. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ñ–∏–≥–µ–Ω–Ω—ã–π —Å–ø–∞—Å–∏–±–æ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9142447710037231. –ò—Å–∫–ª—é—á–∞–µ–º –ö—Ä–∞—Å–∏–≤—ã–π, –∫–æ–∂–∞–Ω—ã–π, –≤–º–µ—Å—Ç–∏—Ç–µ–ª—å–Ω—ã–π\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9553651809692383. –ò—Å–∫–ª—é—á–∞–µ–º –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è, –ø–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –û—Ç–ª–∏—á–Ω–∞—è –≤–µ—â—å\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9922985434532166. –ò—Å–∫–ª—é—á–∞–µ–º –û—á–∫–∏ –∫–ª–∞—Å—Å–Ω—ã–µ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9553651809692383. –ò—Å–∫–ª—é—á–∞–µ–º –°—É–ø–µ—Ä, –æ—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9777071475982666. –ò—Å–∫–ª—é—á–∞–µ–º –û—á–µ–Ω—å —Ö–æ—Ä–æ—à–∏–µ\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –°–ø–∞—Å–∏–±–æ, –æ—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9945003986358643. –ò—Å–∫–ª—é—á–∞–µ–º –í—Å–µ –æ—Ç–ª–∏—á–Ω–æ !\n",
      "–ë–ª–∏–∑–æ—Å—Ç—å - 0.9553651809692383. –ò—Å–∫–ª—é—á–∞–µ–º –ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å –†–µ–∫–æ–º–µ–Ω–¥—É—é\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>key_thought</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç</td>\n",
       "      <td>–°–≤–æ–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç, –æ—Å–æ–±–µ–Ω–Ω–æ –∂—ë–ª—Ç—ã–µ –ª–∏–Ω–∑—ã ...</td>\n",
       "      <td>–•–ª–∏–ø–∫–∏–µ –ø–æ—Å–ª–µ –ø—Ä–æ—Ç–∏—Ä–∫–µ –æ–¥–Ω–æ —Å—Ç–µ–∫–ª–æ –≤—ã–≤–æ–ª–µ–ª–æ—Å—å,...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç</td>\n",
       "      <td>–î–µ—Ç—Å–∫–∏–µ | –ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ | –ù—É –æ—á–µ–Ω—å ...</td>\n",
       "      <td>–ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Clements / –í–∫–ª–∞–¥—ã—à –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∑—Ä–∞—á–Ω...</td>\n",
       "      <td>–í–º–µ—Å—Ç–∏–ª–∏—Å—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã: –¢–°, —Å—Ç—Ä–∞—Ö–æ–≤—ã–µ, –ø–∞—Å–ø–æ...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π –≤–∫–ª–∞–¥—ã—à, –ø–ª–æ—Ç–Ω—ã–π, –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤–æ—à–ª–∏...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Eternal way / –ë–µ—Å–ø—Ä–æ–≤–æ–¥–Ω–æ–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∞–∫–∫—É–º...</td>\n",
       "      <td>–ó–∞–∫–∞–∑–∞–ª–∞ —Å–µ–±–µ –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä, –º–µ–Ω—è –ø–æ–¥–∫—É–ø–∏–ª –Ω–µ–æ–±—ã—á...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ë—Ä–∞–ª–∞ –≤ –ø–æ–¥–∞—Ä–æ–∫ –º—É–∂—É –°—Ä–∞–∑—É ...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FST Auto / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ö–ª–∞—Å—Å–∏–∫–∞ 2 —à—Ç</td>\n",
       "      <td>–ö–∞–∫ –∏–≥—Ä—É—à–µ—á–Ω—ã–µ, –ª—ë–≥–∫–∏–µ, –Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤...</td>\n",
       "      <td>–°–∫–æ–ª—å–∫–æ —Å—Ç–æ—è—Ç, —Ç–∞–∫ –∏ –≤—ã–≥–ª—è–¥—è—Ç: –¥—ë—à–µ–≤–æ –∏ –ø—Ä–æ—Å—Ç–æ</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FST Auto / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –°–ø–æ—Ä—Ç–∏–≤–Ω—ã–π —Å—Ç–∏–ª—å...</td>\n",
       "      <td>–ö–∞–∫ –∏–≥—Ä—É—à–µ—á–Ω—ã–µ, –ª—ë–≥–∫–∏–µ, –Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤...</td>\n",
       "      <td>–°–∫–æ–ª—å–∫–æ —Å—Ç–æ—è—Ç, —Ç–∞–∫ –∏ –≤—ã–≥–ª—è–¥—è—Ç: –¥—ë—à–µ–≤–æ –∏ –ø—Ä–æ—Å—Ç–æ</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Grand House / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –∞–Ω—Ç–∏–±–ª–∏–∫</td>\n",
       "      <td>–ì–æ–¥–Ω—ã–µ –æ—á–∫–∏, –Ω–æ—á—å—é –∫–∞–∫ –¥–Ω—ë–º –µ–¥–µ—à—å, –¥–Ω—ë–º —Å–æ–ª–Ω—Ü–µ...</td>\n",
       "      <td>–ü–æ–ª –¥–Ω—è —Å–µ–≥–æ–¥–Ω—è –µ—Ö–∞–ª –≤ –∂–µ–ª—Ç—ã—Ö –æ—á–∫–∞—Ö, –≥–ª–∞–∑–∞ –Ω–µ ...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Grand House / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –∞–Ω—Ç–∏–±–ª–∏–∫</td>\n",
       "      <td>–û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ, –º—É–∂—É –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é | –û—á...</td>\n",
       "      <td>–û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ, –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Lieblich Hause (Haz) / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –≤–æ–∑–¥—É—à–Ω—ã–π –±–µ...</td>\n",
       "      <td>–ï—Å—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –º–∞–Ω–æ–º–µ—Ç—Ä, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ –Ω–µ –Ω–∞...</td>\n",
       "      <td>–ù–∞–∫–∞—á–∞–ª 2 –∫–æ–ª–µ—Å–∞ –¥–ª—è –≤–µ–ª–∏–∫–∞ –¥–æ 3 –∞—Ç–º–æ—Å—Ñ–µ—Ä - —Å–ø...</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Lieblich Hause (Haz) / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –≤–æ–∑–¥—É—à–Ω—ã–π –±–µ...</td>\n",
       "      <td>–ö—É–ø–∏–ª –∫–∞—á–∞—Ç—å –≤–∞—Ç—Ä—É—à–∫—É –∏ –¥–ª—è –≤–µ–ª–æ—Å–∏–ø–µ–¥–æ–≤ –†–∞–±–æ—Ç–∞...</td>\n",
       "      <td>–ü–æ–∫—É–ø–∞–ª –¥–ª—è –≤–µ–ª–æ—Å–∏–ø–µ–¥–∞, –æ—Ç–ª–∏—á–Ω–∞—è —à—Ç—É–∫–∞ –ü—Ä–æ–±–æ–≤–∞...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Lieblich Hause / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, ...</td>\n",
       "      <td>–û—á–µ–Ω—å –ø–æ–ª–µ–∑–Ω—ã–µ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –¥–µ—à—ë–≤—É...</td>\n",
       "      <td>–£–¥–æ–±–Ω—ã–µ, –æ–±–ª–µ–≥—á–∞—é—Ç –≤–æ–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ —è—Ä–∫–æ–º —Å–≤–µ—Ç–µ –†–µ...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Lieblich Hause / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, ...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –£–¥–æ–±–Ω—ã–µ –†–µ–∫–æ–º–µ–Ω–¥—É—é | –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –£–¥–æ–±–Ω—ã–µ –†–µ–∫–æ–º–µ–Ω–¥—É—é</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Lieblich Hause / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, ...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, —Å–ø–∞—Å–∏–±–æ —Ö–æ—Ä–æ—à–∏–π | –í—Å–µ —Ö–æ—Ä–æ—à–æ –û—á–∫...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, —Å–ø–∞—Å–∏–±–æ —Ö–æ—Ä–æ—à–∏–π</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>MAZURA / –ê–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è —Ö–∞–º–µ–ª–µ–æ–Ω</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, –º–∞—Ç–µ—Ä–∏–∞–ª –æ—Ç–ª–∏—á–Ω—ã–π –∑–∞ —Å–≤–æ—é –∞–∏–Ω–Ω—É ...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, –ª—ë–≥–∫–∏–µ –∏ —É–¥–æ–±–Ω—ã–µ –í —Ö–æ—Ä–æ—à–µ–º —á–µ—Ö–ª–µ...</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>MAZURA / –ê–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è —Ö–∞–º–µ–ª–µ–æ–Ω</td>\n",
       "      <td>–ñ–∞–ª–µ—é, —á—Ç–æ –Ω–µ –∫—É–ø–∏–ª–∞ –∏—Ö —Ä–∞–Ω—å—à–µ –ó–∞–∫–∞–∑–∞–ª–∞ —Ç–æ–ª—å–∫–æ...</td>\n",
       "      <td>–ñ–∞–ª–µ—é, —á—Ç–æ –Ω–µ –∫—É–ø–∏–ª–∞ –∏—Ö —Ä–∞–Ω—å—à–µ –ó–∞–∫–∞–∑–∞–ª–∞ —Ç–æ–ª—å–∫–æ...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>MAZURA / –ê–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è —Ö–∞–º–µ–ª–µ–æ–Ω</td>\n",
       "      <td>–û—á–∫–∏ —Ö–æ—Ä–æ—à–∏ –í–∏–¥–Ω–æ –≤ –Ω–∏—Ö –Ω–∞ —Ç—Ä–∞—Å—Å–µ —Ö–æ—Ä–æ—à–æ | –û—Ç–ª...</td>\n",
       "      <td>–û—á–∫–∏ —Ö–æ—Ä–æ—à–∏ –í–∏–¥–Ω–æ –≤ –Ω–∏—Ö –Ω–∞ —Ç—Ä–∞—Å—Å–µ —Ö–æ—Ä–æ—à–æ</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...</td>\n",
       "      <td>–û—á–∫–∏ –Ω—Ä–∞–≤—è—Ç—Å—è –ó–∞—Ç–µ–º–Ω—è—é—Ç –≤ —Å–æ–ª–Ω–µ—á–Ω—É—é –ø–æ–≥–æ–¥—É –∏ –æ...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–µ —Å—Ç–∏–ª—å–Ω—ã–µ –æ—á–∫–∏ –∏ —Ö–æ—Ä–æ—à–æ –∑–∞—â–∏—â–∞—é—Ç –æ—Ç —Å–æ...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...</td>\n",
       "      <td>–û—á–∫–∏ —Ü–µ–ª—ã–µ, –Ω–æ—Ä–º –¢–æ–ª—å–∫–æ –æ—Å—Ç–∞–≤–ª—è—é—Ç —Å–ª–µ–¥—ã –Ω–∞ –ø–µ—Ä...</td>\n",
       "      <td>–û—á–∫–∏ –Ω–µ –ø–ª–æ—Ö–∏–µ, –Ω–æ —Ö–ª–∏–ø–∫–∏–µ, –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ —Ü–µ–Ω–µ</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –∑–∞ —Å–≤–æ–∏ –¥–µ–Ω—å–≥–∏, —è –±—ã —Å–∫–∞–∑–∞–ª –æ—Ç–ª–∏—á...</td>\n",
       "      <td>–û—á–∫–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∫–ª–∞—Å—Å–Ω—ã–µ, –∑–∞—è–≤–ª–µ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...</td>\n",
       "      <td>–°—É–ø–µ—Ä –æ—á–∫–∏ –∑–∞ —Ç–∞–∫—É—é —Ü–µ–Ω—É, –∑–∞–∫–∞–∑—ã–≤–∞–ª–∞ –º—É–∂—É, –æ—á–µ...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, –∑–∞–∫–∞–∑–∞–ª–∞ –µ—â—ë, –¥–ª—è —Å—ã–Ω–∞</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –ø–æ–ª—å–∑—É—é—Å—å, –Ω–æ –Ω–µ –≤—Å–µ–≥–¥–∞ | –û—á–∫–∏ –Ω–æ...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –ø–æ–ª—å–∑—É—é—Å—å, –Ω–æ –Ω–µ –≤—Å–µ–≥–¥–∞</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...</td>\n",
       "      <td>–ë–æ–ª—å—à–æ–µ —Å–ø–∞—Å–∏–±–æ –û—á–∫–∏ –æ–≥–æ–Ω—å –¥–∞–∂–µ —Å –æ—á–∫–∞–º–∏ –¥–ª—è –∑...</td>\n",
       "      <td>–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—á–∫–∏ –ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Romarina / –ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω—ã–π</td>\n",
       "      <td>–ù–∞ –≤–µ–ª–∏–∫–∞—Ö –∏—Å–ø—Ä–æ–±–æ–≤–∞–ª –ù–∞–∫–∞—á–∏–≤–∞–µ—Ç –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∫...</td>\n",
       "      <td>–ö–æ–º–ø–∞–∫—Ç–Ω—ã–π, –µ—Å—Ç—å —Å—É–º–æ—á–∫–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è, –ª–µ–≥–∫–æ —É...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Romarina / –ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω—ã–π</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π –Ω–∞—Å–æ—Å –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ—Å—Ç–∞–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç—å...</td>\n",
       "      <td>–ù–∞—Å–æ—Å –æ—Ç–ª–∏—á–Ω—ã–π –û—á–µ–Ω—å –¥–æ–≤–æ–ª–µ–Ω, –±—Ä–∞–ª –¥–ª—è –≤–µ–ª–æ—Å–∏–ø...</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Romarina / –ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω—ã–π</td>\n",
       "      <td>–ù–∞–∫–∞—á–∞–ª –¥–≤–∞ —Ä–∞—Å—à–∏—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –±–∞–∫–∞ –ø–æ 8 –ª–∏—Ç—Ä–æ–≤ —Å ...</td>\n",
       "      <td>–ù–∞–∫–∞—á–∞–ª –∫–æ–ª–µ—Å–∞ —Å–∞–º–æ–∫–∞—Ç—É, –ø–æ–¥–∫–∞—á–∞–ª –ø–µ—Ä–µ–¥–Ω–∏–µ –Ω–∞ ...</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SHADOVtech / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –≤–æ–∑–¥—É—à–Ω—ã...</td>\n",
       "      <td>–ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –¥–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ, –¥–∞...</td>\n",
       "      <td>–ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä —Ö–æ—Ä–æ—à–∏–π, —Å –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–ø—É—â–µ–Ω–Ω–æ–≥–æ –∫–æ–ª...</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>StarLine / –ß–µ—Ö–æ–ª —Å–∏–ª–∏–∫–æ–Ω–æ–≤—ã–π –¥–ª—è –±—Ä–µ–ª–æ–∫–∞ –°—Ç–∞—Ä–ª...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π —á–µ—Ö–æ–ª –•–æ—Ä–æ—à–∞—è —Ü–µ–Ω–∞ –ü–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å –∫–∞—á–µ—Å—Ç...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π —á–µ—Ö–æ–ª –•–æ—Ä–æ—à–∞—è —Ü–µ–Ω–∞ –ü–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å –∫–∞—á–µ—Å—Ç...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>StarLine / –ß–µ—Ö–æ–ª —Å–∏–ª–∏–∫–æ–Ω–æ–≤—ã–π –¥–ª—è –±—Ä–µ–ª–æ–∫–∞ –°—Ç–∞—Ä–ª...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ –ø–æ–¥–æ—à—ë–ª üëç | –†–µ–∫–æ–º–µ–Ω–¥—É—é!üëçüèª | –ü–æ–¥–æ—à–µ–ª –æ—Ç...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ –ø–æ–¥–æ—à–µ–ª –†–µ–∫–æ–º–µ–Ω–¥—É—é</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Stylish_Shock / –ö–æ–∂–∞–Ω–∞—è –æ–±–ª–æ–∂–∫–∞ –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ...</td>\n",
       "      <td>–û—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è —Ç–æ–≤–∞—Ä –û–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤...</td>\n",
       "      <td>–°–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤—Ü—É –∑–∞ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω—É—é –¥–æ—Å—Ç–∞–≤–∫—É, –æ—á–µ–Ω...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Stylish_Shock / –ö–æ–∂–∞–Ω–∞—è –æ–±–ª–æ–∂–∫–∞ –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ...</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–∞—è –∏ –ø–æ–ª–µ–∑–Ω–∞—è –≤–µ—â—å –ü–æ–ª–æ–∂–∏–ª–∞ –≤—Å—ë –¥–æ–∫...</td>\n",
       "      <td>–î–∞–≤–Ω–æ —Ö–æ—Ç–µ–ª–∞ —Ç–∞–∫–æ–π –æ—Ä–≥–∞–Ω–∞–π–∑–µ—Ä –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –í...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>SuperVision / –û—á–∫–∏ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, ...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä –®–∏–∫–∞—Ä–Ω—ã–µ –æ—á–∫–∏ –ö–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –†–µ...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä –®–∏–∫–∞—Ä–Ω—ã–µ –æ—á–∫–∏ –ö–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –†–µ...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>SuperVision / –û—á–∫–∏ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, ...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏, –º—É–∂—É –±—Ä–∞–ª–∞ –≤ –ø–æ–¥–∞—Ä–æ–∫, –æ—Å—Ç–∞–ª—Å—è –¥...</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏, –º—É–∂—É –±—Ä–∞–ª–∞ –≤ –ø–æ–¥–∞—Ä–æ–∫, –æ—Å—Ç–∞–ª—Å—è –¥...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>–ú–∏—Å—Å–∏—Å –ê / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–µ –∞–Ω—Ç...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ —É–¥–æ–±–Ω—ã–µ –Ω–µ –º–µ—à–∞—é—Ç –æ–±–∑–æ—Ä—É —Ç–æ —á—Ç–æ –≤...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ —É–¥–æ–±–Ω—ã–µ –Ω–µ –º–µ—à–∞—é—Ç –æ–±–∑–æ—Ä—É —Ç–æ —á—Ç–æ –≤...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>–°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...</td>\n",
       "      <td>–°–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤—Ü—É –û—á–∫–∏ –ø—Ä–∏—à–ª–∏ –≤–æ–≤—Ä–µ–º—è, —Ö–æ—Ä–æ—à–æ —É...</td>\n",
       "      <td>–û—á–∫–∏ –¥–æ—Å—Ç–æ–π–Ω—ã–µ, –¥–æ—Å—Ç–∞–≤–∫–∞ –±—ã—Å—Ç—Ä–∞—è , –∫ –ø–æ–∫—É–ø–∫–µ —Ä...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>–°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...</td>\n",
       "      <td>–û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ, –Ω–µ –±–æ–ª—å—à–∏–µ, –æ—Ç—Ü—É –æ—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª–∏...</td>\n",
       "      <td>–û—á–∫–∏ –∫–ª—ë–≤—ã–µ –ú—É–∂—É –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               product  \\\n",
       "0    *Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç   \n",
       "2    *Happy Family* / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ê–≤–∏–∞—Ç–æ—Ä—ã 2 —à—Ç   \n",
       "6    Clements / –í–∫–ª–∞–¥—ã—à –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∑—Ä–∞—á–Ω...   \n",
       "14   Eternal way / –ë–µ—Å–ø—Ä–æ–≤–æ–¥–Ω–æ–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∞–∫–∫—É–º...   \n",
       "17         FST Auto / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –ö–ª–∞—Å—Å–∏–∫–∞ 2 —à—Ç   \n",
       "28   FST Auto / –û—á–∫–∏ –¥–ª—è –≤–æ–∂–¥–µ–Ω–∏—è. –°–ø–æ—Ä—Ç–∏–≤–Ω—ã–π —Å—Ç–∏–ª—å...   \n",
       "43            Grand House / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –∞–Ω—Ç–∏–±–ª–∏–∫   \n",
       "44            Grand House / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –∞–Ω—Ç–∏–±–ª–∏–∫   \n",
       "52   Lieblich Hause (Haz) / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –≤–æ–∑–¥—É—à–Ω—ã–π –±–µ...   \n",
       "53   Lieblich Hause (Haz) / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –≤–æ–∑–¥—É—à–Ω—ã–π –±–µ...   \n",
       "66   Lieblich Hause / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, ...   \n",
       "67   Lieblich Hause / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, ...   \n",
       "68   Lieblich Hause / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, ...   \n",
       "72    MAZURA / –ê–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è —Ö–∞–º–µ–ª–µ–æ–Ω   \n",
       "73    MAZURA / –ê–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è —Ö–∞–º–µ–ª–µ–æ–Ω   \n",
       "74    MAZURA / –ê–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è —Ö–∞–º–µ–ª–µ–æ–Ω   \n",
       "89   RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...   \n",
       "90   RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...   \n",
       "91   RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...   \n",
       "94   RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...   \n",
       "97   RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...   \n",
       "98   RogoMarcho / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, –∞–Ω—Ç–∏–±–ª–∏–∫, –∞–Ω—Ç–∏...   \n",
       "104    Romarina / –ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω—ã–π   \n",
       "105    Romarina / –ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω—ã–π   \n",
       "106    Romarina / –ê–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω—ã–π   \n",
       "114  SHADOVtech / –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π –≤–æ–∑–¥—É—à–Ω—ã...   \n",
       "119  StarLine / –ß–µ—Ö–æ–ª —Å–∏–ª–∏–∫–æ–Ω–æ–≤—ã–π –¥–ª—è –±—Ä–µ–ª–æ–∫–∞ –°—Ç–∞—Ä–ª...   \n",
       "120  StarLine / –ß–µ—Ö–æ–ª —Å–∏–ª–∏–∫–æ–Ω–æ–≤—ã–π –¥–ª—è –±—Ä–µ–ª–æ–∫–∞ –°—Ç–∞—Ä–ª...   \n",
       "127  Stylish_Shock / –ö–æ–∂–∞–Ω–∞—è –æ–±–ª–æ–∂–∫–∞ –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ...   \n",
       "128  Stylish_Shock / –ö–æ–∂–∞–Ω–∞—è –æ–±–ª–æ–∂–∫–∞ –¥–ª—è –∞–≤—Ç–æ–¥–æ–∫—É–º–µ...   \n",
       "145  SuperVision / –û—á–∫–∏ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, ...   \n",
       "147  SuperVision / –û—á–∫–∏ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è, ...   \n",
       "153  –ú–∏—Å—Å–∏—Å –ê / –û—á–∫–∏ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–µ –∞–Ω—Ç...   \n",
       "158  –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...   \n",
       "160  –°–µ–∑–æ–Ω —Ç–æ–≤–∞—Ä–æ–≤ / –£–º–Ω—ã–µ –∞–Ω—Ç–∏–±–ª–∏–∫–æ–≤—ã–µ –æ—á–∫–∏ –Ω–æ—á–Ω–æ–≥...   \n",
       "\n",
       "                                     cluster_sentences  \\\n",
       "0    –°–≤–æ–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç, –æ—Å–æ–±–µ–Ω–Ω–æ –∂—ë–ª—Ç—ã–µ –ª–∏–Ω–∑—ã ...   \n",
       "2    –î–µ—Ç—Å–∫–∏–µ | –ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ | –ù—É –æ—á–µ–Ω—å ...   \n",
       "6    –í–º–µ—Å—Ç–∏–ª–∏—Å—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã: –¢–°, —Å—Ç—Ä–∞—Ö–æ–≤—ã–µ, –ø–∞—Å–ø–æ...   \n",
       "14   –ó–∞–∫–∞–∑–∞–ª–∞ —Å–µ–±–µ –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä, –º–µ–Ω—è –ø–æ–¥–∫—É–ø–∏–ª –Ω–µ–æ–±—ã—á...   \n",
       "17   –ö–∞–∫ –∏–≥—Ä—É—à–µ—á–Ω—ã–µ, –ª—ë–≥–∫–∏–µ, –Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤...   \n",
       "28   –ö–∞–∫ –∏–≥—Ä—É—à–µ—á–Ω—ã–µ, –ª—ë–≥–∫–∏–µ, –Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤...   \n",
       "43   –ì–æ–¥–Ω—ã–µ –æ—á–∫–∏, –Ω–æ—á—å—é –∫–∞–∫ –¥–Ω—ë–º –µ–¥–µ—à—å, –¥–Ω—ë–º —Å–æ–ª–Ω—Ü–µ...   \n",
       "44   –û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ, –º—É–∂—É –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é | –û—á...   \n",
       "52   –ï—Å—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –º–∞–Ω–æ–º–µ—Ç—Ä, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ –Ω–µ –Ω–∞...   \n",
       "53   –ö—É–ø–∏–ª –∫–∞—á–∞—Ç—å –≤–∞—Ç—Ä—É—à–∫—É –∏ –¥–ª—è –≤–µ–ª–æ—Å–∏–ø–µ–¥–æ–≤ –†–∞–±–æ—Ç–∞...   \n",
       "66   –û—á–µ–Ω—å –ø–æ–ª–µ–∑–Ω—ã–µ –¥–ª—è –≤–æ–¥–∏—Ç–µ–ª—è –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –¥–µ—à—ë–≤—É...   \n",
       "67   –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –£–¥–æ–±–Ω—ã–µ –†–µ–∫–æ–º–µ–Ω–¥—É—é | –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏...   \n",
       "68   –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, —Å–ø–∞—Å–∏–±–æ —Ö–æ—Ä–æ—à–∏–π | –í—Å–µ —Ö–æ—Ä–æ—à–æ –û—á–∫...   \n",
       "72   –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, –º–∞—Ç–µ—Ä–∏–∞–ª –æ—Ç–ª–∏—á–Ω—ã–π –∑–∞ —Å–≤–æ—é –∞–∏–Ω–Ω—É ...   \n",
       "73   –ñ–∞–ª–µ—é, —á—Ç–æ –Ω–µ –∫—É–ø–∏–ª–∞ –∏—Ö —Ä–∞–Ω—å—à–µ –ó–∞–∫–∞–∑–∞–ª–∞ —Ç–æ–ª—å–∫–æ...   \n",
       "74   –û—á–∫–∏ —Ö–æ—Ä–æ—à–∏ –í–∏–¥–Ω–æ –≤ –Ω–∏—Ö –Ω–∞ —Ç—Ä–∞—Å—Å–µ —Ö–æ—Ä–æ—à–æ | –û—Ç–ª...   \n",
       "89   –û—á–∫–∏ –Ω—Ä–∞–≤—è—Ç—Å—è –ó–∞—Ç–µ–º–Ω—è—é—Ç –≤ —Å–æ–ª–Ω–µ—á–Ω—É—é –ø–æ–≥–æ–¥—É –∏ –æ...   \n",
       "90   –û—á–∫–∏ —Ü–µ–ª—ã–µ, –Ω–æ—Ä–º –¢–æ–ª—å–∫–æ –æ—Å—Ç–∞–≤–ª—è—é—Ç —Å–ª–µ–¥—ã –Ω–∞ –ø–µ—Ä...   \n",
       "91   –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –∑–∞ —Å–≤–æ–∏ –¥–µ–Ω—å–≥–∏, —è –±—ã —Å–∫–∞–∑–∞–ª –æ—Ç–ª–∏—á...   \n",
       "94   –°—É–ø–µ—Ä –æ—á–∫–∏ –∑–∞ —Ç–∞–∫—É—é —Ü–µ–Ω—É, –∑–∞–∫–∞–∑—ã–≤–∞–ª–∞ –º—É–∂—É, –æ—á–µ...   \n",
       "97   –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –ø–æ–ª—å–∑—É—é—Å—å, –Ω–æ –Ω–µ –≤—Å–µ–≥–¥–∞ | –û—á–∫–∏ –Ω–æ...   \n",
       "98   –ë–æ–ª—å—à–æ–µ —Å–ø–∞—Å–∏–±–æ –û—á–∫–∏ –æ–≥–æ–Ω—å –¥–∞–∂–µ —Å –æ—á–∫–∞–º–∏ –¥–ª—è –∑...   \n",
       "104  –ù–∞ –≤–µ–ª–∏–∫–∞—Ö –∏—Å–ø—Ä–æ–±–æ–≤–∞–ª –ù–∞–∫–∞—á–∏–≤–∞–µ—Ç –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∫...   \n",
       "105  –û—Ç–ª–∏—á–Ω—ã–π –Ω–∞—Å–æ—Å –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ—Å—Ç–∞–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç—å...   \n",
       "106  –ù–∞–∫–∞—á–∞–ª –¥–≤–∞ —Ä–∞—Å—à–∏—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –±–∞–∫–∞ –ø–æ 8 –ª–∏—Ç—Ä–æ–≤ —Å ...   \n",
       "114  –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä –¥–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ, –¥–∞...   \n",
       "119  –û—Ç–ª–∏—á–Ω—ã–π —á–µ—Ö–æ–ª –•–æ—Ä–æ—à–∞—è —Ü–µ–Ω–∞ –ü–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å –∫–∞—á–µ—Å—Ç...   \n",
       "120  –û—Ç–ª–∏—á–Ω–æ –ø–æ–¥–æ—à—ë–ª üëç | –†–µ–∫–æ–º–µ–Ω–¥—É—é!üëçüèª | –ü–æ–¥–æ—à–µ–ª –æ—Ç...   \n",
       "127  –û—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è —Ç–æ–≤–∞—Ä –û–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤...   \n",
       "128  –û—á–µ–Ω—å —É–¥–æ–±–Ω–∞—è –∏ –ø–æ–ª–µ–∑–Ω–∞—è –≤–µ—â—å –ü–æ–ª–æ–∂–∏–ª–∞ –≤—Å—ë –¥–æ–∫...   \n",
       "145  –û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä –®–∏–∫–∞—Ä–Ω—ã–µ –æ—á–∫–∏ –ö–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –†–µ...   \n",
       "147  –û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏, –º—É–∂—É –±—Ä–∞–ª–∞ –≤ –ø–æ–¥–∞—Ä–æ–∫, –æ—Å—Ç–∞–ª—Å—è –¥...   \n",
       "153  –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ —É–¥–æ–±–Ω—ã–µ –Ω–µ –º–µ—à–∞—é—Ç –æ–±–∑–æ—Ä—É —Ç–æ —á—Ç–æ –≤...   \n",
       "158  –°–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤—Ü—É –û—á–∫–∏ –ø—Ä–∏—à–ª–∏ –≤–æ–≤—Ä–µ–º—è, —Ö–æ—Ä–æ—à–æ —É...   \n",
       "160  –û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ, –Ω–µ –±–æ–ª—å—à–∏–µ, –æ—Ç—Ü—É –æ—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª–∏...   \n",
       "\n",
       "                                           key_thought  word_count  \n",
       "0    –•–ª–∏–ø–∫–∏–µ –ø–æ—Å–ª–µ –ø—Ä–æ—Ç–∏—Ä–∫–µ –æ–¥–Ω–æ —Å—Ç–µ–∫–ª–æ –≤—ã–≤–æ–ª–µ–ª–æ—Å—å,...          53  \n",
       "2                             –ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ           9  \n",
       "6    –û—Ç–ª–∏—á–Ω—ã–π –≤–∫–ª–∞–¥—ã—à, –ø–ª–æ—Ç–Ω—ã–π, –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤–æ—à–ª–∏...          43  \n",
       "14   –•–æ—Ä–æ—à–∏–π –∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä –ë—Ä–∞–ª–∞ –≤ –ø–æ–¥–∞—Ä–æ–∫ –º—É–∂—É –°—Ä–∞–∑—É ...          43  \n",
       "17      –°–∫–æ–ª—å–∫–æ —Å—Ç–æ—è—Ç, —Ç–∞–∫ –∏ –≤—ã–≥–ª—è–¥—è—Ç: –¥—ë—à–µ–≤–æ –∏ –ø—Ä–æ—Å—Ç–æ          37  \n",
       "28      –°–∫–æ–ª—å–∫–æ —Å—Ç–æ—è—Ç, —Ç–∞–∫ –∏ –≤—ã–≥–ª—è–¥—è—Ç: –¥—ë—à–µ–≤–æ –∏ –ø—Ä–æ—Å—Ç–æ          37  \n",
       "43   –ü–æ–ª –¥–Ω—è —Å–µ–≥–æ–¥–Ω—è –µ—Ö–∞–ª –≤ –∂–µ–ª—Ç—ã—Ö –æ—á–∫–∞—Ö, –≥–ª–∞–∑–∞ –Ω–µ ...          65  \n",
       "44               –û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ, –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é          33  \n",
       "52   –ù–∞–∫–∞—á–∞–ª 2 –∫–æ–ª–µ—Å–∞ –¥–ª—è –≤–µ–ª–∏–∫–∞ –¥–æ 3 –∞—Ç–º–æ—Å—Ñ–µ—Ä - —Å–ø...         173  \n",
       "53   –ü–æ–∫—É–ø–∞–ª –¥–ª—è –≤–µ–ª–æ—Å–∏–ø–µ–¥–∞, –æ—Ç–ª–∏—á–Ω–∞—è —à—Ç—É–∫–∞ –ü—Ä–æ–±–æ–≤–∞...          85  \n",
       "66   –£–¥–æ–±–Ω—ã–µ, –æ–±–ª–µ–≥—á–∞—é—Ç –≤–æ–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ —è—Ä–∫–æ–º —Å–≤–µ—Ç–µ –†–µ...          33  \n",
       "67                     –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –£–¥–æ–±–Ω—ã–µ –†–µ–∫–æ–º–µ–Ω–¥—É—é          30  \n",
       "68                       –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, —Å–ø–∞—Å–∏–±–æ —Ö–æ—Ä–æ—à–∏–π          20  \n",
       "72   –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, –ª—ë–≥–∫–∏–µ –∏ —É–¥–æ–±–Ω—ã–µ –í —Ö–æ—Ä–æ—à–µ–º —á–µ—Ö–ª–µ...         372  \n",
       "73   –ñ–∞–ª–µ—é, —á—Ç–æ –Ω–µ –∫—É–ø–∏–ª–∞ –∏—Ö —Ä–∞–Ω—å—à–µ –ó–∞–∫–∞–∑–∞–ª–∞ —Ç–æ–ª—å–∫–æ...         110  \n",
       "74            –û—á–∫–∏ —Ö–æ—Ä–æ—à–∏ –í–∏–¥–Ω–æ –≤ –Ω–∏—Ö –Ω–∞ —Ç—Ä–∞—Å—Å–µ —Ö–æ—Ä–æ—à–æ          52  \n",
       "89   –û—Ç–ª–∏—á–Ω—ã–µ —Å—Ç–∏–ª—å–Ω—ã–µ –æ—á–∫–∏ –∏ —Ö–æ—Ä–æ—à–æ –∑–∞—â–∏—â–∞—é—Ç –æ—Ç —Å–æ...         108  \n",
       "90        –û—á–∫–∏ –Ω–µ –ø–ª–æ—Ö–∏–µ, –Ω–æ —Ö–ª–∏–ø–∫–∏–µ, –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ —Ü–µ–Ω–µ          91  \n",
       "91   –û—á–∫–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∫–ª–∞—Å—Å–Ω—ã–µ, –∑–∞—è–≤–ª–µ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç...          85  \n",
       "94                –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏, –∑–∞–∫–∞–∑–∞–ª–∞ –µ—â—ë, –¥–ª—è —Å—ã–Ω–∞          47  \n",
       "97                –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –ø–æ–ª—å–∑—É—é—Å—å, –Ω–æ –Ω–µ –≤—Å–µ–≥–¥–∞          35  \n",
       "98                     –°–ø–∞—Å–∏–±–æ –∑–∞ –æ—á–∫–∏ –ú–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å          20  \n",
       "104  –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π, –µ—Å—Ç—å —Å—É–º–æ—á–∫–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è, –ª–µ–≥–∫–æ —É...         600  \n",
       "105  –ù–∞—Å–æ—Å –æ—Ç–ª–∏—á–Ω—ã–π –û—á–µ–Ω—å –¥–æ–≤–æ–ª–µ–Ω, –±—Ä–∞–ª –¥–ª—è –≤–µ–ª–æ—Å–∏–ø...         188  \n",
       "106  –ù–∞–∫–∞—á–∞–ª –∫–æ–ª–µ—Å–∞ —Å–∞–º–æ–∫–∞—Ç—É, –ø–æ–¥–∫–∞—á–∞–ª –ø–µ—Ä–µ–¥–Ω–∏–µ –Ω–∞ ...         127  \n",
       "114  –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä —Ö–æ—Ä–æ—à–∏–π, —Å –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–ø—É—â–µ–Ω–Ω–æ–≥–æ –∫–æ–ª...         528  \n",
       "119  –û—Ç–ª–∏—á–Ω—ã–π —á–µ—Ö–æ–ª –•–æ—Ä–æ—à–∞—è —Ü–µ–Ω–∞ –ü–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å –∫–∞—á–µ—Å—Ç...         103  \n",
       "120                         –û—Ç–ª–∏—á–Ω–æ –ø–æ–¥–æ—à–µ–ª –†–µ–∫–æ–º–µ–Ω–¥—É—é          49  \n",
       "127  –°–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤—Ü—É –∑–∞ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω—É—é –¥–æ—Å—Ç–∞–≤–∫—É, –æ—á–µ–Ω...          62  \n",
       "128  –î–∞–≤–Ω–æ —Ö–æ—Ç–µ–ª–∞ —Ç–∞–∫–æ–π –æ—Ä–≥–∞–Ω–∞–π–∑–µ—Ä –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –í...          59  \n",
       "145  –û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä –®–∏–∫–∞—Ä–Ω—ã–µ –æ—á–∫–∏ –ö–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –†–µ...          58  \n",
       "147  –û—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏, –º—É–∂—É –±—Ä–∞–ª–∞ –≤ –ø–æ–¥–∞—Ä–æ–∫, –æ—Å—Ç–∞–ª—Å—è –¥...          35  \n",
       "153  –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ —É–¥–æ–±–Ω—ã–µ –Ω–µ –º–µ—à–∞—é—Ç –æ–±–∑–æ—Ä—É —Ç–æ —á—Ç–æ –≤...          28  \n",
       "158  –û—á–∫–∏ –¥–æ—Å—Ç–æ–π–Ω—ã–µ, –¥–æ—Å—Ç–∞–≤–∫–∞ –±—ã—Å—Ç—Ä–∞—è , –∫ –ø–æ–∫—É–ø–∫–µ —Ä...          55  \n",
       "160                       –û—á–∫–∏ –∫–ª—ë–≤—ã–µ –ú—É–∂—É –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å          18  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import re\n",
    "# import emoji\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
    "# nltk.download('stopwords')\n",
    "# stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "# # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ spaCy –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞\n",
    "# nlp = spacy.load(\"ru_core_news_lg\")\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–ª–∏—á–∏—è —ç–º–æ–¥–∑–∏ –≤ —Å—Ç—Ä–æ–∫–µ\n",
    "# def contains_emoji(text):\n",
    "#     return any(char in emoji.EMOJI_DATA for char in text)\n",
    "\n",
    "# # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–∞—Å–∫–∏\n",
    "# common_phrases = [\n",
    "#     r'–≤—Å—ë –æ–∫', r'—Å—É–ø–µ—Ä', r'–∫–ª–∞—Å—Å', r'–Ω–æ—Ä–º–∞–ª—å–Ω–æ', r'–Ω–æ—Ä–º', r'–≤—Å—ë –Ω–æ—Ä–º', r'–æ—Ç–ª–∏—á–Ω–æ', r'—Ö–æ—Ä–æ—à–æ', r'–Ω–æ—Ä–º–∞–ª—å–Ω–æ —É–ø–∞–∫–æ–≤–∞–Ω–æ',\n",
    "#     r'–±–µ–∑ –ø—Ä–æ–±–ª–µ–º', r'–∫–∞–∫ –≤—Å–µ–≥–¥–∞', r'–Ω–æ—Ä–º'\n",
    "# ]\n",
    "# emotional_phrases = [\n",
    "#     r'—Å–ø–∞—Å–∏–±–æ', r'—Ä–µ–∫–æ–º–µ–Ω–¥—É—é', r'—Å–æ–≤–µ—Ç—É—é', r'–ø—Ä–æ–¥–∞–≤–µ—Ü –º–æ–ª–æ–¥–µ—Ü', r'–º–æ–ª–æ–¥–µ—Ü', r'—Ä–µ–∫–æ–º–µ–Ω–¥—É—é –ø—Ä–æ–¥–∞–≤—Ü–∞', r'–±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω', r'–±–ª–∞–≥–æ–¥–∞—Ä—é',\n",
    "#     r'—Å–æ–≤–µ—Ç—É—é –∫ –ø–æ–∫—É–ø–∫–µ', r'—Å–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–µ', r'–≤—Å–µ–º —Å–æ–≤–µ—Ç—É—é'\n",
    "# ]\n",
    "# short_phrases = [\n",
    "#     r'–ø—Ä–∏—à–µ–ª –±—ã—Å—Ç—Ä–æ', r'—É–∂–µ –±—Ä–∞–ª', r'–ø–æ–º–æ–≥–ª–æ', r'–Ω–µ –ø–æ–º–æ–≥–ª–æ', r'–ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞–ª', r'–æ—Ç–ª–∏—á–Ω–∞—è –≤–µ—â—å', r'–≤—Å—ë –æ–∫–µ–π',\n",
    "#     r'–Ω–æ—Ä–º–∞–ª—å–Ω–æ', r'–±—ã—Å—Ç—Ä–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞', r'–ø—Ä–∏—à–µ–ª –≤–æ–≤—Ä–µ–º—è'\n",
    "# ]\n",
    "# item_phrases = [\n",
    "#     r'—Ö–æ—Ä–æ—à–∞—è –≤–µ—â—å', r'–∫–ª–∞—Å—Å–Ω–∞—è –≤–µ—â—å', r'–æ—Ç–ª–∏—á–Ω–∞—è –≤–µ—â—å', r'–Ω—É–∂–Ω–∞—è –≤–µ—â—å', r'—É–¥–æ–±–Ω–∞—è –≤–µ—â—å', r'–ø–æ–ª–µ–∑–Ω–∞—è –≤–µ—â—å',\n",
    "#     r'–ø—Ä–µ–∫—Ä–∞—Å–Ω–∞—è –≤–µ—â—å', r'–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–∞—è –≤–µ—â—å', r'—Ö–æ—Ä–æ—à–∏–π –ø—Ä–æ–¥—É–∫—Ç', r'–æ—Ç–ª–∏—á–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç', r'–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –≤–µ—â—å'\n",
    "# ]\n",
    "# task_phrases = [\n",
    "#     r'—Å –∑–∞–¥–∞—á–µ–π —Å–ø—Ä–∞–≤–∏–ª—Å—è', r'—Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏ —Å–ø—Ä–∞–≤–∏–ª—Å—è', r'–∑–∞–¥–∞—á—É —Å–≤–æ—é –≤—ã–ø–æ–ª–Ω–∏–ª', r'—Å–ø—Ä–∞–≤–∏–ª—Å—è –Ω–∞ –æ—Ç–ª–∏—á–Ω–æ', \n",
    "#     r'—Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç', r'—Å –∑–∞–¥–∞—á–µ–π —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è', r'–∑–∞–¥–∞—á—É –≤—ã–ø–æ–ª–Ω–∏–ª', r'—Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –∑–∞–¥–∞—á–µ–π', \n",
    "#     r'—Å–æ —Å–≤–æ–∏–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è', r'—Å–ø—Ä–∞–≤–∏–ª—Å—è —Å –∑–∞–¥–∞—á–µ–π'\n",
    "# ]\n",
    "# delivery_phrases = [\n",
    "#     r'–∑–∞–∫–∞–∑ –ø—Ä–∏—à–µ–ª —Ü–µ–ª—ã–π –∏ –≤–æ–≤—Ä–µ–º—è', r'–ø—Ä–∏—à–µ–ª –≤–æ–≤—Ä–µ–º—è', r'–ø—Ä–∏—à–µ–ª —Ü–µ–ª—ã–π', r'–¥–æ—Å—Ç–∞–≤–∫–∞ –≤–æ–≤—Ä–µ–º—è', r'–≤—Å–µ –ø—Ä–∏—à–ª–æ —Ü–µ–ª—ã–º', \n",
    "#     r'—Ç–æ–≤–∞—Ä –ø—Ä–∏—à–µ–ª —Ü–µ–ª—ã–º', r'–ø—Ä–∏—à–µ–ª –≤ —Å—Ä–æ–∫', r'–¥–æ—Å—Ç–∞–≤–∫–∞ –±—ã—Å—Ç—Ä–∞—è', r'–ø—Ä–∏—à–µ–ª –≤–æ–≤—Ä–µ–º—è –∏ —Ü–µ–ª—ã–º', r'–ø–æ–ª—É—á–∏–ª –∑–∞–∫–∞–∑ –≤–æ–≤—Ä–µ–º—è'\n",
    "# ]\n",
    "# emoji_phrases = [\n",
    "#     r'–∏–¥–µ–∞–ª—å–Ω–æ', r'–æ—Ç–ª–∏—á–Ω–æ', r'üëç', r'üëè', r'üòÜ', r'üî•', r'üíØ', r'–∫–ª–∞—Å—Å', r'–∫–ª–∞—Å—Åüëç', r'–≤—Å–µ —Å—É–ø–µ—Äüëç', r'üëçüëçüëç', r'üëçüòä'\n",
    "# ]\n",
    "# negative_condition_phrases = [\n",
    "#     r'–ø—Ä–∏—à–ª–æ –≤—Å–µ –ø–æ–±–∏—Ç–æ–µ', r'—É–ø–∞–∫–æ–≤–∫–∞ –ø–æ—Ä–≤–∞–Ω–∞', r'–≤—Å—ë —Å–ª–æ–º–∞–Ω–æ', r'—Ç–æ–≤–∞—Ä —Ç—Ä–µ—Å–Ω—É–ª', r'–ø–æ–ª—É—á–∏–ª —Ç–æ–≤–∞—Ä —Å –¥–µ—Ñ–µ–∫—Ç–æ–º', \n",
    "#     r'–ø–æ–≥–Ω—É—Ç–∞—è —É–ø–∞–∫–æ–≤–∫–∞', r'–ø—Ä–∏—à–ª–æ —Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω–æ–µ', r'–≤—Å–µ —Ä–∞–∑–ª–∏—Ç–æ', r'–∫–æ—Ä–æ–±–∫–∞ –ø–æ–º—è—Ç–∞', r'–≤—Å—ë –ø–æ–±–∏–ª–æ—Å—å', \n",
    "#     r'—Å–ª–æ–º–∞–Ω–Ω—ã–π —Ç–æ–≤–∞—Ä', r'–≤—Å–µ –ø–æ—Ä–≤–∞–Ω–æ', r'–ø—Ä–∏—à–µ–ª –≤–µ—Å—å –≤ —Ç—Ä–µ—â–∏–Ω–∞—Ö', r'–ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω–∞—è —É–ø–∞–∫–æ–≤–∫–∞', r'—Ç–æ–≤–∞—Ä –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç'\n",
    "# ]\n",
    "# positive_condition_phrases = [\n",
    "#     r'–≤—Å—ë –ø—Ä–∏—à–ª–æ —Ü–µ–ª–æ–µ –∏ –Ω–µ–≤—Ä–µ–¥–∏–º–æ–µ', r'–¥–æ—Å—Ç–∞–≤–∫–∞ - –≤–æ!', r'–∫—Ä—É—Ç–∞—è —É–ø–∞–∫–æ–≤–∫–∞', r'—É–ø–∞–∫–æ–≤–∞–Ω–æ –Ω–∞ —Å–æ–≤–µ—Å—Ç—å', \n",
    "#     r'–≤—Å–µ –ø—Ä–∏—à–ª–æ –≤ –∏–¥–µ–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏', r'—Ç–æ–≤–∞—Ä –≤ –æ—Ç–ª–∏—á–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏', r'–±–µ–∑ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π', r'—É–ø–∞–∫–æ–≤–∫–∞ —Ü–µ–ª–∞—è', \n",
    "#     r'—Ç–æ–≤–∞—Ä –±–µ–∑ –¥–µ—Ñ–µ–∫—Ç–æ–≤', r'–≤—Å–µ –ø—Ä–∏—à–ª–æ –∫–∞–∫ –Ω–∞–¥–æ', r'–ø—Ä–∏—à–µ–ª –≤ –ø–æ–ª–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ', r'–æ—Ç–ª–∏—á–Ω–∞—è —É–ø–∞–∫–æ–≤–∫–∞', \n",
    "#     r'–≤—Å–µ –¥–æ—à–ª–æ —Ü–µ–ª—ã–º', r'–¥–æ—Å—Ç–∞–≤–∫–∞ –±–µ–∑ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π', r'–∏–¥–µ–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ'\n",
    "# ]\n",
    "# gratitude_phrases = [\n",
    "#     r'—Å–ø–∞—Å–∏–±–æ –∑–∞ —Ç–æ–≤–∞—Ä', r'—Å–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤—Ü—É', r'—Å–ø–∞—Å–∏–±–æ –±–æ–ª—å—à–æ–µ', r'–±–ª–∞–≥–æ–¥–∞—Ä—é –∑–∞ —Ç–æ–≤–∞—Ä', r'–±–æ–ª—å—à–æ–µ —Å–ø–∞—Å–∏–±–æ', \n",
    "#     r'–æ—á–µ–Ω—å –±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ –¥–æ—Å—Ç–∞–≤–∫—É', r'–æ–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç–æ–≤–∞—Ä', \n",
    "#     r'–ø—Ä–æ–¥–∞–≤—Ü—É –æ–≥—Ä–æ–º–Ω–æ–µ —Å–ø–∞—Å–∏–±–æ', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ—Å—Ç—å', r'—Å–ø–∞—Å–∏–±–æ –≤–∞–º', r'–±–ª–∞–≥–æ–¥–∞—Ä–µ–Ω –∑–∞ —Ç–æ–≤–∞—Ä', \n",
    "#     r'—Å–ø–∞—Å–∏–±–æ, –≤—Å—ë —Ö–æ—Ä–æ—à–æ', r'–ø—Ä–æ–¥–∞–≤–µ—Ü –º–æ–ª–æ–¥–µ—Ü', r'—Å–ø–∞—Å–∏–±–æ –∑–∞ —Ö–æ—Ä–æ—à–µ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ'\n",
    "# ]\n",
    "# neutral_quality_phrases = [\n",
    "#     r'–≤—Å—ë –æ—Ç–ª–∏—á–Ω–æ', r'–≤—Å—ë —Ö–æ—Ä–æ—à–æ', r'–≤—Å–µ —Å—É–ø–µ—Ä', r'–æ—á–µ–Ω—å –¥–æ–≤–æ–ª–µ–Ω –ø–æ–∫—É–ø–∫–æ–π', r'—Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ', \n",
    "#     r'–Ω–∞–¥–µ—é—Å—å –ø—Ä–æ—Å–ª—É–∂–∏—Ç—å –¥–æ–ª–≥–æ', r'–≤—Å—ë —Ü–µ–ª–æ–µ', r'–≤—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ', r'–≤—Å—ë –∫–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏', \n",
    "#     r'–≤—Å—ë –∫–∞–∫ –∑–∞—è–≤–ª–µ–Ω–æ', r'–∑–∞ —Å–≤–æ—é —Ü–µ–Ω—É –æ—Ç–ª–∏—á–Ω–æ', r'–∫–∞—á–µ—Å—Ç–≤–æ —Ö–æ—Ä–æ—à–µ–µ', r'–æ—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ', \n",
    "#     r'–∫–æ–º–ø–ª–µ–∫—Ç –∫–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏', r'–º–µ–ª–æ—á—å, –∞ –ø—Ä–∏—è—Ç–Ω–æ', r'–º–Ω–µ –≤—Å—ë –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å', r'–¥–æ–±—Ä—ã–π –¥–µ–Ω—å', \n",
    "#     r'–≤—Å—ë —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç', r'—Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ, —Å–ø–∞—Å–∏–±–æ', r'–≤—Å—ë —Å—É–ø–µ—Ä üëå'\n",
    "# ]\n",
    "\n",
    "# # –ù–æ–≤—ã–µ –º–∞—Å–∫–∏\n",
    "# confirmation_phrases = [\n",
    "#     r'–≤—Å—ë —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç', r'–≤—Å—ë –∫–∞–∫ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏', r'–≤—Å—ë –∫–∞–∫ –∑–∞—è–≤–ª–µ–Ω–æ', r'—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—é', r'–≤—Å—ë —Ü–µ–ª–æ–µ', r'–≤—Å—ë –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ', r'–≤—Å—ë –Ω–æ—Ä–º', r'–≤—Å—ë —Ö–æ—Ä–æ—à–æ'\n",
    "# ]\n",
    "# simple_statements_phrases = [\n",
    "#     r'—Ö–æ—Ä–æ—à–∞—è –≤–µ—â—å', r'–∫–ª–∞—Å—Å–Ω–∞—è –≤–µ—â—å', r'–æ—Ç–ª–∏—á–Ω–∞—è –≤–µ—â—å', r'—É–¥–æ–±–Ω–æ', r'–Ω–æ—Ä–º–∞–ª—å–Ω–æ', r'—Ä–∞–±–æ—Ç–∞–µ—Ç', r'—Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ', r'—Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ', r'–≤—Å—ë –Ω–æ—Ä–º–∞–ª—å–Ω–æ', r'–≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç'\n",
    "# ]\n",
    "# quality_phrases = [\n",
    "#     r'–∫–∞—á–µ—Å—Ç–≤–æ —Ö–æ—Ä–æ—à–µ–µ', r'–æ—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ', r'–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ', r'–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ', r'–≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ', r'–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç–æ–≤–∞—Ä', r'–∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–ª–∏—á–Ω–æ–µ', r'–∫–∞—á–µ—Å—Ç–≤–æ —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ'\n",
    "# ]\n",
    "# functionality_phrases = [\n",
    "#     r'—Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ', r'—Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ', r'–≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç', r'—Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç', r'—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π', r'—Ñ—É–Ω–∫—Ü–∏–∏ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è', r'—Å –∑–∞–¥–∞—á–µ–π —Å–ø—Ä–∞–≤–∏–ª—Å—è', r'—Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –∑–∞–¥–∞—á–µ–π', r'—Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç'\n",
    "# ]\n",
    "# price_phrases = [\n",
    "#     r'—Ü–µ–Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è', r'—Ü–µ–Ω–∞ –∞–¥–µ–∫–≤–∞—Ç–Ω–∞—è', r'—Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ü–µ–Ω–∞/–∫–∞—á–µ—Å—Ç–≤–æ', r'—Ü–µ–Ω–∞ –æ—Ç–ª–∏—á–Ω–∞—è', r'—Ü–µ–Ω–∞ —Ö–æ—Ä–æ—à–∞—è', r'—Ü–µ–Ω–∞ –ø—Ä–∏–µ–º–ª–µ–º–∞—è', r'—Ü–µ–Ω–∞ –æ–ø—Ä–∞–≤–¥–∞–Ω–∞', r'—Ü–µ–Ω–∞ –Ω–∏–∑–∫–∞—è', r'—Ü–µ–Ω–∞ –≤—ã—Å–æ–∫–∞—è', r'—Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ü–µ–Ω—ã –∏ –∫–∞—á–µ—Å—Ç–≤–∞', r'–∑–∞ —Ç–∞–∫—É—é —Ü–µ–Ω—É', r'–≤–ø–æ–ª–Ω–µ –ø—Ä–∏–µ–º–ª–µ–º–∞—è —Ü–µ–Ω–∞'\n",
    "# ]\n",
    "# durability_phrases = [\n",
    "#     r'–Ω–∞–¥–µ—é—Å—å –ø—Ä–æ—Å–ª—É–∂–∏—Ç—å –¥–æ–ª–≥–æ', r'–ø–æ–ª—å–∑—É—é—Å—å –¥–æ–ª–≥–æ', r'–Ω–∞–¥–µ–∂–Ω—ã–π —Ç–æ–≤–∞—Ä', r'–¥–æ–ª–≥–æ–≤–µ—á–Ω—ã–π', r'—Ö–≤–∞—Ç–∏—Ç –Ω–∞–¥–æ–ª–≥–æ', r'–±—É–¥—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–æ–ª–≥–æ', r'–Ω–∞ —Å–µ–∑–æ–Ω —Ö–≤–∞—Ç–∏—Ç', r'–¥–æ–ª–≥–æ –ø–æ–ª—å–∑—É—é—Å—å', r'–ø—Ä–æ–≤–µ—Ä–µ–Ω–æ –≤—Ä–µ–º–µ–Ω–µ–º', r'–≤—ã–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–∞–≥—Ä—É–∑–∫–∏', r'–ø–æ—Å–º–æ—Ç—Ä–∏–º, —Å–∫–æ–ª—å–∫–æ –ø—Ä–æ–¥–µ—Ä–∂–∏—Ç—Å—è'\n",
    "# ]\n",
    "# appearance_phrases = [\n",
    "#     r'–≤—ã–≥–ª—è–¥–∏—Ç —Ö–æ—Ä–æ—à–æ', r'—Å–º–æ—Ç—Ä–∏—Ç—Å—è –∫—Ä–∞—Å–∏–≤–æ', r'–≤–Ω–µ—à–Ω–∏–π –≤–∏–¥ –æ—Ç–ª–∏—á–Ω—ã–π', r'—Å—Ç–∏–ª—å–Ω–æ –≤—ã–≥–ª—è–¥–∏—Ç', r'–≤—ã–≥–ª—è–¥–∏—Ç –∫—Ä–∞—Å–∏–≤–æ', r'—Å–º–æ—Ç—Ä–∏—Ç—Å—è –æ—Ç–ª–∏—á–Ω–æ', r'–≤–Ω–µ—à–Ω–µ –ø—Ä–∏—è—Ç–Ω–æ', r'—Å—Ç–∏–ª—å–Ω—ã–π', r'–≤—ã–≥–ª—è–¥–∏—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ'\n",
    "# ]\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "# def compute_sentence_embeddings(sentences):\n",
    "#     inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#     return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "# # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–∞—Å–æ–∫ –∏ –∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "# gratitude_emb = compute_sentence_embeddings(gratitude_phrases)\n",
    "# common_emb = compute_sentence_embeddings(common_phrases)\n",
    "# emotional_emb = compute_sentence_embeddings(emotional_phrases)\n",
    "# short_emb = compute_sentence_embeddings(short_phrases)\n",
    "# item_emb = compute_sentence_embeddings(item_phrases)\n",
    "# task_emb = compute_sentence_embeddings(task_phrases)\n",
    "# delivery_emb = compute_sentence_embeddings(delivery_phrases)\n",
    "# emoji_text_emb = compute_sentence_embeddings(emoji_phrases)\n",
    "# negative_condition_emb = compute_sentence_embeddings(negative_condition_phrases)\n",
    "# positive_condition_emb = compute_sentence_embeddings(positive_condition_phrases)\n",
    "# neutral_quality_emb = compute_sentence_embeddings(neutral_quality_phrases)\n",
    "# confirmation_emb = compute_sentence_embeddings(confirmation_phrases)\n",
    "# simple_statements_emb = compute_sentence_embeddings(simple_statements_phrases)\n",
    "# quality_emb = compute_sentence_embeddings(quality_phrases)\n",
    "# functionality_emb = compute_sentence_embeddings(functionality_phrases)\n",
    "# price_emb = compute_sentence_embeddings(price_phrases)\n",
    "# durability_emb = compute_sentence_embeddings(durability_phrases)\n",
    "# appearance_emb = compute_sentence_embeddings(appearance_phrases)\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –±–ª–∏–∑–æ—Å—Ç–∏ —Å –∫–∞–∂–¥–æ–π –º–∞—Å–∫–æ–π\n",
    "# def is_similar_to_mask(key_thought, mask_emb):\n",
    "#     key_emb = compute_sentence_embeddings([key_thought])\n",
    "#     return np.max(cosine_similarity(key_emb, mask_emb)) > 0.65  # –ü–æ—Ä–æ–≥ –±–ª–∏–∑–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å\n",
    "\n",
    "# # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö –º—ã—Å–ª–µ–π –Ω–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –±–ª–∏–∑–æ—Å—Ç—å –∫ –∫–∞–∂–¥–æ–π –º–∞—Å–∫–µ\n",
    "# final_result['is_similar_to_emoji'] = final_result['key_thought'].apply(lambda x: contains_emoji(x) or is_similar_to_mask(x, emoji_text_emb))\n",
    "# final_result['is_similar_to_common'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, common_emb))\n",
    "# final_result['is_similar_to_emotional'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, emotional_emb))\n",
    "# final_result['is_similar_to_short'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, short_emb))\n",
    "# final_result['is_similar_to_item'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, item_emb))\n",
    "# final_result['is_similar_to_task'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, task_emb))\n",
    "# final_result['is_similar_to_delivery'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, delivery_emb))\n",
    "# final_result['is_similar_to_negative_condition'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, negative_condition_emb))\n",
    "# final_result['is_similar_to_positive_condition'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, positive_condition_emb))\n",
    "# final_result['is_similar_to_gratitude'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, gratitude_emb))\n",
    "# final_result['is_similar_to_neutral_quality'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, neutral_quality_emb))\n",
    "# final_result['is_similar_to_confirmation'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, confirmation_emb))\n",
    "# final_result['is_similar_to_simple_statements'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, simple_statements_emb))\n",
    "# final_result['is_similar_to_quality'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, quality_emb))\n",
    "# final_result['is_similar_to_functionality'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, functionality_emb))\n",
    "# final_result['is_similar_to_price'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, price_emb))\n",
    "# final_result['is_similar_to_durability'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, durability_emb))\n",
    "# final_result['is_similar_to_appearance'] = final_result['key_thought'].apply(lambda x: is_similar_to_mask(x, appearance_emb))\n",
    "\n",
    "# # –£–¥–∞–ª–µ–Ω–∏–µ –ø—É—Å—Ç—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "# final_result = final_result[final_result['cluster_sentences'].str.strip().astype(bool)]\n",
    "\n",
    "# # –°–ª–æ–≤–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "# exclusion_words = [\n",
    "#     r'–æ—Ç–ª–∏—á–Ω—ã–π', r'—Ö–æ—Ä–æ—à–∏–π', r'—à–∏–∫–∞—Ä–Ω—ã–π', r'–æ—Ñ–∏–≥–µ–Ω–Ω—ã–π', r'–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã–π', r'–ø–æ—Ç—Ä—è—Å–∞—é—â–∏–π', r'–≤–µ–ª–∏–∫–æ–ª–µ–ø–Ω—ã–π', \n",
    "#     r'–ø—Ä–µ–∫—Ä–∞—Å–Ω—ã–π', r'–∏–∑—É–º–∏—Ç–µ–ª—å–Ω—ã–π', r'—Ñ–∞–Ω—Ç–∞—Å—Ç–∏—á–µ—Å–∫–∏–π', r'—É–¥–∏–≤–∏—Ç–µ–ª—å–Ω—ã–π', r'–Ω–µ–≤–µ—Ä–æ—è—Ç–Ω—ã–π', r'–∑–∞—á—ë—Ç–Ω—ã–π', r'—Å—É–ø–µ—Ä—Å–∫–∏–π', \n",
    "#     r'–∫–ª–∞—Å—Å–Ω—ã–π', r'–∫—Ä—É—Ç–æ–π', r'–ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å', r'–ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å', r'–ª—é–±–ª—é', r'–≤–æ—Å—Ö–∏—â—ë–Ω', \n",
    "#     r'–¥–æ–≤–æ–ª–µ–Ω', r'–Ω–∞—Å–ª–∞–∂–¥–∞—é—Å—å', r'–ø–æ—Ä–∞–¥–æ–≤–∞–ª–æ'\n",
    "# ]\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞\n",
    "# def lemmatize_text(text):\n",
    "#     doc = nlp(text)\n",
    "#     return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "\n",
    "# # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–ª–æ–≤ –∏–∑ —Å–ø–∏—Å–∫–∞ exclusion_words\n",
    "# lemmatized_exclusion_words = [lemmatize_text(word) for word in exclusion_words]\n",
    "# exclusion_emb = compute_sentence_embeddings(lemmatized_exclusion_words)\n",
    "\n",
    "# # –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –±–ª–∏–∑–æ—Å—Ç–∏\n",
    "# def is_single_word_or_stop_word(key_thought):\n",
    "#     words = re.findall(r'\\w+', key_thought)  # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ —Å–ª–æ–≤–∞\n",
    "#     if len(words) == 1:\n",
    "#         return True\n",
    "#     if len(words) == 2 and words[1] in stop_words:\n",
    "#         return True\n",
    "#     if len(words) == 2 and re.match(r'[^\\w\\s]', words[1]):  # –ü—É–Ω–∫—Ç—É–∞—Ü–∏—è –∫–∞–∫ –≤—Ç–æ—Ä–æ–µ —Å–ª–æ–≤–æ\n",
    "#         return True\n",
    "#     if len(words) in [2, 3]:\n",
    "#         lemmatized_key_thought = lemmatize_text(key_thought)\n",
    "#         lemmatized_words = re.findall(r'\\w+', lemmatized_key_thought)\n",
    "#         for word in lemmatized_words:\n",
    "#             key_emb = compute_sentence_embeddings([word])\n",
    "#             max_similarity = np.max(cosine_similarity(key_emb, exclusion_emb))\n",
    "#             if max_similarity > 0.9:  # –ü–æ—Ä–æ–≥ –±–ª–∏–∑–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å\n",
    "#                 print(f\"–ë–ª–∏–∑–æ—Å—Ç—å - {max_similarity}. –ò—Å–∫–ª—é—á–∞–µ–º {key_thought}\")\n",
    "#                 return True\n",
    "#     return False\n",
    "\n",
    "# # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏\n",
    "# final_result = final_result[~final_result['key_thought'].apply(is_single_word_or_stop_word)]\n",
    "\n",
    "# # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, –≥–¥–µ –≤—Å–µ –º–∞—Å–∫–∏ False\n",
    "# mask_false_clusters = (\n",
    "#     ~final_result['is_similar_to_emoji'] &\n",
    "#     ~final_result['is_similar_to_common'] &\n",
    "#     ~final_result['is_similar_to_emotional'] &\n",
    "#     ~final_result['is_similar_to_short'] &\n",
    "#     ~final_result['is_similar_to_item'] &\n",
    "#     ~final_result['is_similar_to_task'] &\n",
    "#     ~final_result['is_similar_to_delivery'] &\n",
    "#     ~final_result['is_similar_to_negative_condition'] &\n",
    "#     ~final_result['is_similar_to_positive_condition'] &\n",
    "#     ~final_result['is_similar_to_gratitude'] &\n",
    "#     ~final_result['is_similar_to_neutral_quality'] &\n",
    "#     ~final_result['is_similar_to_confirmation'] &\n",
    "#     ~final_result['is_similar_to_simple_statements'] &\n",
    "#     ~final_result['is_similar_to_quality'] &\n",
    "#     ~final_result['is_similar_to_functionality'] &\n",
    "#     ~final_result['is_similar_to_price'] &\n",
    "#     ~final_result['is_similar_to_durability'] &\n",
    "#     ~final_result['is_similar_to_appearance']\n",
    "# )\n",
    "\n",
    "# # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "# df_false_clusters = final_result[mask_false_clusters]\n",
    "# display(df_false_clusters[['product', 'cluster_sentences', 'key_thought', 'word_count']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_false_clusters[['cluster_sentences', 'key_thought', 'word_count']].to_csv(\"./reviews_keywords/clusters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Summarizing clusters: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62/62 [02:09<00:00,  2.09s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_sentences</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–ê –≤–æ—Ç –≤ —Ç–µ–º–Ω—ã—Ö –µ–∑–¥–∏—Ç—å –ø–æ —Å–ª–µ–ø—è—â–µ–π –æ—Ç —Å–æ–ª–Ω—Ü–∞ –¥–æ...</td>\n",
       "      <td>–í —Ç–µ–º–Ω—ã—Ö –æ—á–∫–∞—Ö —á—É—Ç—å –∫–æ–º—Ñ–æ—Ä—Ç–Ω–µ–µ –µ–∑–¥–∏—Ç—å –ø–æ —Å–ª–µ–ø—è...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–û–¥–Ω–æ —Å—Ç–µ–∫–ª–æ —Å–≤–µ—Ç–ª–æ–µ –¥—Ä—É–≥–æ–µ —á–µ—Ä–Ω–æ–µ –≤–æ–æ–±—â–µ —Ä–∞–∑–Ω—ã...</td>\n",
       "      <td>–û–¥–Ω–æ —Å—Ç–µ–∫–ª–æ —Å–≤–µ—Ç–ª–æ–µ, –¥—Ä—É–≥–æ–µ —á–µ—Ä–Ω–æ–µ...&lt;br&gt;–°—Ç–µ–∫–ª...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>–ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ | –î–µ—Ç—Å–∫–∏–µ | –ù—É –æ—á–µ–Ω—å ...</td>\n",
       "      <td>–ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ &lt;br&gt;&lt;br&gt;–ú–∞–ª—ã—à–∏ –æ—á–µ–Ω—å ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –æ–±–ª–æ–∂–∫–∞! | –ò –ø–æ —Ä–∞–∑–º–µ—Ä—É –∏–¥–µ–∞–ª—å–Ω–æ ...</td>\n",
       "      <td>–ù–µ–º–Ω–æ–≥–æ –Ω–µ –≤–ª–µ–∑ –≤ –æ–±–ª–æ–∂–∫—É, –ø—Ä–∏—à–ª–æ—Å—å –ø–æ–¥—Ä–µ–∑–∞—Ç—å ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç—É—Ä–Ω–∞—è, –ø–æ—ç—Ç–æ–º—É –ª–∞–º...</td>\n",
       "      <td>–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç—É—Ä–Ω–∞—è, –ø–æ—ç—Ç–æ–º—É –ª–∞–º...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>–ü–æ–∫—É–ø–∞–ª–∞ –ø–∞–ø–µ- —Ä—ã–±–∞–∫—É. | –ü–æ–∫—É–ø–∞–ª–∞ –º—É–∂—É. | –ë—Ä–∞–ª...</td>\n",
       "      <td>–ü–æ–∫—É–ø–∞–ª–∞ –ø–∞–ø–µ- —Ä—ã–±–∞–∫—É &lt;br&gt;–ü–æ–∫—É–ø–∞–ª–∞ –º—É–∂—É &lt;br&gt;–ë—ã...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>–û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ –¥–µ–¥—É—à–∫–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å | –§–æ—Ç–æ —Å–æ–æ—Ç–≤–µ...</td>\n",
       "      <td>–û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ, —à–∏—Ä–æ–∫–∏–µ, –º–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å –æ—á–∫–∏. &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>–û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ,—Å–≤–∞–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç –Ω–∞ 5+ .–ú–∏–Ω...</td>\n",
       "      <td>–•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –Ω–µ –º–µ—à–∞—é—Ç –æ–±–∑–æ—Ä—É, –æ–Ω–∏ –∫–∞–∫–∏–µ —Ç–æ —Ä–∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>–û–ì–†–û–ú–ù–ê–Ø –ë–õ–ê–ì–û–î–ê–†–ù–û–°–¢–¨  –ó–ê –û–ß–ö–ò , –ú–£–ñ–£ –û–ß–ï–ù–¨ –ü...</td>\n",
       "      <td>–°–ø–∞—Å–∏–±–æ, –±—Ä–∞–ª–∞ –º—É–∂—É, —Å–∫–∞–∑–∞–ª –æ—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏. –í –¥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>–†–µ–∞–ª—å–Ω–æ —É–±–∏—Ä–∞—é—Ç –±–ª–∏–∫–∏ —Å –æ—Ç—Ä–∞–∂–∞—é—â–∏—Ö –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ...</td>\n",
       "      <td>–†–µ–∞–ª—å–Ω–æ —É–±–∏—Ä–∞—é—Ç –±–ª–∏–∫–∏ —Å –æ—Ç—Ä–∞–∂–∞—é—â–∏—Ö –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     cluster_sentences  \\\n",
       "0    –ê –≤–æ—Ç –≤ —Ç–µ–º–Ω—ã—Ö –µ–∑–¥–∏—Ç—å –ø–æ —Å–ª–µ–ø—è—â–µ–π –æ—Ç —Å–æ–ª–Ω—Ü–∞ –¥–æ...   \n",
       "1    –û–¥–Ω–æ —Å—Ç–µ–∫–ª–æ —Å–≤–µ—Ç–ª–æ–µ –¥—Ä—É–≥–æ–µ —á–µ—Ä–Ω–æ–µ –≤–æ–æ–±—â–µ —Ä–∞–∑–Ω—ã...   \n",
       "7    –ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ | –î–µ—Ç—Å–∫–∏–µ | –ù—É –æ—á–µ–Ω—å ...   \n",
       "10   –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –æ–±–ª–æ–∂–∫–∞! | –ò –ø–æ —Ä–∞–∑–º–µ—Ä—É –∏–¥–µ–∞–ª—å–Ω–æ ...   \n",
       "17   –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç—É—Ä–Ω–∞—è, –ø–æ—ç—Ç–æ–º—É –ª–∞–º...   \n",
       "..                                                 ...   \n",
       "244  –ü–æ–∫—É–ø–∞–ª–∞ –ø–∞–ø–µ- —Ä—ã–±–∞–∫—É. | –ü–æ–∫—É–ø–∞–ª–∞ –º—É–∂—É. | –ë—Ä–∞–ª...   \n",
       "249  –û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ –¥–µ–¥—É—à–∫–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å | –§–æ—Ç–æ —Å–æ–æ—Ç–≤–µ...   \n",
       "250  –û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ,—Å–≤–∞–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç –Ω–∞ 5+ .–ú–∏–Ω...   \n",
       "256  –û–ì–†–û–ú–ù–ê–Ø –ë–õ–ê–ì–û–î–ê–†–ù–û–°–¢–¨  –ó–ê –û–ß–ö–ò , –ú–£–ñ–£ –û–ß–ï–ù–¨ –ü...   \n",
       "263  –†–µ–∞–ª—å–Ω–æ —É–±–∏—Ä–∞—é—Ç –±–ª–∏–∫–∏ —Å –æ—Ç—Ä–∞–∂–∞—é—â–∏—Ö –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ...   \n",
       "\n",
       "                                               summary  \n",
       "0    –í —Ç–µ–º–Ω—ã—Ö –æ—á–∫–∞—Ö —á—É—Ç—å –∫–æ–º—Ñ–æ—Ä—Ç–Ω–µ–µ –µ–∑–¥–∏—Ç—å –ø–æ —Å–ª–µ–ø—è...  \n",
       "1    –û–¥–Ω–æ —Å—Ç–µ–∫–ª–æ —Å–≤–µ—Ç–ª–æ–µ, –¥—Ä—É–≥–æ–µ —á–µ—Ä–Ω–æ–µ...<br>–°—Ç–µ–∫–ª...  \n",
       "7    –ú–∞–ª–µ–Ω—å–∫–∏–µ –æ—á–µ–Ω—å, –¥–µ—Ç—Å–∫–∏–µ <br><br>–ú–∞–ª—ã—à–∏ –æ—á–µ–Ω—å ...  \n",
       "10   –ù–µ–º–Ω–æ–≥–æ –Ω–µ –≤–ª–µ–∑ –≤ –æ–±–ª–æ–∂–∫—É, –ø—Ä–∏—à–ª–æ—Å—å –ø–æ–¥—Ä–µ–∑–∞—Ç—å ...  \n",
       "17   –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç—É—Ä–Ω–∞—è, –ø–æ—ç—Ç–æ–º—É –ª–∞–º...  \n",
       "..                                                 ...  \n",
       "244  –ü–æ–∫—É–ø–∞–ª–∞ –ø–∞–ø–µ- —Ä—ã–±–∞–∫—É <br>–ü–æ–∫—É–ø–∞–ª–∞ –º—É–∂—É <br>–ë—ã...  \n",
       "249  –û—á–∫–∏ —Ö–æ—Ä–æ—à–∏–µ, —à–∏—Ä–æ–∫–∏–µ, –º–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å –æ—á–∫–∏. <...  \n",
       "250  –•–æ—Ä–æ—à–∏–µ –æ—á–∫–∏ –Ω–µ –º–µ—à–∞—é—Ç –æ–±–∑–æ—Ä—É, –æ–Ω–∏ –∫–∞–∫–∏–µ —Ç–æ —Ä–∞...  \n",
       "256  –°–ø–∞—Å–∏–±–æ, –±—Ä–∞–ª–∞ –º—É–∂—É, —Å–∫–∞–∑–∞–ª –æ—Ç–ª–∏—á–Ω—ã–µ –æ—á–∫–∏. –í –¥...  \n",
       "263  –†–µ–∞–ª—å–Ω–æ —É–±–∏—Ä–∞—é—Ç –±–ª–∏–∫–∏ —Å –æ—Ç—Ä–∞–∂–∞—é—â–∏—Ö –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ...  \n",
       "\n",
       "[62 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (GPU –∏–ª–∏ CPU)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ T5\n",
    "# model_name = \"cointegrated/rut5-base-multitask\"  # –ú–æ–¥–µ–ª—å –¥–ª—è —Ä—É—Å—Å–∫–æ–π T5\n",
    "# model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "# tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞—Å—Ç–∏\n",
    "# def chunk_text(text, max_length=100):\n",
    "#     words = text.split()\n",
    "#     chunks = [' '.join(words[i:i + max_length]) for i in range(0, len(words), max_length)]\n",
    "#     return chunks\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n",
    "# def summarize_text(text):\n",
    "#     # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –ø–µ—Ä–µ–Ω–æ—Å –Ω–∞ GPU\n",
    "#     inputs = tokenizer(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    \n",
    "#     # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPU\n",
    "#     summary_ids = model.generate(\n",
    "#         inputs.input_ids, \n",
    "#         max_length=150, \n",
    "#         min_length=40, \n",
    "#         length_penalty=4,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º penalty –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π\n",
    "#         num_beams=16,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ beam –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "#         repetition_penalty=3.0,  # –î–æ–±–∞–≤–ª—è–µ–º —à—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è\n",
    "#         early_stopping=True\n",
    "#     )\n",
    "    \n",
    "#     # –ü–µ—Ä–µ–Ω–æ—Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ CPU –∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "#     return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ —Å —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º\n",
    "# def recursive_summarization(text, depth=2):\n",
    "#     chunks = chunk_text(text, max_length=100)  # –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞—Å—Ç–∏, –∫–∞–∂–¥–∞—è –¥–æ 100 —Å–ª–æ–≤\n",
    "#     summaries = [summarize_text(chunk) for chunk in chunks]\n",
    "    \n",
    "#     # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–π –≥–ª—É–±–∏–Ω—ã —Ä–µ–∫—É—Ä—Å–∏–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "#     if depth <= 1:\n",
    "#         return ' '.join(summaries)\n",
    "    \n",
    "#     # –í –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ —Å—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ–º –µ—â–µ —Ä–∞–∑ –Ω–∞ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–æ–π –≥–ª—É–±–∏–Ω–µ\n",
    "#     return recursive_summarization(' '.join(summaries), depth - 1)\n",
    "\n",
    "# # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –∫ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Ç–µ—Ä—É —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPU\n",
    "# df_false_clusters['summary'] = [\n",
    "#     recursive_summarization(text, depth=2) for text in tqdm(df_false_clusters['cluster_sentences'], desc=\"Summarizing clusters\")\n",
    "# ]\n",
    "\n",
    "# # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏\n",
    "# display(df_false_clusters[['cluster_sentences', 'summary']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'–•–æ—Ä–æ—à–∏–π –≥–µ—Ä–º–µ—Ç–∏–∫, –ø–æ–º–æ–≥. –•–æ—Ä–æ—à–∏–π –≥–µ—Ä–º–µ—Ç–∏–∫, –ø–æ–º–æ–≥. –•–æ—Ä–æ—à–∏–π –≥–µ—Ä–º–µ—Ç–∏–∫, –ø–æ–º–æ–≥. –•–æ—Ä–æ—à–∏–π –≥–µ—Ä–º–µ—Ç–∏–∫, –ø–æ–º–æ–≥. –•–æ—Ä–æ—à–∏–π –≥–µ—Ä–º–µ—Ç–∏–∫, –ø–æ–º–æ–≥.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import re\n",
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞\n",
    "# model_name = \"cointegrated/rut5-base-multitask\"  # –ú–æ–¥–µ–ª—å T5 –¥–ª—è –º—É–ª—å—Ç–∏—Ç–∞—Å–∫–∏–Ω–≥–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–æ–≤ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞\n",
    "# def clean_text(text):\n",
    "#     sentences = text.split('<br>')\n",
    "#     cleaned_sentences = []\n",
    "#     seen = set()\n",
    "    \n",
    "#     for sentence in sentences:\n",
    "#         sentence = sentence.strip()\n",
    "#         if sentence not in seen:\n",
    "#             cleaned_sentences.append(sentence)\n",
    "#             seen.add(sentence)\n",
    "    \n",
    "#     return ' '.join(cleaned_sentences)\n",
    "\n",
    "# # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º T5\n",
    "# def correct_text(text):\n",
    "#     inputs = tokenizer(\"correct: \" + text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "#     summary_ids = model.generate(inputs.input_ids, max_length=150, min_length=40, length_penalty=1.0, num_beams=4, early_stopping=True)\n",
    "#     return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# # –ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞\n",
    "# text = '–•–æ—Ä–æ—à–∏–π –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å, —á–∏—Å—Ç–∏–ª –¥—Ä–æ—Å—Å–µ–ª—å —Å—Ç–∞—Ä–æ–π –¢–æ–π–æ—Ç—ã, –æ—Ç–º—ã–≤–∞–µ—Ç –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ, —Å–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤—Ü—É. <br>–û—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ –æ—Ç–º—ã–≤–∞–µ—Ç –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏—è, –Ω–∞–≥–∞—Ä –•–æ—Ä–æ—à–∏–π –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å, –ø—Ä–µ—à—ë–ª —Ö–æ—Ä–æ—à–æ —É–ø–∞–∫–æ–≤–∞–Ω, —Å–ø–∞—Å–∏–±–æ –ø—Ä–æ–¥–∞–≤—Ü—É <br>–•–æ—Ä–æ—à–∏–π –≥–µ—Ä–º–µ—Ç–∏–∫, –ø–æ–º–æ–≥. <br>–•–æ—Ä–æ—à–∏–π –≥–µ—Ä–º–µ—Ç–∏–∫, –ø–æ–º–æ–≥. <br>–û—Ç–ª–∏—á–Ω—ã–π —Ç–æ–≤–∞—Ä —Ä–µ–∫–æ–º–µ–Ω–¥—É—é'\n",
    "\n",
    "# # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –ø–æ–≤—Ç–æ—Ä–æ–≤\n",
    "# cleaned_text = clean_text(text)\n",
    "\n",
    "# # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏\n",
    "# final_text = correct_text(cleaned_text)\n",
    "# final_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_exploded_sorted[\"cluster_sentences\"].to_csv(\"./reviews_keywords/clusters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce69147fe48a4354a19c51e442d277ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'clusters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m key_phrases\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkey_phrases\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_key_phrases_from_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclusters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# –ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ñ—Ä–∞–∑–∞–º\u001b[39;00m\n\u001b[1;32m     54\u001b[0m key_phrases \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey_phrases\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:3161\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3156\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3157\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3158\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3159\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3160\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3161\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3162\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3163\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:3552\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3548\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3549\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3550\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3551\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3552\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3556\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3557\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3561\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:3421\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3420\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3421\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3423\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3424\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3425\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[15], line 50\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m key_phrases\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m batch: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey_phrases\u001b[39m\u001b[38;5;124m\"\u001b[39m: extract_key_phrases_from_clusters(\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclusters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)}, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# –ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ñ—Ä–∞–∑–∞–º\u001b[39;00m\n\u001b[1;32m     54\u001b[0m key_phrases \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey_phrases\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:271\u001b[0m, in \u001b[0;36mLazyDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 271\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys_to_format:\n\u001b[1;32m    273\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'clusters'"
     ]
    }
   ],
   "source": [
    "# def filter_tokens(syntax_analysis):\n",
    "#     # –û—Ç–∫–ª—é—á–∞–µ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "#     filtered_tokens = [\n",
    "#         token for token in syntax_analysis \n",
    "#         if token[1] not in {\"PUNCT\", \"SPACE\"}  # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –∏ –ø—Ä–æ–±–µ–ª—ã\n",
    "#         # –û—Ç–∫–ª—é—á–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –¥–ª–∏–Ω–µ\n",
    "#     ]\n",
    "    \n",
    "#     return filtered_tokens\n",
    "\n",
    "# def extract_key_phrases_from_sentences(doc):\n",
    "#     key_phrases = []\n",
    "    \n",
    "#     for sent in doc.sents:\n",
    "#         syntax_analysis = [(token.text, token.pos_, token.dep_, token.head.text) for token in sent]\n",
    "#         filtered_tokens = filter_tokens(syntax_analysis)\n",
    "#         phrase = []\n",
    "\n",
    "#         for i, token in enumerate(filtered_tokens):\n",
    "#             if token[1] in {\"NOUN\", \"VERB\"}:  # –°—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ –∏–ª–∏ –≥–ª–∞–≥–æ–ª\n",
    "#                 if phrase:\n",
    "#                     key_phrases.append(\" \".join(phrase))\n",
    "#                     phrase = []\n",
    "#                 phrase.append(token[0])\n",
    "#             elif token[1] in {\"ADJ\", \"ADV\"}:  # –ü—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ, –Ω–∞—Ä–µ—á–∏—è\n",
    "#                 if phrase:\n",
    "#                     phrase.append(token[0])\n",
    "\n",
    "#             # –ï—Å–ª–∏ –∫–æ–Ω–µ—Ü —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —á–∞—Å—Ç—å —Ä–µ—á–∏ –Ω–µ —Å–≤—è–∑–∞–Ω–∞ —Å —Ç–µ–∫—É—â–µ–π —Ñ—Ä–∞–∑–æ–π\n",
    "#             if i == len(filtered_tokens) - 1 or filtered_tokens[i+1][1] not in {\"ADJ\", \"ADV\", \"ADP\", \"CCONJ\", \"SCONJ\", \"PART\"}:\n",
    "#                 if phrase:\n",
    "#                     key_phrases.append(\" \".join(phrase))\n",
    "#                     phrase = []\n",
    "#     key_phrases = [phrase for phrase in key_phrases if len(phrase.split()) > 1 and len(phrase.strip()) > 2]\n",
    "\n",
    "#     return \" \".join(key_phrases)\n",
    "\n",
    "\n",
    "# def extract_key_phrases_from_clusters(clusters):\n",
    "#     key_phrases = []\n",
    "#     for cluster in clusters:\n",
    "#         cluster_key_phrases = []\n",
    "#         for sentences in cluster:  # –¢–∞–∫ –∫–∞–∫ cluster —Ç–µ–ø–µ—Ä—å —Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤\n",
    "#             doc = nlp(sentences)\n",
    "#             cluster_key_phrases.append(extract_key_phrases_from_sentences(doc))\n",
    "#         key_phrases.append(\" \".join(cluster_key_phrases))  # –°–æ–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã –∏–∑ –æ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞ –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É\n",
    "#     return key_phrases\n",
    "\n",
    "# # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "# dataset = dataset.map(lambda batch: {\"key_phrases\": extract_key_phrases_from_clusters(batch['clusters'])}, batched=True, batch_size=8)\n",
    "\n",
    "\n",
    "# # –ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ñ—Ä–∞–∑–∞–º\n",
    "# key_phrases = dataset['key_phrases']\n",
    "# phrase_freq = Counter(key_phrases)\n",
    "\n",
    "# # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "# print(\"–ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑ (–ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –±–ª–∏–∑–æ—Å—Ç–∏):\")\n",
    "# print(phrase_freq.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"./reviews_keywords/temp_spacy.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
